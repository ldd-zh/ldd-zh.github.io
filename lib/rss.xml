<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[ldd_zh]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib/media/favicon.png</url><title>ldd_zh</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Tue, 04 Mar 2025 16:40:32 GMT</lastBuildDate><atom:link href="lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Tue, 04 Mar 2025 16:40:32 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[index]]></title><description><![CDATA[ 
 <br>这里是 linux device driver 的中文版]]></description><link>index.html</link><guid isPermaLink="false">index.md</guid><pubDate>Tue, 04 Mar 2025 16:38:25 GMT</pubDate></item><item><title><![CDATA[1.0 设备驱动简介]]></title><description><![CDATA[ 
 <br>以Linux为代表的自由操作系统具有众多优势，其中之一就是其内部代码对所有人开放。操作系统曾经是可见代码受限的神秘领域，只有少数程序员能够接触，而现在，任何具备相应技能的人都可以轻松查看、理解和修改它。Linux帮助实现了操作系统的民主化。然而，Linux内核的代码仍然是庞大且复杂的，为了不被复杂性压倒的情况下接近代码，对于想要成为内核黑客的人来说需要一个切入点。通常，设备驱动程序就是这个切入点。<br>设备驱动程序在Linux内核中扮演着特殊的角色。它们是独立的“黑匣子”，使得特定的硬件能够响应定义良好的内部编程接口；设备驱动程序完全隐藏了设备的工作细节。用户活动通过一组标准化的调用来执行，这些调用与具体的驱动程序无关；将这些调用映射到实际硬件上的设备特定操作，则是设备驱动程序的任务。这种编程接口使得驱动程序可以与内核的其他部分分开构建，并在需要时“插入”运行时。这种模块化使得Linux驱动程序易于编写，以至于现在有数百个驱动程序可用。<br>编写Linux设备驱动程序有很多理由。新硬件推出（和淘汰！）的速度本身就保证了驱动程序编写者在可预见的未来会非常忙碌。个人可能需要了解驱动程序，以便访问他们感兴趣的特定设备。硬件供应商通过为其产品提供Linux驱动程序，可以将庞大且不断增长的Linux用户群纳入其潜在市场。而Linux系统的开源性质意味着，如果驱动程序编写者愿意，驱动程序的源代码可以迅速传播给数百万用户。<br>本书将教你如何编写自己的驱动程序，以及如何在内核的相关部分进行修改。我们采用了设备无关的方法；编程技术和接口尽可能在不绑定任何特定设备的情况下呈现。每个驱动程序都不同；作为驱动程序编写者，你需要深入了解你的特定设备。但大多数原则和基本技术对所有驱动程序都是相同的。本书无法教你关于你的设备的知识，但它为你提供了使设备工作所需的背景知识。<br>在学习编写驱动程序的过程中，你会对Linux内核有更深入的了解；这可能会帮助你理解你的机器是如何工作的，以及为什么事情并不总是像你期望的那样快，或者为什么它们不完全按照你的意愿行事。我们逐步引入新概念，从非常简单的驱动程序开始，并在此基础上构建；每个新概念都伴随着不需要特殊硬件即可测试的示例代码。<br>本章实际上并没有涉及编写代码。然而，我们介绍了一些关于Linux内核的背景概念，这些概念在你开始编程时会很有用。]]></description><link>第1章-设备驱动简介/1.0-设备驱动简介.html</link><guid isPermaLink="false">第1章 设备驱动简介/1.0 设备驱动简介.md</guid><pubDate>Tue, 04 Mar 2025 15:56:22 GMT</pubDate></item><item><title><![CDATA[1.1 设备驱动程序的作用]]></title><description><![CDATA[ 
 <br>作为程序员，你可以根据自己的需求选择驱动程序的设计，并在编程时间和结果的灵活性之间找到一个可接受的平衡点。尽管说驱动程序“灵活”可能听起来有些奇怪，但我们喜欢这个词，因为它强调了设备驱动程序的作用是提供机制，而不是策略。<br>机制与策略的区分是Unix设计中最出色的思想之一。大多数编程问题确实可以分为两部分：“提供哪些功能”（机制）和“如何使用这些功能”（策略）。如果这两个问题由程序的不同部分甚至不同的程序来处理，软件包的开发和适应特定需求就会容易得多。<br>例如，Unix对图形显示的管理分为X服务器和窗口及会话管理器。X服务器了解硬件并为用户程序提供统一的接口，而窗口和会话管理器则实现特定的策略，而不需要了解硬件的任何信息。人们可以在不同的硬件上使用相同的窗口管理器，不同的用户可以在同一工作站上运行不同的配置。甚至完全不同的桌面环境，如KDE和GNOME，也可以在同一系统上共存。另一个例子是TCP/IP网络的分层结构：操作系统提供套接字抽象，它不涉及数据传输的策略，而不同的服务器负责服务（及其相关策略）。此外，像ftpd这样的服务器提供文件传输机制，而用户可以使用他们喜欢的任何客户端；既有命令行客户端，也有图形客户端，任何人都可以编写新的用户界面来传输文件。<br>在驱动程序方面，机制与策略的分离同样适用。软盘驱动程序是无策略的——它的作用只是将磁盘显示为连续的数据块数组。系统的更高层次提供策略，例如谁可以访问软盘驱动器，驱动器是直接访问还是通过文件系统访问，以及用户是否可以在驱动器上挂载文件系统。由于不同的环境通常需要以不同的方式使用硬件，因此尽可能保持无策略是非常重要的。<br>在编写驱动程序时，程序员应特别注意这一基本概念：编写内核代码以访问硬件，但不要对用户强加特定的策略，因为不同的用户有不同的需求。驱动程序应处理硬件的可用性，将所有关于如何使用硬件的问题留给应用程序。因此，如果驱动程序提供对硬件功能的访问而不增加约束，那么它就是灵活的。然而，有时必须做出一些策略决策。例如，数字I/O驱动程序可能只提供字节级访问硬件，以避免处理单个位所需的额外代码。<br>你也可以从不同的角度来看待你的驱动程序：它是位于应用程序和实际设备之间的软件层。驱动程序的这一特权角色使得驱动程序程序员可以精确选择设备应如何呈现：不同的驱动程序可以提供不同的功能，即使对于相同的设备。实际的驱动程序设计应平衡多种不同的考虑因素。例如，单个设备可能同时被不同的程序使用，驱动程序程序员可以完全自由地决定如何处理并发。你可以在设备的硬件功能之外实现内存映射，或者提供一个用户库来帮助应用程序程序员在可用原语的基础上实现新策略，等等。一个主要的考虑因素是在尽可能多的选项和编写驱动程序所需的时间之间进行权衡，以及保持简单以避免错误。<br>无策略的驱动程序通常具有一些典型特征。这些特征包括支持同步和异步操作、能够多次打开、能够充分利用硬件的全部功能，以及没有“简化事物”或提供策略相关操作的软件层。这种驱动程序不仅对最终用户更好，而且编写和维护起来也更容易。无策略实际上是软件设计者的一个常见目标。<br>许多设备驱动程序确实与用户程序一起发布，以帮助配置和访问目标设备。这些程序的范围从简单的实用程序到完整的图形应用程序。例如，调整并行端口打印机驱动程序操作的tunelp程序，以及作为PCMCIA驱动程序包一部分的图形cardctl实用程序。通常还提供一个客户端库，它提供不需要作为驱动程序本身实现的功能。<br>本书的范围是内核，因此我们尽量不涉及策略问题或应用程序或支持库。有时我们会讨论不同的策略以及如何支持它们，但我们不会详细讨论使用设备的程序或它们执行的策略。然而，你应该理解，用户程序是软件包的一个组成部分，即使是无策略的软件包也附带配置文件，这些文件将默认行为应用于底层机制。]]></description><link>第1章-设备驱动简介/1.1-设备驱动程序的作用.html</link><guid isPermaLink="false">第1章 设备驱动简介/1.1 设备驱动程序的作用.md</guid><pubDate>Tue, 04 Mar 2025 15:52:56 GMT</pubDate></item><item><title><![CDATA[1.2 内核的划分]]></title><description><![CDATA[ 
 <br>在Unix系统中，多个并发进程处理不同的任务。每个进程请求系统资源，无论是计算能力、内存、网络连接还是其他资源。内核是负责处理所有这些请求的大块可执行代码。尽管不同内核任务之间的区别并不总是清晰，但内核的作用可以划分为以下几个部分（如图1-1所示）：<br>
<br>
进程管理：内核负责创建和销毁进程，并处理它们与外部世界的连接（输入和输出）。不同进程之间的通信（通过信号、管道或进程间通信原语）是系统整体功能的基础，也由内核处理。此外，调度程序控制进程如何共享CPU，是进程管理的一部分。更一般地说，内核的进程管理活动在单个CPU或少数CPU上实现了多个进程的抽象。

<br>
内存管理：计算机的内存是一个主要资源，处理它的策略对系统性能至关重要。内核在有限的可用资源之上为所有进程构建虚拟地址空间。内核的不同部分通过一组函数调用与内存管理子系统交互，从简单的malloc/free对到更复杂的功能。

<br>
文件系统：Unix严重依赖于文件系统的概念；几乎所有的东西在Unix中都可以被视为文件。内核在非结构化硬件之上构建结构化文件系统，生成的文件抽象在整个系统中被广泛使用。此外，Linux支持多种文件系统类型，即在物理介质上组织数据的不同方式。例如，磁盘可以格式化为Linux标准的ext3文件系统、常用的FAT文件系统或其他几种文件系统。

<br>
设备控制：几乎每个系统操作最终都会映射到物理设备。除了处理器、内存和极少数其他实体外，所有设备控制操作都由特定于设备的代码执行。该代码称为设备驱动程序。内核必须嵌入系统中每个外围设备的设备驱动程序，从硬盘到键盘和磁带驱动器。内核功能的这一方面是我们在本书中的主要兴趣所在。

<br>
网络：网络必须由操作系统管理，因为大多数网络操作不特定于某个进程：传入的数据包是异步事件。数据包必须被收集、识别和分发，然后由进程处理。系统负责跨程序和网络接口传递数据包，并且必须根据程序的网络活动控制其执行。此外，所有路由和地址解析问题都在内核内实现。

<br><br>Linux的一个优点是能够在运行时扩展内核提供的功能集。这意味着你可以在系统运行时添加（或删除）内核功能。<br>每个可以在运行时添加到内核的代码片段称为模块。Linux内核支持多种不同类型的模块，包括但不限于设备驱动程序。每个模块由目标代码（未链接到完整的可执行文件中）组成，可以通过insmod程序动态链接到运行中的内核，并可以通过rmmod程序取消链接。<br>图1-1标识了负责特定任务的不同模块类——根据模块提供的功能，模块被归类为特定类。图1-1中模块的位置涵盖了最重要的类，但远未完成，因为Linux中越来越多的功能正在模块化。]]></description><link>第1章-设备驱动简介/1.2-内核的划分.html</link><guid isPermaLink="false">第1章 设备驱动简介/1.2 内核的划分.md</guid><pubDate>Tue, 04 Mar 2025 15:54:17 GMT</pubDate></item><item><title><![CDATA[1.3 设备和模块的分类]]></title><description><![CDATA[ 
 <br>Linux看待设备的方式区分了三种基本设备类型。每个模块通常实现其中一种类型，因此可以分为字符模块、块模块或网络模块。模块的这种分类并不是严格的；程序员可以选择在一个代码块中实现不同驱动程序的大型模块。然而，优秀的程序员通常为每个新功能创建一个不同的模块，因为分解是可扩展性和可扩展性的关键要素。<br>这三种类型是：<br>
<br>
字符设备：字符设备是可以作为字节流访问的设备（如文件）；字符驱动程序负责实现这种行为。这种驱动程序通常至少实现open、close、read和write系统调用。文本控制台（/dev/console）和串行端口（/dev/ttyS0等）是字符设备的例子，因为它们很好地体现了流抽象。字符设备通过文件系统节点访问，例如/dev/tty1和/dev/lp0。字符设备与常规文件之间的唯一相关区别是，你总是可以在常规文件中来回移动，而大多数字符设备只是数据通道，你只能顺序访问。然而，也存在看起来像数据区域的字符设备，你可以在其中来回移动；例如，这通常适用于帧抓取器，应用程序可以使用mmap或lseek访问整个获取的图像。

<br>
块设备：像字符设备一样，块设备通过/dev目录中的文件系统节点访问。块设备是可以托管文件系统的设备（例如磁盘）。在大多数Unix系统中，块设备只能处理传输一个或多个完整块的I/O操作，这些块通常为512字节（或更大的2的幂次方字节）。Linux则允许应用程序像字符设备一样读写块设备——它允许一次传输任意数量的字节。因此，块设备和字符设备仅在数据在内核中的管理方式以及内核/驱动程序软件接口方面有所不同。像字符设备一样，每个块设备通过文件系统节点访问，它们之间的区别对用户是透明的。块驱动程序与内核的接口与字符驱动程序完全不同。

<br>
网络接口：任何网络事务都是通过接口进行的，即能够与其他主机交换数据的设备。通常，接口是硬件设备，但也可能是纯软件设备，如环回接口。网络接口负责发送和接收数据包，由内核的网络子系统驱动，而不需要知道单个事务如何映射到实际传输的数据包。许多网络连接（尤其是使用TCP的连接）是面向流的，但网络设备通常围绕数据包的传输和接收设计。网络驱动程序对单个连接一无所知；它只处理数据包。由于网络接口不是面向流的设备，因此不容易像/dev/tty1那样映射到文件系统中的节点。Unix提供对接口访问的方式仍然是为它们分配唯一的名称（如eth0），但该名称在文件系统中没有相应的条目。内核与网络设备驱动程序之间的通信与字符和块驱动程序完全不同。内核调用与数据包传输相关的函数，而不是read和write。

<br>还有其他与上述设备类型正交的驱动程序模块分类方式。一般来说，某些类型的驱动程序与给定类型设备的额外内核支持功能层一起工作。例如，可以谈论通用串行总线（USB）模块、串行模块、SCSI模块等。每个USB设备都由一个与USB子系统一起工作的USB模块驱动，但设备本身在系统中显示为字符设备（如USB串行端口）、块设备（如USB存储卡读卡器）或网络设备（如USB以太网接口）。<br>近年来，内核中添加了其他类别的设备驱动程序，包括FireWire驱动程序和I2O驱动程序。与处理USB和SCSI驱动程序的方式相同，内核开发人员收集了类范围内的功能，并将其导出给驱动程序实现者，以避免重复工作和错误，从而简化和加强编写此类驱动程序的过程。<br>除了设备驱动程序外，内核中还模块化了其他功能，包括硬件和软件。一个常见的例子是文件系统。文件系统类型决定了如何在块设备上组织信息以表示目录和文件的树。这种实体不是设备驱动程序，因为没有显式设备与信息的布局方式相关联；文件系统类型是软件驱动程序，因为它将低级数据结构映射到高级数据结构。文件系统决定了文件名可以有多长以及每个文件的信息存储在目录条目中的内容。文件系统模块必须实现访问目录和文件的系统调用的最低级别，通过将文件名和路径（以及其他信息，如访问模式）映射到存储在数据块中的数据结构。这种接口与实际数据传输到磁盘（或其他介质）完全独立，后者由块设备驱动程序完成。<br>如果你考虑到Unix系统对底层文件系统的依赖程度，你会意识到这种软件概念对系统操作至关重要。解码文件系统信息的能力位于内核层次结构的最低层，至关重要；即使你为新的CD-ROM编写了块驱动程序，如果你无法对其托管的数据运行ls或cp，它也是无用的。Linux支持文件系统模块的概念，其软件接口声明了可以对文件系统节点、目录、文件和超级块执行的不同操作。程序员通常不需要编写文件系统模块，因为官方内核已经包含了最重要文件系统类型的代码。]]></description><link>第1章-设备驱动简介/1.3-设备和模块的分类.html</link><guid isPermaLink="false">第1章 设备驱动简介/1.3 设备和模块的分类.md</guid><pubDate>Tue, 04 Mar 2025 15:57:05 GMT</pubDate></item><item><title><![CDATA[1.4 安全问题]]></title><description><![CDATA[ 
 <br>在现代，安全是一个越来越重要的问题。我们将在本书中讨论与安全相关的问题。然而，有一些一般概念值得现在提及。<br>系统中的任何安全检查都由内核代码强制执行。如果内核有安全漏洞，那么整个系统就有漏洞。在官方内核发行版中，只有授权用户才能加载模块；系统调用init_module检查调用进程是否有权将模块加载到内核中。因此，在运行官方内核时，只有超级用户或成功获得权限的入侵者才能利用特权代码的力量。<br>在可能的情况下，驱动程序编写者应避免在其代码中编码安全策略。安全是一个策略问题，通常最好在内核的更高层次处理，由系统管理员控制。然而，总是有例外。<br>作为设备驱动程序编写者，你应该意识到某些类型的设备访问可能会对整个系统产生不利影响，并应提供足够的控制。例如，影响全局资源的设备操作（如设置中断线）、可能损坏硬件的操作（如加载固件）或可能影响其他用户的操作（如在磁带驱动器上设置默认块大小）通常只对足够特权的用户可用，并且必须在驱动程序本身中进行此检查。<br>驱动程序编写者当然也必须小心，以避免引入安全漏洞。C编程语言使得犯几种类型的错误变得容易。例如，许多当前的安全问题是由缓冲区溢出错误引起的，程序员忘记检查写入缓冲区的数据量，数据最终写入缓冲区末尾之外，从而覆盖了不相关的数据。此类错误可能会危及整个系统，必须避免。幸运的是，在设备驱动程序的上下文中，避免这些错误通常相对容易，因为与用户的接口是狭窄定义且高度控制的。<br>其他一些一般的安全思想值得牢记。从用户进程接收的任何输入都应非常怀疑；除非你能验证它，否则永远不要信任它。小心未初始化的内存；从内核获得的任何内存应在提供给用户进程或设备之前清零或以其他方式初始化。否则，可能会导致信息泄漏（数据、密码等的泄露）。如果你的设备解释发送给它的数据，请确保用户不能发送任何可能危及系统的内容。最后，考虑设备操作的可能影响；如果有特定操作（如重新加载适配器板上的固件或格式化磁盘）可能会影响系统，这些操作几乎肯定应限制为特权用户。<br>在接收第三方软件时也要小心，尤其是涉及内核时：因为每个人都可以访问源代码，每个人都可以破坏和重新编译东西。虽然你通常可以信任发行版中的预编译内核，但你应该避免运行由不受信任的朋友编译的内核——如果你不会以root身份运行预编译的二进制文件，那么你最好不要运行预编译的内核。例如，恶意修改的内核可能允许任何人加载模块，从而通过init_module打开一个意想不到的后门。<br>请注意，Linux内核可以编译为完全不支持模块，从而关闭任何与模块相关的安全漏洞。在这种情况下，当然，所有需要的驱动程序必须直接构建到内核本身中。在2.2及更高版本的内核中，还可以通过能力机制在系统启动后禁用内核模块的加载。]]></description><link>第1章-设备驱动简介/1.4-安全问题.html</link><guid isPermaLink="false">第1章 设备驱动简介/1.4 安全问题.md</guid><pubDate>Tue, 04 Mar 2025 15:57:14 GMT</pubDate></item><item><title><![CDATA[1.5 版本编号]]></title><description><![CDATA[ 
 <br>在深入编程之前，我们应该评论一下Linux中使用的版本编号方案以及本书涵盖的版本。<br>首先，请注意，Linux系统中使用的每个软件包都有自己的发布号，并且它们之间通常存在相互依赖关系：你需要特定版本的软件包才能运行另一个特定版本的软件包。Linux发行版的创建者通常处理匹配软件包的混乱问题，从预打包发行版安装的用户不需要处理版本号。另一方面，那些替换和升级系统软件的人在这方面只能靠自己。幸运的是，几乎所有现代发行版都支持通过检查软件包之间的依赖关系来升级单个软件包；发行版的软件包管理器通常不允许升级，直到满足依赖关系。<br>要运行我们在讨论中介绍的示例，你不需要任何工具的特定版本，除了2.6内核所需的版本；任何最近的Linux发行版都可以用来运行我们的示例。我们不会详细说明具体要求，因为如果你遇到任何问题，内核源代码中的Documentation/Changes文件是此类信息的最佳来源。<br>就内核而言，偶数版本的内核（即2.6.x）是用于一般分发的稳定版本。相反，奇数版本（如2.7.x）是开发快照，非常短暂；最新的版本代表了开发的当前状态，但在几天内就会过时。<br>本书涵盖2.6版本的内核。我们的重点是展示2.6.10中设备驱动程序编写者可用的所有功能，这是我们写作时的当前版本。本书的这一版不涵盖内核的早期版本。对于那些感兴趣的人，第二版详细涵盖了2.0到2.4版本。该版仍然可以在<a rel="noopener nofollow" class="external-link" href="http://lwn.net/Kernel/LDD2/" target="_blank">http://lwn.net/Kernel/LDD2/</a>在线获取。<br>内核程序员应该意识到，2.6的开发过程发生了变化。2.6系列现在接受以前被认为对“稳定”内核来说太大的更改。除其他外，这意味着内部内核编程接口可能会发生变化，从而使本书的部分内容过时；出于这个原因，随文本附带的示例代码已知适用于2.6.10，但某些模块在早期版本下无法编译。希望跟上内核编程变化的程序员被鼓励加入邮件列表并利用书目中列出的网站。还有一个网页维护在<a rel="noopener nofollow" class="external-link" href="http://lwn.net/Articles/2.6-kernel-api/" target="_blank">http://lwn.net/Articles/2.6-kernel-api/</a>，其中包含自本书出版以来发生的API更改的信息。<br>本书不专门讨论奇数版本的内核。普通用户没有理由运行开发内核。然而，实验新功能的开发人员希望运行最新的开发版本。他们通常会不断升级到最新版本以获取错误修复和新功能的实现。请注意，实验内核没有任何保证，如果由于非当前奇数版本内核中的错误而出现问题，没有人会帮助你。运行奇数版本内核的人通常足够熟练，可以在不需要教科书的情况下深入研究代码，这是我们不在这里讨论开发内核的另一个原因。<br>Linux的另一个特点是它是一个平台独立的操作系统，而不仅仅是“PC克隆的Unix克隆”：它目前支持大约20种架构。本书尽可能平台独立，所有代码示例至少在x86和x86-64平台上进行了测试。由于代码已经在32位和64位处理器上进行了测试，它应该可以在所有其他平台上编译和运行。正如你所料，依赖特定硬件的代码示例并不适用于所有支持的平台，但这总是在源代码中说明。]]></description><link>第1章-设备驱动简介/1.5-版本编号.html</link><guid isPermaLink="false">第1章 设备驱动简介/1.5 版本编号.md</guid><pubDate>Tue, 04 Mar 2025 15:57:26 GMT</pubDate></item><item><title><![CDATA[1.6 许可条款]]></title><description><![CDATA[ 
 <br>Linux根据GNU通用公共许可证（GPL）第2版获得许可，该文件由自由软件基金会为GNU项目设计。GPL允许任何人重新分发甚至销售受GPL保护的产品，只要接收者可以访问源代码并能够行使相同的权利。此外，任何从受GPL保护的产品派生的软件产品，如果重新分发，必须根据GPL发布。<br>这种许可证的主要目标是通过允许每个人随意修改程序来促进知识的增长；同时，向公众销售软件的人仍然可以完成他们的工作。尽管目标简单，但关于GPL及其使用的讨论从未停止。如果你想阅读许可证，你可以在系统中的多个地方找到它，包括内核源代码树的顶层目录中的COPYING文件。<br>供应商经常询问他们是否可以仅以二进制形式分发内核模块。这个问题的答案故意模棱两可。只要二进制模块遵守已发布的内核接口，它们的分发到目前为止是被容忍的。但内核的版权由许多开发人员持有，并非所有人都同意内核模块不是派生作品。如果你或你的雇主希望以非自由许可证分发内核模块，你真的需要与你的法律顾问讨论情况。请注意，内核开发人员不介意在内核版本之间破坏二进制模块，即使是在稳定内核系列的中间。如果可能的话，你和你的用户最好将你的模块作为自由软件发布。<br>如果你希望你的代码进入主线内核，或者如果你的代码需要内核补丁，你必须在发布代码时使用与GPL兼容的许可证。尽管个人使用你的更改不会强制你使用GPL，但如果你分发你的代码，你必须在分发中包含源代码——获取你的软件包的人必须能够随意重新构建二进制文件。<br>就本书而言，大多数代码可以自由重新分发，无论是源代码还是二进制形式，我们和O'Reilly都不保留任何派生作品的权利。所有程序都可以在ftp://ftp.ora.com/pub/examples/linux/drivers/获取，确切的许可条款在同一目录的LICENSE文件中说明。]]></description><link>第1章-设备驱动简介/1.6-许可条款.html</link><guid isPermaLink="false">第1章 设备驱动简介/1.6 许可条款.md</guid><pubDate>Tue, 04 Mar 2025 15:57:35 GMT</pubDate></item><item><title><![CDATA[1.7 加入内核开发社区]]></title><description><![CDATA[ 
 <br>当你开始为Linux内核编写模块时，你就成为了一个更大的开发者社区的一部分。在这个社区中，你不仅可以找到从事类似工作的人，还可以找到一群高度敬业的工程师，他们致力于使Linux成为一个更好的系统。这些人可以成为帮助、想法和批评的来源——当你为新驱动程序寻找测试人员时，他们可能是你首先求助的人。<br>Linux内核开发者的中心聚集点是linux-kernel邮件列表。所有主要的内核开发者，从Linus Torvalds开始，都订阅了这个列表。请注意，这个列表不适合胆小的人：截至本文写作时，每天的邮件量可能高达200封或更多。尽管如此，关注这个列表对于那些对内核开发感兴趣的人来说是必不可少的；它也可以为那些需要内核开发帮助的人提供高质量的资源。<br>要加入linux-kernel邮件列表，请按照linux-kernel邮件列表FAQ中的说明操作：<a rel="noopener nofollow" class="external-link" href="http://www.tux.org/lkml" target="_blank">http://www.tux.org/lkml</a>。阅读FAQ的其他部分，那里有很多有用的信息。Linux内核开发者非常忙碌，他们更愿意帮助那些已经做好功课的人。]]></description><link>第1章-设备驱动简介/1.7-加入内核开发社区.html</link><guid isPermaLink="false">第1章 设备驱动简介/1.7 加入内核开发社区.md</guid><pubDate>Tue, 04 Mar 2025 15:57:43 GMT</pubDate></item><item><title><![CDATA[1.8 本书概述]]></title><description><![CDATA[ 
 <br>从现在开始，我们将进入内核编程的世界。第2章介绍了模块化，解释了模块化的奥秘，并展示了运行模块的代码。第3章讨论了字符驱动程序，并展示了一个基于内存的设备驱动程序的完整代码，该驱动程序可以用于读写操作。使用内存作为设备的硬件基础，使得任何人都可以在不需要特殊硬件的情况下运行示例代码。<br>调试技术是程序员的重要工具，第4章将介绍这些技术。对于想要在现代内核上进行开发的程序员来说，管理并发和竞争条件同样重要。第5章涉及并发访问资源所带来的问题，并介绍了Linux控制并发的机制。<br>在掌握了调试和并发管理技能之后，我们将转向字符驱动程序的高级功能，如阻塞操作、select的使用以及重要的ioctl调用；这些主题是第6章的主要内容。<br>在处理硬件管理之前，我们将剖析内核的更多软件接口：第7章展示了内核中时间的管理方式，第8章解释了内存分配。<br>接下来我们将专注于硬件。第9章描述了设备上的I/O端口和内存缓冲区的管理；之后是第10章的中断处理。不幸的是，并非所有人都能运行这些章节的示例代码，因为测试软件接口中断确实需要一些硬件支持。我们尽力将所需的硬件支持降到最低，但你仍然需要一些简单的硬件，如标准的并行端口，才能运行这些章节的示例代码。<br>第11章涵盖了内核中数据类型的使用以及编写可移植代码的技巧。<br>本书的后半部分专注于更高级的主题。我们首先深入硬件，特别是特定外围总线的工作原理。第12章详细介绍了如何为PCI设备编写驱动程序，第13章则探讨了与USB设备交互的API。<br>在理解了外围总线之后，我们可以详细研究Linux设备模型，这是内核用于描述其管理的硬件和软件资源的抽象层。第14章从下至上介绍了设备模型的基础设施，从kobject类型开始，逐步向上。它涵盖了设备模型与真实硬件的集成；然后利用这些知识讨论了热插拔设备和电源管理等主题。<br>第15章，我们将深入探讨Linux内存管理。本章展示了如何将内核内存映射到用户空间（mmap系统调用），将用户内存映射到内核空间（使用get_user_pages），以及如何将这两种内存映射到设备空间（以执行直接内存访问[DMA]操作）。<br>我们对内存的理解将有助于接下来的两章，这两章涵盖了其他主要的驱动程序类别。第16章介绍了块驱动程序，并展示了它们与我们迄今为止使用的字符驱动程序的不同之处。然后第17章深入探讨了网络驱动程序的编写。最后，我们讨论了串行驱动程序（第18章）并提供了参考文献。]]></description><link>第1章-设备驱动简介/1.8-本书概述.html</link><guid isPermaLink="false">第1章 设备驱动简介/1.8 本书概述.md</guid><pubDate>Tue, 04 Mar 2025 15:57:52 GMT</pubDate></item><item><title><![CDATA[2.0  构建和运行模块]]></title><description><![CDATA[ 
 <br>现在，我们即将开始编程。本章将介绍有关模块和内核编程的所有基本概念。在这几页中，我们将构建并运行一个完整的（尽管相对无用）模块，并了解所有模块共享的一些基本代码。掌握这些知识是开发任何模块化驱动程序的基础。为了避免一次性引入太多概念，本章仅讨论模块，不涉及任何特定设备类别。<br>本章介绍的所有内核项（函数、变量、头文件和宏）都在本章末尾的参考部分进行了详细说明。]]></description><link>第2章-构建和运行模块/2.0-构建和运行模块.html</link><guid isPermaLink="false">第2章 构建和运行模块/2.0  构建和运行模块.md</guid><pubDate>Tue, 04 Mar 2025 15:58:14 GMT</pubDate></item><item><title><![CDATA[2.1 设置测试系统]]></title><description><![CDATA[ 
 <br>从本章开始，我们将通过示例模块来演示编程概念。（所有这些示例都可以在O’Reilly的FTP站点上找到，详见第1章。）构建、加载和修改这些示例是理解驱动程序如何工作以及与内核交互的好方法。<br>这些示例模块应该适用于几乎所有2.6.x内核，包括由发行版供应商提供的内核。然而，我们建议你直接从kernel.org镜像网络获取“主线”内核，并将其安装到你的系统上。供应商的内核可能经过大量补丁修改，与主线内核存在差异；有时，供应商的补丁可能会改变设备驱动程序所看到的内核API。如果你正在编写一个必须在特定发行版上运行的驱动程序，你肯定需要针对相关内核进行构建和测试。但是，出于学习驱动程序编写的目的，标准内核是最佳选择。<br>无论你的内核来源如何，构建2.6.x模块都要求你在系统上有一个配置并构建好的内核树。这一要求与之前的内核版本不同，以前只需要一组当前的头文件即可。2.6模块是链接到内核源代码树中的目标文件的；这使得模块加载器更加健壮，但也要求这些目标文件必须可用。因此，你的首要任务是获取一个内核源代码树（可以从kernel.org网络或你的发行版的内核源代码包中获取），构建一个新内核，并将其安装到你的系统上。出于我们稍后会看到的原因，通常最简单的情况是你在构建模块时实际运行目标内核，尽管这并不是必须的。<br>你还应该考虑在哪里进行模块的实验、开发和测试。我们已尽力确保示例模块的安全性和正确性，但错误的可能性始终存在。内核代码中的故障可能会导致用户进程甚至整个系统的崩溃。它们通常不会引发更严重的问题，例如磁盘损坏。尽管如此，建议你在不包含重要数据的系统上进行内核实验，并且该系统不应执行关键服务。内核黑客通常会保留一个“牺牲”系统用于测试新代码。<br>因此，如果你还没有一个配置并构建好内核源代码树的合适系统，现在是时候设置一个了。我们会等你。一旦完成这个任务，你就可以开始玩转内核模块了。]]></description><link>第2章-构建和运行模块/2.1-设置测试系统.html</link><guid isPermaLink="false">第2章 构建和运行模块/2.1 设置测试系统.md</guid><pubDate>Tue, 04 Mar 2025 15:58:32 GMT</pubDate></item><item><title><![CDATA[2.2 Hello World 模块]]></title><description><![CDATA[ 
 <br>许多编程书籍都以“hello world”示例作为展示最简单程序的方式。本书讨论的是内核模块而非程序；因此，为了满足心急的读者，以下代码是一个完整的“hello world”模块：<br>#include &lt;linux/init.h&gt;
#include &lt;linux/module.h&gt;
MODULE_LICENSE("Dual BSD/GPL");

static int hello_init(void)
{
    printk(KERN_ALERT "Hello, world\n");
    return 0;
}

static void hello_exit(void)
{
    printk(KERN_ALERT "Goodbye, cruel world\n");
}

module_init(hello_init);
module_exit(hello_exit);
<br>该模块定义了两个函数，一个在模块加载到内核时调用（hello_init），另一个在模块移除时调用（hello_exit）。module_init 和 module_exit 行使用特殊的内核宏来指示这两个函数的作用。另一个特殊宏（MODULE_LICENSE）用于告诉内核该模块采用自由许可证；如果没有这样的声明，内核在加载模块时会发出警告。<br>printk 函数在 Linux 内核中定义，并可供模块使用；它的行为类似于标准 C 库函数 printf。内核需要自己的打印函数，因为它独立运行，不依赖于 C 库的帮助。模块可以调用 printk，因为在 insmod 加载模块后，模块会链接到内核，并可以访问内核的公共符号（函数和变量，详见下一节）。字符串 KERN_ALERT 是消息的优先级。我们在该模块中指定了高优先级，因为默认优先级的消息可能不会显示在任何有用的地方，具体取决于你运行的内核版本、klogd 守护进程的版本以及你的配置。你现在可以忽略这个问题；我们将在第4章中详细解释。<br>你可以使用 insmod 和 rmmod 工具测试该模块，如下所示。注意，只有超级用户才能加载和卸载模块。<br>% make
make[1]: Entering directory `/usr/src/linux-2.6.10'
CC [M] /home/ldd3/src/misc-modules/hello.o
Building modules, stage 2.
MODPOST
CC /home/ldd3/src/misc-modules/hello.mod.o
LD [M] /home/ldd3/src/misc-modules/hello.ko
make[1]: Leaving directory `/usr/src/linux-2.6.10'
% su
root# insmod ./hello.ko
Hello, world
root# rmmod hello
Goodbye cruel world
root#
<br>请注意，为了使上述命令序列正常工作，你必须有一个正确配置并构建的内核树，并且 makefile 能够找到它（例如 /usr/src/linux-2.6.10）。我们将在“编译和加载”部分详细介绍模块的构建过程。<br>根据系统传递消息行的机制，你的输出可能会有所不同。特别是，之前的屏幕截图来自文本控制台；如果你在窗口系统下的终端模拟器中运行 insmod 和 rmmod，你将不会在屏幕上看到任何内容。消息会发送到系统日志文件之一，例如 /var/log/messages（实际文件名因 Linux 发行版而异）。内核消息传递机制将在第4章中描述。<br>如你所见，编写模块并不像你想象的那么困难——至少，只要模块不需要做任何有意义的事情。困难的部分在于理解你的设备以及如何最大化性能。我们将在本章深入探讨模块化，并将设备特定的问题留到后面的章节。]]></description><link>第2章-构建和运行模块/2.2-hello-world-模块.html</link><guid isPermaLink="false">第2章 构建和运行模块/2.2 Hello World 模块.md</guid><pubDate>Tue, 04 Mar 2025 15:58:41 GMT</pubDate></item><item><title><![CDATA[2.3 内核模块与应用程序的区别]]></title><description><![CDATA[ 
 <br>在我们继续之前，值得强调内核模块与应用程序之间的各种区别。<br>虽然大多数中小型应用程序从头到尾执行单一任务，但每个内核模块只是注册自己以服务于未来的请求，并且其初始化函数会立即终止。换句话说，模块的初始化函数的任务是为以后调用模块的函数做准备；就像模块在说：“我在这里，这是我能做的。”模块的退出函数（示例中的 hello_exit）在模块卸载之前调用。它应该告诉内核：“我不在了；不要再让我做任何事情。”这种编程方法类似于事件驱动编程，但并非所有应用程序都是事件驱动的，而每个内核模块都是。事件驱动应用程序与内核代码之间的另一个主要区别在于退出函数：应用程序在终止时可以懒惰地释放资源或完全避免清理，而模块的退出函数必须仔细撤销初始化函数所构建的一切，否则这些部分将一直保留到系统重新启动。<br>顺便说一句，能够卸载模块是模块化最受赞赏的特性之一，因为它有助于缩短开发时间；你可以在不经过冗长的关机/重启周期的情况下测试新驱动程序的连续版本。<br>作为程序员，你知道应用程序可以调用它未定义的函数：链接阶段使用适当的函数库解析外部引用。printf 就是其中之一，它在 libc 中定义。另一方面，模块仅链接到内核，它只能调用内核导出的函数；没有库可以链接。例如，之前在 hello.c 中使用的 printk 函数是内核中定义的 printf 版本，并导出给模块使用。它的行为与原始函数类似，但有一些小差异，主要区别在于不支持浮点数。<br>图2-1展示了模块中如何使用函数调用和函数指针将新功能添加到运行中的内核。<br><br>模块在内核空间中运行，而应用程序在用户空间中运行。这个概念是操作系统理论的基础。<br>操作系统的角色实际上是为程序提供计算机硬件的一致视图。此外，操作系统必须考虑程序的独立操作和防止对资源的未授权访问。只有在 CPU 强制执行系统软件与应用程序之间的保护时，这一非平凡任务才可能实现。<br>每个现代处理器都能够强制执行这种行为。选择的方法是在 CPU 本身中实现不同的操作模式（或级别）。这些级别具有不同的角色，某些操作在较低级别是不允许的；程序代码只能通过有限数量的门从一个级别切换到另一个级别。Unix 系统设计为利用这一硬件特性，使用两个这样的级别。所有当前处理器至少有两个保护级别，有些（如 x86 系列）有更多级别；当存在多个级别时，使用最高和最低级别。在 Unix 下，内核在最高级别（也称为管理模式）执行，其中允许所有操作，而应用程序在最低级别（所谓的用户模式）执行，处理器在其中调节对硬件的直接访问和对内存的未授权访问。<br>我们通常将执行模式称为内核空间和用户空间。这些术语不仅包括两种模式中固有的不同权限级别，还包括每种模式可以有自己的内存映射——自己的地址空间——的事实。<br>每当应用程序发出系统调用或被硬件中断挂起时，Unix 都会将执行从用户空间转移到内核空间。执行系统调用的内核代码在进程的上下文中工作——它代表调用进程操作，并能够访问进程地址空间中的数据。另一方面，处理中断的代码与进程是异步的，并且与任何特定进程无关。<br>模块的作用是扩展内核功能；模块化代码在内核空间中运行。通常，驱动程序执行前面概述的两种任务：模块中的一些函数作为系统调用的一部分执行，而另一些则负责中断处理。<br><br>内核编程与传统应用程序编程的一个显著区别是并发性问题。大多数应用程序（除了多线程应用程序）通常按顺序运行，从头到尾，无需担心环境中可能发生的其他事情。内核代码并不运行在如此简单的世界中，即使是最简单的内核模块也必须考虑到许多事情可能同时发生。<br>内核编程中有几个并发源。自然，Linux 系统运行多个进程，其中多个进程可能同时尝试使用你的驱动程序。大多数设备能够中断处理器；中断处理程序异步运行，并且可以在你的驱动程序尝试执行其他操作时被调用。一些软件抽象（如内核定时器，将在第7章介绍）也是异步运行的。此外，Linux 可以在对称多处理器（SMP）系统上运行，结果可能是你的驱动程序在多个 CPU 上并发执行。最后，在2.6内核中，内核代码已被设置为可抢占的；这一变化导致即使是单处理器系统也具有与多处理器系统相同的并发问题。<br>因此，Linux 内核代码（包括驱动程序代码）必须是可重入的——它必须能够在多个上下文中同时运行。数据结构必须精心设计，以保持多个执行线程的分离，代码必须小心访问共享数据，以防止数据损坏。编写处理并发并避免竞争条件（执行顺序不当导致不良行为的情况）的代码需要深思熟虑，并且可能很棘手。正确管理并发是编写正确内核代码的必要条件；因此，本书中的每个示例驱动程序都是在考虑并发性的情况下编写的。我们将在遇到这些技术时进行解释；第5章也专门讨论了这个问题以及可用于并发管理的内核原语。<br>驱动程序程序员常犯的一个错误是假设只要特定代码段不进入睡眠（或“阻塞”），并发就不是问题。即使在以前的内核（不可抢占）中，这种假设在多处理器系统上也是无效的。在2.6内核中，内核代码几乎不能假设它可以在给定的代码段中保持处理器。如果你不编写考虑并发性的代码，它将面临灾难性的失败，这些失败可能非常难以调试。<br><br>尽管内核模块不像应用程序那样按顺序执行，但内核执行的大多数操作都是代表特定进程完成的。内核代码可以通过访问 &lt;asm/current.h&gt; 中定义的全局项 current 来引用当前进程，它返回一个指向 struct task_struct 的指针，该结构由 &lt;linux/sched.h&gt; 定义。current 指针引用当前正在执行的进程。在执行系统调用（如 open 或 read）时，当前进程是调用该调用的进程。内核代码可以通过使用 current 来使用进程特定的信息，如果需要的话。第6章将展示这种技术的示例。<br>实际上，current 并不是真正的全局变量。支持 SMP 系统的需求迫使内核开发人员开发一种机制，以在相关 CPU 上找到当前进程。这种机制还必须快速，因为对 current 的引用频繁发生。结果是一种依赖于体系结构的机制，通常将指向 task_struct 结构的指针隐藏在内核堆栈上。实现的细节对其他内核子系统保持隐藏，设备驱动程序只需包含 &lt;linux/sched.h&gt; 并引用当前进程。例如，以下语句通过访问 struct task_struct 中的某些字段打印当前进程的进程 ID 和命令名称：<br>printk(KERN_INFO "The process is \"%s\" (pid %i)\n",
       current-&gt;comm, current-&gt;pid);
<br>存储在 current-&gt;comm 中的命令名称是当前进程正在执行的程序文件的基本名称（如果需要，则修剪为15个字符）。<br><br>内核编程与用户空间编程在许多方面有所不同。我们将在本书中遇到这些问题时指出，但有一些基本问题虽然不值得单独一节，但值得一提。因此，当你深入研究内核时，应牢记以下问题。<br>应用程序在虚拟内存中布局，具有非常大的堆栈区域。堆栈当然用于保存函数调用历史记录和当前活动函数创建的所有自动变量。相反，内核的堆栈非常小；它可以小到单个4096字节的页面。你的函数必须与整个内核空间调用链共享该堆栈。因此，声明大型自动变量从来都不是一个好主意；如果你需要更大的结构，你应该在调用时动态分配它们。<br>通常，当你查看内核 API 时，你会遇到以双下划线（__）开头的函数名。如此标记的函数通常是接口的低级组件，应谨慎使用。本质上，双下划线对程序员说：“如果你调用这个函数，请确保你知道你在做什么。”<br>内核代码不能进行浮点运算。启用浮点运算将要求内核在每次进入和退出内核空间时保存和恢复浮点处理器的状态——至少在某些架构上是这样。鉴于内核代码中确实不需要浮点运算，额外的开销是不值得的。]]></description><link>第2章-构建和运行模块/2.3-内核模块与应用程序的区别.html</link><guid isPermaLink="false">第2章 构建和运行模块/2.3 内核模块与应用程序的区别.md</guid><pubDate>Tue, 04 Mar 2025 15:58:50 GMT</pubDate></item><item><title><![CDATA[2.4 编译和加载]]></title><description><![CDATA[ 
 <br>本章开头的“hello world”示例简要演示了如何构建模块并将其加载到系统中。当然，整个过程比我们目前看到的要复杂得多。本节将详细介绍模块作者如何将源代码转换为内核中执行的子系统。<br><br>首先，我们需要了解模块的构建过程。模块的构建过程与用户空间应用程序的构建过程有很大不同；内核是一个大型的独立程序，对其各个部分的组合方式有详细而明确的要求。构建过程也与以前的内核版本不同；新的构建系统更易于使用，并且产生更正确的结果，但它看起来与以前大不相同。内核构建系统是一个复杂的野兽，我们只看了其中的一小部分。内核源代码中的 Documentation/kbuild 目录中的文件是任何想要了解表面下真正发生的事情的人的必读材料。<br>在构建内核模块之前，你需要满足一些先决条件。首先是确保你有足够新版本的编译器、模块工具和其他必要工具。内核文档目录中的 Documentation/Changes 文件始终列出了所需的工具版本；在继续之前，你应该查阅它。尝试使用错误的工具版本构建内核（及其模块）可能会导致无数微妙且难以解决的问题。请注意，有时编译器版本过新可能与过旧一样有问题；内核源代码对编译器做了很多假设，新版本有时会暂时破坏一些东西。<br>如果你还没有一个内核树，或者还没有配置和构建该内核，现在是时候去做了。如果没有这个树，你无法为2.6内核构建可加载模块。实际运行你正在构建的内核也很有帮助（尽管不是必需的）。<br>一旦你设置好一切，为你的模块创建一个 makefile 就很简单了。事实上，对于本章前面展示的“hello world”示例，只需一行即可：<br>obj-m := hello.o
<br>熟悉 make 但不熟悉2.6内核构建系统的读者可能会想知道这个 makefile 是如何工作的。毕竟，上面的行看起来不像传统的 makefile。答案当然是内核构建系统处理了其余部分。上面的赋值（利用了 GNU make 提供的扩展语法）声明有一个模块将从目标文件 hello.o 构建。生成的模块在从目标文件构建后命名为 hello.ko。<br>如果你有一个名为 module.ko 的模块，它由两个源文件生成（例如 file1.c 和 file2.c），正确的写法是：<br>obj-m := module.o
module-objs := file1.o file2.o
<br>为了使上述 makefile 正常工作，它必须在更大的内核构建系统的上下文中调用。如果你的内核源代码树位于 ~/kernel-2.6 目录中，构建模块所需的 make 命令（在包含模块源代码和 makefile 的目录中键入）将是：<br>make -C ~/kernel-2.6 M=`pwd` modules
<br>该命令首先使用 -C 选项将其目录更改为提供的目录（即你的内核源代码目录）。在那里，它找到内核的顶级 makefile。M= 选项使该 makefile 在尝试构建 modules 目标之前移回你的模块源代码目录。该目标又引用 obj-m 变量中找到的模块列表，我们在示例中将其设置为 module.o。<br>键入上述 make 命令可能会在一段时间后变得繁琐，因此内核开发人员开发了一种 makefile 惯用语，使那些在内核树之外构建模块的人生活更轻松。诀窍是将你的 makefile 编写如下：<br># 如果定义了 KERNELRELEASE，我们从内核构建系统调用，可以使用它的语言。
ifneq ($(KERNELRELEASE),)
obj-m := hello.o

# 否则我们从命令行直接调用；调用内核构建系统。
else

KERNELDIR ?= /lib/modules/$(shell uname -r)/build
PWD := $(shell pwd)

default:
    $(MAKE) -C $(KERNELDIR) M=$(PWD) modules

endif
<br>我们再次看到扩展的 GNU make 语法在起作用。这个 makefile 在典型的构建中被读取两次。当从命令行调用 makefile 时，它会注意到 KERNELRELEASE 变量尚未设置。它通过利用已安装模块目录中的符号链接 build 指向内核构建树的事实来定位内核源代码目录。如果你没有实际运行你正在构建的内核，你可以在命令行上提供 KERNELDIR= 选项，设置 KERNELDIR 环境变量，或者重写 makefile 中设置 KERNELDIR 的行。一旦找到内核源代码树，makefile 就会调用 default: 目标，该目标运行第二个 make 命令（在 makefile 中参数化为 $(MAKE)）以调用内核构建系统，如前所述。在第二次读取时，makefile 设置 obj-m，内核 makefile 负责实际构建模块。<br>这种构建模块的机制可能会让你觉得有点笨拙和晦涩。然而，一旦你习惯了它，你可能会欣赏内核构建系统中编程的功能。请注意，上面的内容并不是一个完整的 makefile；一个真正的 makefile 通常还包括清理不需要的文件、安装模块等目标。你可以参考示例源代码目录中的 makefile 来查看完整的示例。<br><br>模块构建完成后，下一步就是将其加载到内核中。正如我们已经提到的，insmod 可以帮你完成这个任务。该程序将模块代码和数据加载到内核中，内核随后执行类似于 ld 的功能，将模块中未解析的符号链接到内核的符号表。不过，与链接器不同的是，内核不会修改模块的磁盘文件，而是修改内存中的副本。insmod 接受许多命令行选项（详见手册页），并且它可以在将模块链接到当前内核之前为模块中的参数赋值。因此，如果模块设计正确，它可以在加载时进行配置；加载时配置比编译时配置更灵活，尽管后者有时仍在使用。加载时配置将在本章后面的“模块参数”部分进行解释。<br>感兴趣的读者可能想看看内核如何支持 insmod：它依赖于 kernel/module.c 中定义的系统调用。函数 sys_init_module 分配内核内存来保存模块（该内存使用 vmalloc 分配；详见第8章中的“vmalloc 及其朋友”部分）；然后将模块文本复制到该内存区域，通过内核符号表解析模块中的内核引用，并调用模块的初始化函数以启动一切。<br>如果你查看内核源代码，你会发现系统调用的名称都以 sys_ 为前缀。所有系统调用都是如此，其他函数则没有；在源代码中搜索系统调用时，记住这一点很有用。<br>modprobe 工具值得一提。modprobe 与 insmod 类似，都是将模块加载到内核中。不同之处在于，modprobe 会查看要加载的模块，检查它是否引用了内核中当前未定义的任何符号。如果发现任何此类引用，modprobe 会在当前模块搜索路径中查找定义相关符号的其他模块。当 modprobe 找到这些模块（这些模块是正在加载的模块所需的）时，它也会将它们加载到内核中。如果你在这种情况下使用 insmod，命令将失败，并在系统日志文件中留下“未解析符号”的消息。<br>如前所述，可以使用 rmmod 工具从内核中移除模块。请注意，如果内核认为模块仍在使用中（例如，某个程序仍在使用模块导出的设备打开文件），或者内核配置为不允许模块移除，则模块移除将失败。可以将内核配置为允许“强制”移除模块，即使它们看起来正在使用中。然而，如果你考虑使用此选项，情况可能已经非常糟糕，重启系统可能是更好的选择。<br>lsmod 程序会生成当前加载到内核中的模块列表。它还提供了一些其他信息，例如哪些其他模块正在使用特定模块。lsmod 通过读取 /proc/modules 虚拟文件来工作。当前加载的模块的信息也可以在 sysfs 虚拟文件系统中的 /sys/module 下找到。<br><br>请记住，你的模块代码必须为每个链接的内核版本重新编译——至少在不存在 modversions 的情况下是这样，这里不讨论 modversions，因为它们更多是为发行版制作者准备的。模块与特定内核版本中定义的数据结构和函数原型紧密相关；模块所见的接口可能在不同内核版本之间发生显著变化。当然，这在开发内核中尤为明显。<br>内核不会假设给定的模块是针对正确内核版本构建的。构建过程中的一个步骤是将你的模块链接到当前内核树中的一个文件（称为 vermagic.o）；该对象包含有关模块构建的内核的大量信息，包括目标内核版本、编译器版本以及许多重要配置变量的设置。当尝试加载模块时，可以测试这些信息是否与运行中的内核兼容。如果不匹配，模块将不会被加载；相反，你会看到类似以下的内容：<br># insmod hello.ko
Error inserting './hello.ko': -1 Invalid module format
<br>查看系统日志文件（/var/log/messages 或你的系统配置使用的任何文件）将揭示导致模块加载失败的具体问题。<br>如果你需要为特定内核版本编译模块，你需要使用该特定版本的构建系统和源代码树。只需修改前面示例 makefile 中的 KERNELDIR 变量即可。<br>内核接口经常在版本之间发生变化。如果你正在编写一个旨在与多个内核版本兼容的模块（特别是如果它必须跨主要版本工作），你可能需要使用宏和 #ifdef 结构来使你的代码正确构建。本书的这一版只涉及一个主要版本的内核，因此你在我们的示例代码中不会经常看到版本测试。但有时确实需要它们。在这种情况下，你可以使用 &lt;linux/version.h&gt; 中的定义。该头文件由 &lt;linux/module.h&gt; 自动包含，定义了以下宏：<br>
<br>UTS_RELEASE：该宏扩展为描述此内核树版本的字符串。例如，"2.6.10"。
<br>LINUX_VERSION_CODE：该宏扩展为内核版本的二进制表示，每个版本号部分占一个字节。例如，2.6.10 的代码是 132618（即 0x02060a）。有了这些信息，你可以（几乎）轻松确定你正在处理的内核版本。
<br>KERNEL_VERSION(major,minor,release)：该宏用于从构成版本号的各个数字构建整数版本代码。例如，KERNEL_VERSION(2,6,10) 扩展为 132618。当你需要比较当前版本和已知检查点时，该宏非常有用。
<br>大多数基于内核版本的依赖可以通过使用 KERNEL_VERSION 和 LINUX_VERSION_CODE 的预处理器条件来解决。然而，版本依赖不应使驱动程序代码充满复杂的 #ifdef 条件；处理不兼容性的最佳方法是将它们限制在特定的头文件中。通常，显式依赖于版本（或平台）的代码应隐藏在低级宏或函数后面。高级代码可以调用这些函数，而无需关心低级细节。以这种方式编写的代码往往更易于阅读且更健壮。<br><br>每个计算机平台都有其独特之处，内核设计者可以自由利用所有这些独特之处来实现目标对象文件的最佳性能。<br>与应用程序开发者不同，他们必须将代码与预编译的库链接并遵守参数传递约定，内核开发者可以将某些处理器寄存器专用于特定角色，并且他们已经这样做了。此外，内核代码可以针对 CPU 系列中的特定处理器进行优化，以从目标平台中获得最佳性能：与通常以二进制格式分发的应用程序不同，内核的自定义编译可以针对特定的计算机集进行优化。<br>例如，IA32（x86）架构已被细分为几种不同的处理器类型。旧的 80386 处理器仍然受支持（目前），尽管其指令集按现代标准来看相当有限。该架构中更现代的处理器引入了许多新功能，包括进入内核的更快指令、处理器间锁定、数据复制等。较新的处理器在正确模式下运行时还可以使用 36 位（或更大）的物理地址，使它们能够寻址超过 4 GB 的物理内存。其他处理器系列也看到了类似的改进。根据各种配置选项，内核可以构建为利用这些附加功能。<br>显然，如果模块要与给定的内核一起工作，它必须与内核一样理解目标处理器。再次，vermagic.o 对象文件发挥作用。当加载模块时，内核会检查模块的处理器特定配置选项，并确保它们与运行中的内核匹配。如果模块是用不同的选项编译的，它将不会被加载。<br>如果你计划编写一个用于广泛分发的驱动程序，你可能想知道如何支持所有这些不同的变体。当然，最好的答案是以 GPL 兼容的许可证发布你的驱动程序，并将其贡献给主线内核。如果做不到这一点，以源代码形式分发你的驱动程序以及一组在用户系统上编译它的脚本可能是最佳答案。一些供应商已经发布了使此任务更轻松的工具。如果你必须以二进制形式分发驱动程序，你需要查看目标发行版提供的不同内核，并为每个内核提供一个模块版本。请务必考虑自发行版发布以来可能发布的任何勘误内核。然后，还需要考虑许可问题，正如我们在第1章的“许可条款”部分讨论的那样。通常，以源代码形式分发是更简单的方式。]]></description><link>第2章-构建和运行模块/2.4-编译和加载.html</link><guid isPermaLink="false">第2章 构建和运行模块/2.4 编译和加载.md</guid><pubDate>Tue, 04 Mar 2025 15:58:57 GMT</pubDate></item><item><title><![CDATA[2.5 内核符号表]]></title><description><![CDATA[ 
 <br>我们已经看到 insmod 如何根据公共内核符号表解析未定义的符号。该表包含全局内核项（函数和变量）的地址，这些项是实现模块化驱动程序所需的。当加载模块时，模块导出的任何符号都会成为内核符号表的一部分。在通常情况下，模块实现自己的功能而不需要导出任何符号。然而，当其他模块可能受益于使用它们时，你需要导出符号。<br>新模块可以使用你的模块导出的符号，你可以在其他模块之上堆叠新模块。模块堆叠在主流通用内核源代码中也有实现：msdos 文件系统依赖于 fat 模块导出的符号，每个输入 USB 设备模块堆叠在 usbcore 和 input 模块之上。<br>模块堆叠在复杂项目中非常有用。如果新的抽象以设备驱动程序的形式实现，它可能会为硬件特定的实现提供一个插槽。例如，video-for-linux 驱动程序集分为一个通用模块，该模块导出由特定硬件的低级设备驱动程序使用的符号。根据你的设置，你加载通用视频模块和已安装硬件的特定模块。并行端口和各种可连接设备的支持也以相同的方式处理，USB 内核子系统也是如此。图2-2显示了并行端口子系统中的堆叠；箭头显示了模块之间以及与内核编程接口之间的通信。<br>当使用堆叠模块时，了解 modprobe 实用程序会很有帮助。如前所述，modprobe 的功能与 insmod 类似，但它还会加载你想要的模块所需的任何其他模块。因此，一个 modprobe 命令有时可以替代多次 insmod 调用（尽管当你从当前目录加载自己的模块时，你仍然需要 insmod，因为 modprobe 只查看标准安装的模块目录）。<br>通过将模块拆分为多个层来使用堆叠可以帮助减少开发时间，因为每一层都得到了简化。这类似于我们在第1章中讨论的机制与策略的分离。<br>Linux 内核头文件提供了一种方便的方式来管理符号的可见性，从而减少命名空间污染（用可能与其他地方定义的名称冲突的名称填充命名空间）并促进正确的信息隐藏。如果你的模块需要导出符号供其他模块使用，应使用以下宏：<br>EXPORT_SYMBOL(name);
EXPORT_SYMBOL_GPL(name);
<br>上述任一宏使给定符号在模块外部可用。GPL 版本仅使符号对 GPL 许可的模块可用。符号必须在模块文件的全局部分中导出，在任何函数之外，因为这些宏扩展为特殊用途变量的声明，该变量预期在全局范围内可访问。该变量存储在模块可执行文件的一个特殊部分（“ELF 部分”）中，内核在加载时使用该部分来查找模块导出的变量。（感兴趣的读者可以查看 &lt;linux/module.h&gt; 以了解详细信息，尽管这些细节不需要使事情正常工作。）]]></description><link>第2章-构建和运行模块/2.5-内核符号表.html</link><guid isPermaLink="false">第2章 构建和运行模块/2.5 内核符号表.md</guid><pubDate>Tue, 04 Mar 2025 15:59:06 GMT</pubDate></item><item><title><![CDATA[2.6 准备工作]]></title><description><![CDATA[ 
 <br>我们即将查看一些实际的模块代码。但首先，我们需要查看一些其他需要在模块源文件中出现的内容。内核是一个独特的环境，它对与其交互的代码提出了自己的要求。<br>大多数内核代码最终会包含相当多的头文件，以获取函数、数据类型和变量的定义。我们将在遇到这些文件时进行讨论，但有一些特定于模块的文件，必须出现在每个可加载模块中。因此，几乎所有模块代码都有以下内容：<br>#include &lt;linux/module.h&gt;
#include &lt;linux/init.h&gt;
<br>module.h 包含许多可加载模块所需的符号和函数的定义。你需要 init.h 来指定初始化和清理函数，正如我们在“hello world”示例中看到的那样，我们将在下一节中重新讨论。大多数模块还包括 moduleparam.h，以便在加载时向模块传递参数；我们稍后会讨论这一点。<br>虽然不是严格必要的，但你的模块确实应该指定适用于其代码的许可证。只需包含一行 MODULE_LICENSE 即可：<br>MODULE_LICENSE("GPL");
<br>内核识别的特定许可证包括“GPL”（适用于任何版本的 GNU 通用公共许可证）、“GPL v2”（仅适用于 GPL 第二版）、“GPL 及附加权利”、“Dual BSD/GPL”、“Dual MPL/GPL”和“Proprietary”。除非你的模块明确标记为内核认可的自由许可证，否则它被视为专有模块，加载模块时内核会被“污染”。正如我们在第1章的“许可条款”部分提到的，内核开发者通常对帮助加载专有模块后遇到问题的用户不太热心。<br>其他可以包含在模块中的描述性定义包括 MODULE_AUTHOR（声明谁编写了模块）、MODULE_DESCRIPTION（模块功能的可读描述）、MODULE_VERSION（代码修订号；请参阅 &lt;linux/module.h&gt; 中的注释以了解创建版本字符串的约定）、MODULE_ALIAS（模块的另一个名称）和 MODULE_DEVICE_TABLE（告诉用户空间模块支持哪些设备）。我们将在第11章讨论 MODULE_ALIAS，在第12章讨论 MODULE_DEVICE_TABLE。<br>各种 MODULE_ 声明可以出现在源文件中函数之外的任何位置。然而，内核代码中相对较新的约定是将这些声明放在文件末尾。]]></description><link>第2章-构建和运行模块/2.6-准备工作.html</link><guid isPermaLink="false">第2章 构建和运行模块/2.6 准备工作.md</guid><pubDate>Tue, 04 Mar 2025 15:59:16 GMT</pubDate></item><item><title><![CDATA[2.7 初始化和关闭]]></title><description><![CDATA[ 
 <br>如前所述，模块初始化函数注册模块提供的任何功能。所谓功能，我们指的是新的功能，无论是整个驱动程序还是新的软件抽象，应用程序都可以访问。初始化函数的实际定义通常如下所示：<br>static int __init initialization_function(void)
{
    /* 初始化代码 */
}
module_init(initialization_function);
<br>初始化函数应声明为 static，因为它们不应在特定文件之外可见；虽然没有硬性规定，但没有函数会被显式导出到内核的其余部分。定义中的 __init 标记可能看起来有点奇怪；它是对内核的提示，表明给定的函数仅在初始化时使用。模块加载器在模块加载后丢弃初始化函数，使其内存可用于其他用途。对于仅在初始化期间使用的数据，也有类似的标记（__initdata）。使用 __init 和 __initdata 是可选的，但值得这样做。只需确保不要将它们用于初始化完成后将使用的任何函数（或数据结构）。你可能还会在内核源代码中遇到 __devinit 和 __devinitdata；这些仅在未配置为支持热插拔设备时转换为 __init 和 __initdata。我们将在第14章讨论热插拔支持。<br>使用 module_init 是强制性的。此宏将模块的目标代码中添加一个特殊部分，声明模块的初始化函数的位置。如果没有此定义，你的初始化函数将永远不会被调用。<br>模块可以注册许多不同类型的设施，包括不同类型的设备、文件系统、加密转换等。对于每种设施，都有一个特定的内核函数来完成此注册。传递给内核注册函数的参数通常是指向描述新设施的数据结构的指针和正在注册的设施的名称。数据结构通常包含指向模块函数的指针，这就是模块体中的函数如何被调用的方式。<br>可以注册的项目超出了第1章中提到的设备类型列表。它们包括串行端口、杂项设备、sysfs 条目、/proc 文件、可执行域和线路规程等。其中许多可注册项目支持的功能与硬件没有直接关系，但仍属于“软件抽象”领域。这些项目可以注册，因为它们无论如何都集成到驱动程序的功能中（例如 /proc 文件和线路规程）。<br>还有一些设施可以作为某些驱动程序的附加组件注册，但它们的使用非常特定，不值得讨论；它们使用堆叠技术，如“内核符号表”部分所述。如果你想进一步探索，可以在内核源代码中搜索 EXPORT_SYMBOL，并找到不同驱动程序提供的入口点。大多数注册函数都以 register_ 为前缀，因此另一种可能的查找方法是搜索内核源代码中的 register_。<br><br>每个非平凡的模块还需要一个清理函数，该函数在模块移除之前注销接口并将所有资源返回给系统。此函数定义如下：<br>static void __exit cleanup_function(void)
{
    /* 清理代码 */
}
module_exit(cleanup_function);
<br>清理函数没有返回值，因此声明为 void。__exit 修饰符将代码标记为仅用于模块卸载（通过使编译器将其放置在特殊的 ELF 部分中）。如果你的模块直接构建到内核中，或者如果你的内核配置为不允许卸载模块，标记为 __exit 的函数将被简单地丢弃。因此，标记为 __exit 的函数只能在模块卸载或系统关闭时调用；任何其他使用都是错误的。同样，module_exit 声明是必要的，以使内核能够找到你的清理函数。<br>如果你的模块没有定义清理函数，内核将不允许它被卸载。<br><br>在向内核注册设施时，你必须始终记住注册可能会失败。即使是最简单的操作通常也需要内存分配，而所需的内存可能不可用。因此，模块代码必须始终检查返回值，并确保请求的操作实际成功。<br>如果在注册实用程序时发生任何错误，首要任务是决定模块是否可以继续初始化。通常，模块可以在注册失败后继续运行，必要时功能会有所降低。只要有可能，你的模块应在失败后继续前进，并提供它能够提供的功能。<br>如果事实证明你的模块在特定类型的失败后根本无法加载，你必须撤销在失败之前执行的任何注册活动。Linux 不会保留每个模块已注册设施的注册表，因此如果初始化在某个时刻失败，模块必须自行撤销所有操作。如果你未能注销你获得的内容，内核将处于不稳定状态；它包含指向不再存在的代码的内部指针。在这种情况下，通常唯一的办法是重新启动系统。你真的希望在发生初始化错误时小心处理。<br>错误恢复有时最好使用 goto 语句处理。我们通常不喜欢使用 goto，但在我们看来，这是它有用的一种情况。在错误情况下谨慎使用 goto 可以消除大量复杂的、高度缩进的“结构化”逻辑。因此，在内核中，goto 经常用于处理错误，如下所示。<br>以下示例代码（使用虚构的注册和注销函数）在初始化在任何时刻失败时表现正确：<br>int __init my_init_function(void)
{
    int err;

    /* 注册需要一个指针和一个名称 */
    err = register_this(ptr1, "skull");
    if (err) goto fail_this;
    err = register_that(ptr2, "skull");
    if (err) goto fail_that;
    err = register_those(ptr3, "skull");
    if (err) goto fail_those;

    return 0; /* 成功 */

fail_those: unregister_that(ptr2, "skull");
fail_that: unregister_this(ptr1, "skull");
fail_this: return err; /* 传播错误 */
}
<br>此代码尝试注册三个（虚构的）设施。goto 语句在失败时用于仅注销在出现问题之前已成功注册的设施。<br>另一种不需要复杂的 goto 语句的选项是跟踪已成功注册的内容，并在发生任何错误时调用模块的清理函数。清理函数仅撤销已成功完成的步骤。然而，这种替代方案需要更多的代码和更多的 CPU 时间，因此在快速路径中你仍然会使用 goto 作为最佳的错误恢复工具。<br>my_init_function 的返回值 err 是一个错误代码。在 Linux 内核中，错误代码是负数，属于 &lt;linux/errno.h&gt; 中定义的集合。如果你想生成自己的错误代码，而不是返回从其他函数获得的值，你应该包含 &lt;linux/errno.h&gt;，以便使用诸如 -ENODEV、-ENOMEM 等符号值。返回适当的错误代码始终是一个好习惯，因为用户程序可以使用 perror 或类似方法将其转换为有意义的字符串。<br>显然，模块的清理函数必须撤销初始化函数执行的任何注册操作，通常（但不总是强制性的）以与注册顺序相反的顺序注销设施：<br>void __exit my_cleanup_function(void)
{
    unregister_those(ptr3, "skull");
    unregister_that(ptr2, "skull");
    unregister_this(ptr1, "skull");
    return;
}
<br>如果你的初始化和清理比处理几个项目更复杂，goto 方法可能会变得难以管理，因为所有清理代码必须在初始化函数中重复，并混合多个标签。因此，有时不同的代码布局会更为成功。<br>为了最小化代码重复并保持一切简洁，你可以在发生错误时从初始化函数中调用清理函数。然后，清理函数必须在撤销注册之前检查每个项目的状态。在最简单的形式中，代码如下所示：<br>struct something *item1;
struct somethingelse *item2;
int stuff_ok;

void my_cleanup(void)
{
    if (item1)
        release_thing(item1);
    if (item2)
        release_thing2(item2);
    if (stuff_ok)
        unregister_stuff();
    return;
}

int __init my_init(void)
{
    int err = -ENOMEM;

    item1 = allocate_thing(arguments);
    item2 = allocate_thing2(arguments2);
    if (!item1 || !item2)
        goto fail;
    err = register_stuff(item1, item2);
    if (!err)
        stuff_ok = 1;
    else
        goto fail;
    return 0; /* 成功 */

fail:
    my_cleanup();
    return err;
}
<br>如这段代码所示，你可能需要外部标志来标记初始化步骤的成功，具体取决于你调用的注册/分配函数的语义。无论是否需要标志，这种初始化方式都可以很好地扩展到大量项目，并且通常比前面展示的技术更好。请注意，当清理函数被非退出代码调用时（如前面的示例），它不能标记为 __exit。<br><br>到目前为止，我们的讨论忽略了一个重要的模块加载问题：竞争条件。如果你不小心编写初始化函数，可能会创建危及整个系统稳定性的情况。我们将在本书后面讨论竞争条件；现在，几个要点就足够了。<br>首先，你应该始终记住，内核的其他部分可以在你注册任何设施后立即使用它。换句话说，内核可能会在你的初始化函数仍在运行时调用你的模块。因此，你的代码必须准备好在完成第一次注册后立即被调用。在支持该设施所需的所有内部初始化完成之前，不要注册任何设施。<br>你还必须考虑如果你的初始化函数决定失败，但内核的某些部分已经在使用你的模块注册的设施时会发生什么。如果这种情况对你的模块是可能的，你应该认真考虑根本不使初始化失败。毕竟，模块显然已经成功导出了有用的东西。如果初始化必须失败，它必须小心地绕过内核中可能正在进行的任何操作，直到这些操作完成。]]></description><link>第2章-构建和运行模块/2.7-初始化和关闭.html</link><guid isPermaLink="false">第2章 构建和运行模块/2.7 初始化和关闭.md</guid><pubDate>Tue, 04 Mar 2025 15:59:26 GMT</pubDate></item><item><title><![CDATA[2.8 模块参数]]></title><description><![CDATA[ 
 <br>驱动程序需要知道的几个参数可能因系统而异。这些参数可以从使用的设备号（我们将在下一章看到）到驱动程序应如何操作的许多方面。例如，SCSI 适配器的驱动程序通常具有控制标记命令队列使用的选项，而 IDE 驱动程序允许用户控制 DMA 操作。如果你的驱动程序控制较旧的硬件，它可能还需要明确告知在哪里找到该硬件的 I/O 端口或 I/O 内存地址。内核通过使驱动程序能够指定在加载驱动程序的模块时可以更改的参数来支持这些需求。<br>这些参数值可以在加载时由 insmod 或 modprobe 分配；后者还可以从其配置文件（/etc/modprobe.conf）中读取参数分配。这些命令接受在命令行上指定几种类型的值。为了演示此功能，想象一下对本章开头的“hello world”模块（称为 hellop）进行了一个非常需要的增强。我们添加了两个参数：一个名为 howmany 的整数值和一个名为 whom 的字符串。我们的功能更强大的模块在加载时不仅向 whom 问候一次，而是 howmany 次。这样的模块可以通过以下命令行加载：<br>insmod hellop howmany=10 whom="Mom"
<br>以这种方式加载后，hellop 会说“Hello, Mom” 10 次。<br>然而，在 insmod 可以更改模块参数之前，模块必须使它们可用。参数使用 module_param 宏声明，该宏在 moduleparam.h 中定义。module_param 接受三个参数：变量的名称、其类型和用于伴随的 sysfs 条目的权限掩码。该宏应放在任何函数之外，通常位于源文件的顶部。因此，hellop 将声明其参数并使它们对 insmod 可用，如下所示：<br>static char *whom = "world";
static int howmany = 1;
module_param(howmany, int, S_IRUGO);
module_param(whom, charp, S_IRUGO);
<br>支持多种类型的模块参数：<br>
<br>bool 和 invbool：布尔值（真或假），相关变量应为 int 类型。invbool 类型反转值，使真值变为假，反之亦然。
<br>charp：字符指针值。为用户提供的字符串分配内存，并相应地设置指针。
<br>int、long、short、uint、ulong、ushort：各种长度的基本整数值。以 u 开头的版本用于无符号值。
<br>模块加载器还支持数组参数，其中值以逗号分隔的列表形式提供。要声明数组参数，请使用：<br>module_param_array(name, type, num, perm);
<br>其中 name 是数组（和参数）的名称，type 是数组元素的类型，num 是一个整数变量，perm 是通常的权限值。如果在加载时设置了数组参数，num 将设置为提供的值的数量。模块加载器拒绝接受超过数组容量的值。<br>如果你确实需要一个不在上述列表中的类型，模块代码中有钩子允许你定义它们；有关如何执行此操作的详细信息，请参阅 moduleparam.h。所有模块参数都应提供默认值；insmod 仅在用户明确告知时更改值。模块可以通过将参数与其默认值进行比较来检查显式参数。<br>module_param 的最后一个字段是权限值；你应该使用 &lt;linux/stat.h&gt; 中找到的定义。此值控制谁可以访问 sysfs 中模块参数的表示。如果 perm 设置为 0，则根本没有 sysfs 条目；否则，它出现在 /sys/module 下，并具有给定的权限集。使用 S_IRUGO 表示可以被所有人读取但不能更改的参数；S_IRUGO|S_IWUSR 允许 root 更改参数。请注意，如果 sysfs 更改了参数，模块看到的该参数的值会更改，但模块不会以任何其他方式收到通知。除非你准备检测更改并做出相应反应，否则你可能不应使模块参数可写。]]></description><link>第2章-构建和运行模块/2.8-模块参数.html</link><guid isPermaLink="false">第2章 构建和运行模块/2.8 模块参数.md</guid><pubDate>Tue, 04 Mar 2025 15:59:34 GMT</pubDate></item><item><title><![CDATA[2.9 在用户空间中进行操作]]></title><description><![CDATA[ 
 <br>第一次处理内核问题的 Unix 程序员可能会对编写模块感到紧张。编写一个直接读取和写入设备端口的用户程序可能更容易。<br>实际上，用户空间编程有一些优点，有时编写所谓的用户空间设备驱动程序是内核编程的明智替代方案。在本节中，我们讨论你可能在用户空间编写驱动程序的一些原因。然而，本书是关于内核空间驱动程序的，因此我们不会超出此介绍性讨论。<br>用户空间驱动程序的优点包括：<br>
<br>可以链接完整的 C 库。驱动程序可以执行许多复杂的任务，而无需依赖外部程序（通常与驱动程序一起分发的实现使用策略的实用程序）。
<br>程序员可以在驱动程序代码上运行传统的调试器，而无需费心调试运行中的内核。
<br>如果用户空间驱动程序挂起，你可以简单地杀死它。驱动程序的问题不太可能导致整个系统挂起，除非被控制的硬件确实出现问题。
<br>用户内存是可交换的，而内核内存则不是。一个不常使用的设备及其庞大的驱动程序不会占用其他程序可以使用的 RAM，除非它实际在使用中。
<br>设计良好的驱动程序程序仍然可以像内核空间驱动程序一样，允许对设备的并发访问。
<br>如果你必须编写闭源驱动程序，用户空间选项使你更容易避免模糊的许可情况和不断变化的内核接口问题。
<br>例如，USB 驱动程序可以在用户空间编写；请参阅（仍然年轻的）libusb 项目（libusb.sourceforge.net）和内核源代码中的“gadgetfs”。另一个例子是 X 服务器：它确切地知道硬件可以做什么和不能做什么，并向所有 X 客户端提供图形资源。然而，请注意，有一种缓慢但稳定的趋势是向基于帧缓冲区的图形环境发展，其中 X 服务器仅作为基于实际内核空间设备驱动程序的服务器进行实际图形操作。<br>通常，用户空间驱动程序的编写者会实现一个服务器进程，从内核接管硬件控制的单一代理任务。然后，客户端应用程序可以连接到服务器以执行与设备的实际通信；因此，智能驱动程序进程可以允许对设备的并发访问。这正是 X 服务器的工作方式。<br>但用户空间设备驱动程序方法也有一些缺点。最重要的是：<br>
<br>用户空间中没有中断。在某些平台上，有一些解决方法可以解决此限制，例如 IA32 架构上的 vm86 系统调用。
<br>只有通过 mmap 映射 /dev/mem 才能直接访问内存，并且只有特权用户可以这样做。
<br>只有在调用 ioperm 或 iopl 后才能访问 I/O 端口。此外，并非所有平台都支持这些系统调用，并且访问 /dev/port 可能太慢而无法有效。系统调用和设备文件都保留给特权用户。
<br>响应时间较慢，因为需要在客户端和硬件之间传输信息或操作时进行上下文切换。
<br>更糟糕的是，如果驱动程序被交换到磁盘，响应时间会不可接受地长。使用 mlock 系统调用可能会有所帮助，但通常你需要锁定许多内存页，因为用户空间程序依赖于大量库代码。mlock 也仅限于特权用户。
<br>最重要的设备无法在用户空间处理，包括但不限于网络接口和块设备。
<br>如你所见，用户空间驱动程序毕竟不能做那么多。然而，仍然存在一些有趣的应用：例如，支持 SCSI 扫描仪设备（由 SANE 包实现）和 CD 刻录机（由 cdrecord 和其他工具实现）。在这两种情况下，用户级设备驱动程序依赖于“SCSI 通用”内核驱动程序，该驱动程序将低级 SCSI 功能导出到用户空间程序，以便它们可以驱动自己的硬件。<br>当你开始处理新的和不寻常的硬件时，在用户空间工作可能是有意义的。这样，你可以在不冒挂起整个系统风险的情况下学习管理你的硬件。一旦你做到了这一点，将软件封装在内核模块中应该是一个轻松的操作。]]></description><link>第2章-构建和运行模块/2.9-在用户空间中进行操作.html</link><guid isPermaLink="false">第2章 构建和运行模块/2.9 在用户空间中进行操作.md</guid><pubDate>Tue, 04 Mar 2025 15:59:46 GMT</pubDate></item><item><title><![CDATA[2.10 快速参考]]></title><description><![CDATA[ 
 <br>本节总结了我们在本章中提到的内核函数、变量、宏和 /proc 文件。它旨在作为参考。每个项目在相关头文件（如果有）之后列出。从本章开始，几乎每章末尾都有一个类似的章节，总结了本章中引入的新符号。本节中的条目通常按照它们在章节中引入的顺序出现：<br>
<br>insmod、modprobe、rmmod：用户空间实用程序，用于将模块加载到运行中的内核并移除它们。
<br>#include &lt;linux/init.h&gt;、module_init(init_function)、module_exit(cleanup_function)：宏，用于指定模块的初始化和清理函数。
<br>__init、__initdata、__exit、__exitdata：标记仅用于模块初始化或清理时间的函数（__init 和 __exit）和数据（__initdata 和 __exitdata）。标记为初始化的项在初始化完成后可能会被丢弃；退出项在未配置模块卸载到内核时可能会被丢弃。这些标记通过将相关对象放置在可执行文件中的特殊 ELF 部分中来工作。
<br>#include &lt;linux/sched.h&gt;：最重要的头文件之一。该文件包含驱动程序使用的许多内核 API 的定义，包括睡眠函数和众多变量声明。
<br>struct task_struct *current：当前进程。
<br>current-&gt;pid、current-&gt;comm：当前进程的进程 ID 和命令名称。
<br>obj-m：内核构建系统使用的 makefile 符号，用于确定应在当前目录中构建哪些模块。
<br>/sys/module、/proc/modules：/sys/module 是一个 sysfs 目录层次结构，包含有关当前加载模块的信息。/proc/modules 是该信息的较旧的单文件版本。条目包含模块名称、每个模块占用的内存量和使用计数。附加到每行的额外字符串指定当前对模块有效的标志。
<br>vermagic.o：来自内核源目录的对象文件，描述模块构建的环境。
<br>#include &lt;linux/module.h&gt;：必需的头文件。模块源必须包含它。
<br>#include &lt;linux/version.h&gt;：包含有关正在构建的内核版本信息的头文件。
<br>LINUX_VERSION_CODE：整数宏，用于 #ifdef 版本依赖。
<br>EXPORT_SYMBOL(symbol)、EXPORT_SYMBOL_GPL(symbol)：用于将符号导出到内核的宏。第二种形式导出时不使用版本信息，第三种形式将导出限制为 GPL 许可的模块。
<br>MODULE_AUTHOR(author)、MODULE_DESCRIPTION(description)、MODULE_VERSION(version_string)、MODULE_DEVICE_TABLE(table_info)、MODULE_ALIAS(alternate_name)：将模块的文档放置在目标文件中。
<br>module_init(init_function)、module_exit(exit_function)：声明模块初始化和清理函数的宏。
<br>#include &lt;linux/moduleparam.h&gt;、module_param(variable, type, perm)：创建模块参数的宏，用户可以在加载模块时（或内置代码的启动时）调整该参数。类型可以是 bool、charp、int、invbool、long、short、ushort、uint、ulong 或 intarray 之一。
<br>#include &lt;linux/kernel.h&gt;、int printk(const char *fmt, ...)：内核代码中 printf 的类似物。
<br><br><br>本章介绍了如何构建和运行 Linux 内核模块，涵盖了从简单的“hello world”模块到模块参数、错误处理和并发性等高级主题。通过理解这些基本概念，你可以开始编写更复杂的内核模块，并逐步掌握 Linux 设备驱动开发的精髓。在接下来的章节中，我们将深入探讨特定设备类别的驱动程序开发，并进一步扩展这些基础知识。]]></description><link>第2章-构建和运行模块/2.10-快速参考.html</link><guid isPermaLink="false">第2章 构建和运行模块/2.10 快速参考.md</guid><pubDate>Tue, 04 Mar 2025 15:59:55 GMT</pubDate></item><item><title><![CDATA[3.0 字符设备驱动]]></title><description><![CDATA[ 
 <br>本章的目标是编写一个完整的字符设备驱动程序。我们选择开发字符设备驱动，因为这类驱动适合大多数简单的硬件设备。相比于块设备驱动或网络驱动（我们将在后续章节中讨论），字符设备驱动更容易理解。我们的最终目标是编写一个模块化的字符设备驱动，但本章不会讨论模块化的问题。<br>在本章中，我们将展示从实际设备驱动中提取的代码片段：scull（Simple Character Utility for Loading Localities）。scull 是一个字符设备驱动，它操作的内存区域就像操作设备一样。由于 scull 的这一特性，我们在本章中将“设备”与“scull 使用的内存区域”互换使用。<br>scull 的优势在于它不依赖于硬件。scull 只是操作从内核分配的一些内存。任何人都可以编译和运行 scull，并且 scull 可以在 Linux 运行的所有计算机体系结构上移植。另一方面，除了演示内核与字符驱动之间的接口并允许用户运行一些测试外，scull 并没有做任何“有用”的事情。]]></description><link>第3章-字符设备驱动/3.0-字符设备驱动.html</link><guid isPermaLink="false">第3章 字符设备驱动/3.0 字符设备驱动.md</guid><pubDate>Tue, 04 Mar 2025 16:00:23 GMT</pubDate></item><item><title><![CDATA[3.1 scull 的设计]]></title><description><![CDATA[ 
 <br>编写驱动的第一步是定义驱动将向用户程序提供的功能（机制）。由于我们的“设备”是计算机内存的一部分，我们可以自由地对其进行操作。它可以是一个顺序访问设备或随机访问设备，可以是一个设备或多个设备，等等。<br>为了使 scull 成为编写真实设备驱动的模板，我们将展示如何在计算机内存上实现几种设备抽象，每种抽象都有不同的特性。<br>scull 源代码实现了以下设备。模块实现的每种设备类型被称为一种类型。<br>
<br>
scull0 到 scull3：四个设备，每个设备由一个全局且持久的内存区域组成。全局意味着如果设备被多次打开，设备中包含的数据将被所有打开它的文件描述符共享。持久意味着如果设备被关闭并重新打开，数据不会丢失。这个设备可以很有趣地使用，因为它可以使用常规命令（如 cp、cat 和 shell I/O 重定向）进行访问和测试。

<br>
scullpipe0 到 scullpipe3：四个 FIFO（先进先出）设备，它们的行为类似于管道。一个进程读取另一个进程写入的内容。如果多个进程读取同一设备，它们将竞争数据。scullpipe 的内部实现展示了如何在不使用中断的情况下实现阻塞和非阻塞的读写操作。尽管真实驱动通常使用硬件中断与设备同步，但阻塞和非阻塞操作是一个重要的话题，与中断处理（第10章讨论）是分开的。

<br>
scullsingle、scullpriv、sculluid、scullwuid：这些设备与 scull0 类似，但在打开时有一些限制。第一个（scullsingle）只允许一个进程使用驱动，而 scullpriv 对每个虚拟控制台（或 X 终端会话）是私有的，因为每个控制台/终端上的进程获得不同的内存区域。sculluid 和 scullwuid 可以被多次打开，但每次只能由一个用户打开；前者在另一个用户锁定设备时返回“设备忙”错误，而后者实现阻塞打开。这些 scull 的变体似乎混淆了策略和机制，但它们值得一看，因为一些现实生活中的设备需要这种管理。

<br>每个 scull 设备展示了驱动的不同特性，并提出了不同的挑战。本章涵盖了 scull0 到 scull3 的内部实现；更高级的设备将在第6章中讨论。scullpipe 在“阻塞 I/O 示例”部分中描述，其他设备在“设备文件的访问控制”部分中描述。]]></description><link>第3章-字符设备驱动/3.1-scull-的设计.html</link><guid isPermaLink="false">第3章 字符设备驱动/3.1 scull 的设计.md</guid><pubDate>Tue, 04 Mar 2025 16:00:53 GMT</pubDate></item><item><title><![CDATA[3.2 主设备号和次设备号]]></title><description><![CDATA[ 
 <br>字符设备通过文件系统中的名称进行访问。这些名称称为特殊文件或设备文件，或简称为文件系统树的节点；它们通常位于 /dev 目录中。字符设备的特殊文件在 ls -l 输出的第一列中用“c”标识。块设备也出现在 /dev 中，但它们用“b”标识。本章的重点是字符设备，但以下大部分信息也适用于块设备。<br>如果你执行 ls -l 命令，你会在设备文件条目中看到两个数字（用逗号分隔），位于最后修改日期之前，通常显示文件长度的位置。这些数字是特定设备的主设备号和次设备号。以下列表显示了典型系统上的几个设备。它们的主设备号是 1、4、7 和 10，而次设备号是 1、3、5、64、65 和 129。<br>传统上，主设备号标识与设备关联的驱动。例如，/dev/null 和 /dev/zero 都由驱动 1 管理，而虚拟控制台和串行终端由驱动 4 管理；同样，vcs1 和 vcsa1 设备都由驱动 7 管理。现代 Linux 内核允许多个驱动共享主设备号，但你看到的大多数设备仍然遵循“一个主设备号对应一个驱动”的原则。<br>次设备号由内核用来确定具体引用的是哪个设备。根据驱动的编写方式（我们将在下面看到），你可以直接从内核获取设备的指针，或者你可以使用次设备号作为本地设备数组的索引。无论哪种方式，内核本身对次设备号几乎一无所知，只知道它们引用的是由你的驱动实现的设备。<br><br>在内核中，dev_t 类型（定义在 &lt;linux/types.h&gt; 中）用于保存设备号——包括主设备号和次设备号。从内核版本 2.6.0 开始，dev_t 是一个 32 位的量，其中 12 位用于主设备号，20 位用于次设备号。当然，你的代码不应该对设备号的内部组织做任何假设；相反，它应该使用 &lt;linux/kdev_t.h&gt; 中定义的一组宏。要获取 dev_t 的主设备号或次设备号，请使用：<br>MAJOR(dev_t dev);
MINOR(dev_t dev);
<br>如果你有主设备号和次设备号，并需要将它们转换为 dev_t，请使用：<br>MKDEV(int major, int minor);
<br>请注意，2.6 内核可以容纳大量设备，而以前的内核版本仅限于 255 个主设备号和 255 个次设备号。人们假设更宽的范围将在相当长的时间内足够使用，但计算领域充满了这种性质的错误假设。因此，你应该预期 dev_t 的格式可能会在未来再次改变；如果你小心编写驱动，这些变化不会成为问题。<br><br>设置字符设备时，驱动需要做的第一件事是获取一个或多个设备号。完成此任务的必要函数是 register_chrdev_region，它声明在 &lt;linux/fs.h&gt; 中：<br>int register_chrdev_region(dev_t first, unsigned int count, char *name);
<br>在这里，first 是你希望分配的设备号范围的起始设备号。first 的次设备号部分通常为 0，但没有硬性要求。count 是你请求的连续设备号的总数。请注意，如果 count 很大，你请求的范围可能会溢出到下一个主设备号；但只要请求的设备号范围可用，一切仍将正常工作。最后，name 是与该设备号范围关联的设备名称；它将出现在 /proc/devices 和 sysfs 中。<br>与大多数内核函数一样，如果分配成功，register_chrdev_region 的返回值为 0。如果出错，将返回一个负的错误代码，你将无法访问请求的区域。<br>register_chrdev_region 在你提前知道要使用的设备号时效果很好。然而，通常你不会知道设备将使用哪个主设备号；Linux 内核开发社区一直在努力转向使用动态分配的设备号。内核可以动态为你分配一个主设备号，但你必须通过使用不同的函数来请求此分配：<br>int alloc_chrdev_region(dev_t *dev, unsigned int firstminor, unsigned int count, char *name);
<br>使用此函数时，dev 是一个仅输出的参数，在成功完成后，它将保存你分配的范围中的第一个设备号。firstminor 应该是要使用的第一个次设备号；通常为 0。count 和 name 参数与传递给 register_chrdev_region 的参数相同。<br>无论你如何分配设备号，当它们不再使用时，你都应该释放它们。设备号通过以下函数释放：<br>void unregister_chrdev_region(dev_t first, unsigned int count);
<br>通常，unregister_chrdev_region 的调用位置是在模块的清理函数中。<br><br>一些主设备号被静态分配给最常见的设备。这些设备的列表可以在内核源代码树的 Documentation/devices.txt 中找到。然而，静态分配的主设备号已经被分配给你的新驱动的可能性很小，而且新的号码不再被分配。因此，作为驱动编写者，你有两个选择：你可以简单地选择一个看起来未使用的号码，或者你可以以动态方式分配主设备号。选择一个号码可能在你自己是驱动的唯一用户时有效；一旦你的驱动被广泛部署，随机选择的主设备号将导致冲突和麻烦。<br>因此，对于新驱动，我们强烈建议你使用动态分配来获取主设备号，而不是从当前空闲的号码中随机选择一个。换句话说，你的驱动几乎肯定应该使用 alloc_chrdev_region 而不是 register_chrdev_region。<br>动态分配的缺点是，你无法提前创建设备节点，因为分配给模块的主设备号会变化。对于驱动的正常使用来说，这几乎不是问题，因为一旦分配了号码，你可以从 /proc/devices 中读取它。<br>要加载使用动态主设备号的驱动，可以使用一个简单的脚本来替换 insmod 的调用，该脚本在调用 insmod 后读取 /proc/devices 以创建设备文件。<br>一个典型的 /proc/devices 文件如下所示：<br>Character devices:
  1 mem
  2 pty
  3 ttyp
  4 ttyS
  6 lp
  7 vcs
 10 misc
 13 input
 14 sound
 21 sg
180 usb

Block devices:
  2 fd
  8 sd
 11 sr
 65 sd
 66 sd
<br>因此，加载已分配动态号码的模块的脚本可以使用 awk 等工具从 /proc/devices 中检索信息，以在 /dev 中创建设备文件。<br>以下脚本 scull_load 是 scull 发行版的一部分。以模块形式分发的驱动的用户可以从系统的 rc.load 文件中调用此脚本，或在需要模块时手动调用它。<br>#!/bin/sh
module="scull"
device="scull"
mode="664"
# 使用我们得到的所有参数调用 insmod
# 并使用路径名，因为较新的 modutils 默认不在当前目录中查找
/sbin/insmod ./$module.ko $* || exit 1
# 删除旧的设备节点
rm -f /dev/${device}[0-3]
major=$(awk '$2=="$module" {print $1}' /proc/devices)
mknod /dev/${device}0 c $major 0
mknod /dev/${device}1 c $major 1
mknod /dev/${device}2 c $major 2
mknod /dev/${device}3 c $major 3
# 设置适当的组/权限，并更改组。
# 并非所有发行版都有 staff 组，有些使用 "wheel" 代替。
group="staff"
grep -q '^staff:' /etc/group || group="wheel"
chgrp $group /dev/${device}[0-3]
chmod $mode /dev/${device}[0-3]
<br>可以通过重新定义变量并调整 mknod 行来为其他驱动调整此脚本。上面显示的脚本创建了四个设备，因为 scull 源代码中默认有四个设备。<br>脚本的最后几行可能看起来有些晦涩：为什么要更改设备的组和权限？原因是脚本必须以超级用户身份运行，因此新创建的特殊文件归 root 所有。默认的权限位使得只有 root 具有写访问权限，而任何人都可以获得读访问权限。通常，设备节点需要不同的访问策略，因此必须以某种方式更改访问权限。在我们的脚本中，默认是给一组用户访问权限，但你的需求可能不同。在第6章的“设备文件的访问控制”部分中，sculluid 的代码展示了驱动如何强制执行自己的设备访问授权。<br>scull_unload 脚本也可用于清理 /dev 目录并删除模块。<br>作为使用一对脚本进行加载和卸载的替代方案，你可以编写一个 init 脚本，准备放置在你的发行版用于这些脚本的目录中。作为 scull 源代码的一部分，我们提供了一个相当完整且可配置的 init 脚本示例，称为 scull.init；它接受常规参数——start、stop 和 restart——并执行 scull_load 和 scull_unload 的角色。<br>如果反复创建和销毁 /dev 节点听起来有些过分，有一个有用的解决方法。如果你只加载和卸载一个驱动，你可以在第一次使用脚本创建特殊文件后，只需使用 rmmod 和 insmod：动态号码不会随机化，如果你不加载其他（动态）模块，你可以指望每次选择相同的号码。在开发过程中避免冗长的脚本是有用的。但显然，这个技巧不适用于同时加载多个驱动。<br>我们认为，分配主设备号的最佳方法是默认使用动态分配，同时允许自己在加载时甚至编译时指定主设备号。scull 的实现以这种方式工作；它使用一个全局变量 scull_major 来保存选择的号码（还有一个 scull_minor 用于次设备号）。该变量初始化为 SCULL_MAJOR，在 scull.h 中定义。分发源代码中 SCULL_MAJOR 的默认值为 0，表示“使用动态分配”。用户可以接受默认值，或者在编译前修改宏，或者在 insmod 命令行上为 scull_major 指定一个值。最后，通过使用 scull_load 脚本，用户可以在 scull_load 的命令行上传递参数给 insmod。<br>以下是我们在 scull 源代码中用于获取主设备号的代码：<br>if (scull_major) {
    dev = MKDEV(scull_major, scull_minor);
    result = register_chrdev_region(dev, scull_nr_devs, "scull");
} else {
    result = alloc_chrdev_region(&amp;dev, scull_minor, scull_nr_devs, "scull");
    scull_major = MAJOR(dev);
}
if (result &lt; 0) {
    printk(KERN_WARNING "scull: can't get major %d\n", scull_major);
    return result;
}
<br>本书中使用的大多数示例驱动都使用类似的代码来分配主设备号。]]></description><link>第3章-字符设备驱动/3.2-主设备号和次设备号.html</link><guid isPermaLink="false">第3章 字符设备驱动/3.2 主设备号和次设备号.md</guid><pubDate>Tue, 04 Mar 2025 16:01:01 GMT</pubDate></item><item><title><![CDATA[3.3 一些重要的数据结构]]></title><description><![CDATA[ 
 <br>正如你所想象的，设备号注册只是驱动代码必须执行的众多任务中的第一个。我们很快会查看其他重要的驱动组件，但首先需要另一个插曲。大多数基本的驱动操作涉及三个重要的内核数据结构，称为 file_operations、file 和 inode。要能够做任何有趣的事情，必须对这些结构有基本的了解，因此我们现在将快速查看每个结构，然后再详细介绍如何实现基本的驱动操作。<br><br>到目前为止，我们已经为设备预留了一些设备号，但尚未将驱动程序的任何操作与这些设备号关联起来。file_operations 结构体是字符驱动程序用来建立这种连接的机制。该结构体定义在 &lt;linux/fs.h&gt; 中，是一个函数指针的集合。每个打开的文件（在内部由 file 结构体表示，稍后我们会详细讨论）都通过一个名为 f_op 的字段与一组函数关联起来，该字段指向一个 file_operations 结构体。这些操作主要负责实现系统调用，因此被命名为 open、read 等。我们可以将文件视为一个“对象”，而操作它的函数则是它的“方法”，这是我们在 Linux 内核中看到的第一个面向对象编程的迹象，后续章节中还会看到更多。<br>通常，file_operations 结构体或其指针被称为 fops（或类似的名称）。结构体中的每个字段必须指向驱动程序中实现特定操作的函数，或者对于不支持的操作，可以留空（即设置为 NULL）。当指定 NULL 指针时，内核的确切行为因函数而异，本节后面的列表会详细说明。<br>以下列表介绍了应用程序可以在设备上调用的所有操作。我们尽量保持列表简洁，以便作为参考，仅总结每个操作以及当使用 NULL 指针时的默认内核行为。在阅读 file_operations 方法列表时，你会注意到许多参数包含 __user 字符串。这个注解是一种文档形式，用于说明指针是用户空间地址，不能直接解引用。在正常编译时，__user 没有实际作用，但它可以被外部检查工具用来发现用户空间地址的误用。<br>在本章的其余部分，我们将描述一些其他重要的数据结构，解释最重要操作的作用，并提供提示、注意事项和实际代码示例。我们将更复杂操作的讨论推迟到后面的章节，因为目前还不适合深入探讨内存管理、阻塞操作和异步通知等主题。<br>
<br>struct module *owner
<br>file_operations 结构体的第一个字段并不是一个操作，而是一个指向“拥有”该结构体的模块的指针。该字段用于防止模块在其操作仍在使用时被卸载。大多数情况下，它只需初始化为 THIS_MODULE，这是一个定义在 &lt;linux/module.h&gt; 中的宏。<br>
<br>loff_t (*llseek) (struct file *, loff_t, int);
<br>llseek 方法用于更改文件中的当前读/写位置，并将新位置作为（正数）返回值返回。loff_t 参数是一个“长偏移量”，即使在 32 位平台上也至少为 64 位宽。错误通过负返回值表示。如果该函数指针为 NULL，seek 调用将以可能不可预测的方式修改 file 结构体中的位置计数器。<br>
<br>ssize_t (*read) (struct file *, char __user *, size_t, loff_t *);
<br>用于从设备中检索数据。如果该字段为 NULL，read 系统调用将返回 -EINVAL（“无效参数”）。非负返回值表示成功读取的字节数（返回值是一个“有符号大小”类型，通常是目标平台的原生整数类型）。<br>
<br>ssize_t (*aio_read)(struct kiocb *, char __user *, size_t, loff_t);
<br>启动异步读取操作——该操作可能在函数返回之前未完成。如果该字段为 NULL，所有操作将由 read 方法同步处理。<br>
<br>ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *);
<br>向设备发送数据。如果该字段为 NULL，write 系统调用将返回 -EINVAL。非负返回值表示成功写入的字节数。<br>
<br>ssize_t (*aio_write)(struct kiocb *, const char __user *, size_t, loff_t *);
<br>启动设备上的异步写入操作。<br>
<br>int (*readdir) (struct file *, void *, filldir_t);
<br>该字段对于设备文件应为 NULL，它用于读取目录，仅对文件系统有用。<br>
<br>unsigned int (*poll) (struct file *, struct poll_table_struct *);
<br>poll 方法是 poll、epoll 和 select 系统调用的后端，这些系统调用用于查询对一个或多个文件描述符的读/写操作是否会阻塞。poll 方法应返回一个位掩码，指示是否可以进行非阻塞读/写操作，并可能向内核提供信息，以便在 I/O 操作可能时将调用进程置于睡眠状态。如果驱动程序将 poll 方法设置为 NULL，则假定设备既可读又可写且不会阻塞。<br>
<br>int (*ioctl) (struct inode *, struct file *, unsigned int, unsigned long);
<br>ioctl 系统调用提供了一种发出设备特定命令的方式（例如格式化软盘的一个磁道，这既不是读也不是写）。此外，内核会识别一些 ioctl 命令，而无需参考 fops 表。如果设备未提供 ioctl 方法，则对于任何未预定义的请求，系统调用将返回错误（-ENOTTY，“设备没有此类 ioctl”）。<br>
<br>int (*mmap) (struct file *, struct vm_area_struct *);
<br>mmap 用于请求将设备内存映射到进程的地址空间。如果该字段为 NULL，mmap 系统调用将返回 -ENODEV。<br>
<br>int (*open) (struct inode *, struct file *);
<br>尽管这是对设备文件执行的第一个操作，但驱动程序不需要声明相应的方法。如果该字段为 NULL，打开设备将始终成功，但驱动程序不会收到通知。<br>
<br>int (*flush) (struct file *);
<br>当进程关闭其设备文件描述符的副本时，会调用 flush 操作；它应执行（并等待）设备上的任何未完成操作。这不应与用户程序请求的 fsync 操作混淆。目前，flush 仅在少数驱动程序中使用；例如，SCSI 磁带驱动程序使用它来确保在设备关闭之前将所有写入的数据写入磁带。如果 flush 为 NULL，内核将忽略用户应用程序的请求。<br>
<br>int (*release) (struct inode *, struct file *);
<br>当释放 file 结构体时，会调用此操作。与 open 一样，release 可以为 NULL。<br>
<br>int (*fsync) (struct file *, struct dentry *, int);
<br>该方法是 fsync 系统调用的后端，用户调用该系统调用来刷新任何挂起的数据。如果该字段为 NULL，系统调用将返回 -EINVAL。<br>
<br>int (*aio_fsync)(struct kiocb *, int);
<br>这是 fsync 方法的异步版本。<br>
<br>int (*fasync) (int, struct file *, int);
<br>该操作用于通知设备其 FASYNC 标志的更改。异步通知是一个高级主题，将在第 6 章中描述。如果驱动程序不支持异步通知，该字段可以为 NULL。<br>
<br>int (*lock) (struct file *, int, struct file_lock *);
<br>lock 方法用于实现文件锁定；锁定是常规文件不可或缺的功能，但设备驱动程序几乎从不实现它。<br>
<br>ssize_t (*readv) (struct file *, const struct iovec *, unsigned long, loff_t*);
<br>ssize_t (*writev) (struct file *, const struct iovec *, unsigned long, loff_t *);
<br>这些方法实现了分散/聚集读/写操作。应用程序有时需要对多个内存区域执行单个读/写操作；这些系统调用允许它们在不强制对数据进行额外复制操作的情况下完成此操作。如果这些函数指针为 NULL，则将调用 read 和 write 方法（可能多次）。<br>
<br>ssize_t (*sendfile)(struct file *, loff_t *, size_t, read_actor_t, void *);
<br>该方法实现了 sendfile 系统调用的读取端，该系统调用以最少的复制将数据从一个文件描述符移动到另一个文件描述符。例如，Web 服务器使用它来将文件内容发送到网络连接。设备驱动程序通常将 sendfile 设置为 NULL。<br>
<br>ssize_t (*sendpage) (struct file *, struct page *, int, size_t, loff_t *, int);
<br>sendpage 是 sendfile 的另一半；内核调用它以逐页的方式将数据发送到相应的文件。设备驱动程序通常不实现 sendpage。<br>
<br>unsigned long (*get_unmapped_area)(struct file *, unsigned long, unsigned long, unsigned long, unsigned long);
<br>该方法的目的是在进程的地址空间中找到一个合适的位置来映射底层设备的内存段。此任务通常由内存管理代码执行；该方法的存在是为了允许驱动程序强制执行特定设备可能具有的任何对齐要求。大多数驱动程序可以将此方法设置为 NULL。<br>
<br>int (*check_flags)(int);
<br>该方法允许模块检查传递给 fcntl(F_SETFL...) 调用的标志。<br>
<br>int (*dir_notify)(struct file *, unsigned long);
<br>当应用程序使用 fcntl 请求目录更改通知时，会调用此方法。它仅对文件系统有用；驱动程序无需实现 dir_notify。<br>scull 设备驱动程序仅实现了最重要的设备方法。其 file_operations 结构体初始化如下：<br>struct file_operations scull_fops = {
    .owner = THIS_MODULE,
    .llseek = scull_llseek,
    .read = scull_read,
    .write = scull_write,
    .ioctl = scull_ioctl,
    .open = scull_open,
    .release = scull_release,
};
<br>此声明使用了标准的 C 标记结构体初始化语法。这种语法是首选，因为它使驱动程序在结构体定义更改时更具可移植性，并且可以说使代码更紧凑和易读。标记初始化允许结构体成员的重新排序；在某些情况下，通过将频繁访问的成员指针放置在同一硬件缓存行中，可以实现显著的性能提升。<br><br>struct file 定义在 &lt;linux/fs.h&gt; 中，是设备驱动中使用的第二个最重要的数据结构。请注意，file 与用户空间程序的 FILE 指针无关。FILE 在 C 库中定义，永远不会出现在内核代码中。另一方面，struct file 是一个内核结构，永远不会出现在用户程序中。<br>file 结构表示一个打开的文件。（它不特定于设备驱动；系统中的每个打开文件在内核空间中都有一个关联的 struct file。）它在打开时由内核创建，并传递给任何操作文件的函数，直到最后一次关闭。在所有文件实例关闭后，内核释放该数据结构。<br>在内核源代码中，指向 struct file 的指针通常称为 file 或 filp（“文件指针”）。我们将一致地称指针为 filp，以防止与结构本身产生歧义。因此，file 指结构，filp 指指向结构的指针。<br>struct file 的最重要字段如下所示。与上一节一样，列表可以在第一次阅读时跳过。然而，在本章后面，当我们面对一些真实的 C 代码时，我们将更详细地讨论这些字段。<br>
<br>mode_t f_mode：
<br>文件模式标识文件是可读、可写还是两者兼有，通过 FMODE_READ 和 FMODE_WRITE 位。你可能希望在 open 或 ioctl 函数中检查此字段以获取读/写权限，但你不需要为 read 和 write 检查权限，因为内核在调用你的方法之前会进行检查。如果文件未以该类型访问打开，尝试读取或写入将被拒绝，而驱动甚至不会知道。<br>
<br>loff_t f_pos：
<br>当前的读取或写入位置。loff_t 在所有平台上都是 64 位值（在 gcc 术语中为 long long）。如果需要知道文件中的当前位置，驱动可以读取此值，但通常不应更改它；read 和 write 应使用它们接收的指针作为最后一个参数来更新位置，而不是直接操作 filp-&gt;f_pos。此规则的一个例外是 llseek 方法，其目的是更改文件位置。<br>
<br>unsigned int f_flags：
<br>这些是文件标志，如 O_RDONLY、O_NONBLOCK 和 O_SYNC。驱动应检查 O_NONBLOCK 标志以查看是否已请求非阻塞操作（我们将在第1章的“阻塞和非阻塞操作”部分讨论非阻塞 I/O）；其他标志很少使用。特别是，应使用 f_mode 而不是 f_flags 检查读/写权限。所有标志都在头文件 &lt;linux/fcntl.h&gt; 中定义。<br>
<br>struct file_operations *f_op：
<br>与文件关联的操作。内核在实现 open 时分配指针，然后在需要分派任何操作时读取它。内核不会保存 fillp-&gt;f_op 的值以供以后参考；这意味着你可以更改与文件关联的文件操作，并且在你返回调用者后，新方法将生效。例如，与主设备号 1 关联的 open 代码（/dev/null、/dev/zero 等）根据打开的次设备号替换 fillp-&gt;f_op 中的操作。这种做法允许在同一个主设备号下实现多种行为，而不会在每次系统调用时引入开销。替换文件操作的能力是内核中“方法重写”的等价物，类似于面向对象编程中的概念。<br>
<br>void *private_data：
<br>open 系统调用在调用驱动的 open 方法之前将此指针设置为 NULL。你可以自由地使用该字段或忽略它；你可以使用该字段指向分配的数据，但必须记得在 release 方法中释放该内存，以免内核销毁文件结构时造成内存泄漏。private_data 是跨系统调用保存状态信息的有用资源，大多数示例模块都使用它。<br>
<br>struct dentry *f_dentry：
<br>与文件关联的目录项（dentry）结构。设备驱动编写者通常不需要关心 dentry 结构，除非需要访问 inode 结构，如 fillp-&gt;f_dentry-&gt;d_inode。<br>实际的结构中还有更多字段，但它们对设备驱动没有用处。我们可以安全地忽略这些字段，因为驱动从不创建文件结构；它们只访问其他地方创建的结构。<br><br>inode 结构由内核内部用于表示文件。因此，它与表示打开文件描述符的 file 结构不同。一个文件可以有多个 file 结构，表示多个打开的描述符，但它们都指向同一个 inode 结构。<br>inode 结构包含大量关于文件的信息。通常，只有该结构的两个字段对编写驱动代码有意义：<br>
<br>dev_t i_rdev：
<br>对于表示设备文件的 inode，此字段包含实际的设备号。<br>
<br>struct cdev *i_cdev：
<br>struct cdev 是内核内部表示字符设备的结构；当 inode 引用字符设备文件时，此字段包含指向该结构的指针。<br>在 2.5 开发系列的过程中，i_rdev 的类型发生了变化，导致许多驱动出现问题。为了鼓励更可移植的编程，内核开发者添加了两个宏，用于从 inode 中获取主设备号和次设备号：<br>unsigned int iminor(struct inode *inode);
unsigned int imajor(struct inode *inode);
<br>为了避免被未来的变化所困扰，应使用这些宏，而不是直接操作 i_rdev。]]></description><link>第3章-字符设备驱动/3.3-一些重要的数据结构.html</link><guid isPermaLink="false">第3章 字符设备驱动/3.3 一些重要的数据结构.md</guid><pubDate>Tue, 04 Mar 2025 16:01:09 GMT</pubDate></item><item><title><![CDATA[3.4 字符设备注册]]></title><description><![CDATA[ 
 <br>如前所述，内核使用 struct cdev 类型的结构在内部表示字符设备。在内核调用你的设备操作之前，你必须分配并注册一个或多个这些结构。为此，你的代码应包含 &lt;linux/cdev.h&gt;，其中定义了该结构及其相关的辅助函数。<br>有两种方法可以分配和初始化这些结构。如果你希望在运行时获取一个独立的 cdev 结构，可以使用如下代码：<br>struct cdev *my_cdev = cdev_alloc();
my_cdev-&gt;ops = &amp;my_fops;
<br>然而，你可能希望将 cdev 结构嵌入到你自己的设备特定结构中；scull 就是这样做的。在这种情况下，你应该使用以下代码初始化你已经分配的结构：<br>void cdev_init(struct cdev *cdev, struct file_operations *fops);
<br>无论哪种方式，你都需要初始化 struct cdev 的另一个字段。与 file_operations 结构一样，struct cdev 有一个 owner 字段，应设置为 THIS_MODULE。<br>一旦 cdev 结构设置完毕，最后一步是通过调用以下函数告诉内核：<br>int cdev_add(struct cdev *dev, dev_t num, unsigned int count);
<br>在这里，dev 是 cdev 结构，num 是此设备响应的第一个设备号，count 是应与设备关联的设备号数量。通常 count 为 1，但在某些情况下，让多个设备号对应特定设备是有意义的。例如，SCSI 磁带驱动允许用户空间通过为每个物理设备分配多个次设备号来选择操作模式（如密度）。<br>使用 cdev_add 时需要注意几点。首先，此调用可能会失败。如果它返回一个负的错误代码，你的设备将不会被添加到系统中。然而，它几乎总是成功的，这引出了另一点：一旦 cdev_add 返回，你的设备就“激活”了，内核可以调用其操作。你不应在驱动完全准备好处理设备操作之前调用 cdev_add。<br>要从系统中删除字符设备，请调用：<br>void cdev_del(struct cdev *dev);
<br>显然，在将 cdev 结构传递给 cdev_del 后，你不应再访问它。<br><br>在内部，scull 使用 struct scull_dev 类型的结构表示每个设备。该结构定义如下：<br>struct scull_dev {
    struct scull_qset *data; /* 指向第一个量子集的指针 */
    int quantum; /* 当前量子大小 */
    int qset; /* 当前数组大小 */
    unsigned long size; /* 存储在此处的数据量 */
    unsigned int access_key; /* 由 sculluid 和 scullpriv 使用 */
    struct semaphore sem; /* 互斥信号量 */
    struct cdev cdev; /* 字符设备结构 */
};
<br>我们将在讨论各个字段时介绍它们，但现在我们注意到 cdev，即 struct cdev，它将我们的设备与内核接口连接起来。必须按照上述方式初始化和添加此结构；处理此任务的 scull 代码如下：<br>static void scull_setup_cdev(struct scull_dev *dev, int index)
{
    int err, devno = MKDEV(scull_major, scull_minor + index);

    cdev_init(&amp;dev-&gt;cdev, &amp;scull_fops);
    dev-&gt;cdev.owner = THIS_MODULE;
    dev-&gt;cdev.ops = &amp;scull_fops;
    err = cdev_add(&amp;dev-&gt;cdev, devno, 1);
    /* 如果需要，优雅地处理失败 */
    if (err)
        printk(KERN_NOTICE "Error %d adding scull%d", err, index);
}
<br>由于 cdev 结构嵌入在 struct scull_dev 中，必须调用 cdev_init 来初始化该结构。<br><br>如果你深入研究 2.6 内核中的许多驱动代码，你可能会注意到许多字符驱动没有使用我们刚刚描述的 cdev 接口。你看到的是尚未升级到 2.6 接口的旧代码。由于该代码仍然有效，这种升级可能不会很快发生。为了完整起见，我们描述了旧的字符设备注册接口，但新代码不应使用它；这种机制可能会在未来的内核中消失。<br>注册字符设备驱动的经典方式是：<br>int register_chrdev(unsigned int major, const char *name,
                    struct file_operations *fops);
<br>在这里，major 是感兴趣的主设备号，name 是驱动的名称（它出现在 /proc/devices 中），fops 是默认的 file_operations 结构。调用 register_chrdev 会为给定的主设备号注册次设备号 0-255，并为每个设备设置一个默认的 cdev 结构。使用此接口的驱动必须准备好处理所有 256 个次设备号上的 open 调用（无论它们是否对应真实设备），并且它们不能使用大于 255 的主设备号或次设备号。<br>如果你使用 register_chrdev，从系统中删除设备的正确函数是：<br>int unregister_chrdev(unsigned int major, const char *name);
<br>major 和 name 必须与传递给 register_chrdev 的值相同，否则调用将失败。]]></description><link>第3章-字符设备驱动/3.4-字符设备注册.html</link><guid isPermaLink="false">第3章 字符设备驱动/3.4 字符设备注册.md</guid><pubDate>Tue, 04 Mar 2025 16:01:25 GMT</pubDate></item><item><title><![CDATA[3.5 open 和 release]]></title><description><![CDATA[ 
 <br>现在我们已经快速浏览了这些字段，我们开始在真实的 scull 函数中使用它们。<br><br>open 方法是为驱动准备的，以便为后续操作进行任何初始化。在大多数驱动中，open 应执行以下任务：<br>
<br>检查设备特定的错误（如设备未准备好或类似的硬件问题）
<br>如果设备是第一次打开，则初始化设备
<br>如果需要，更新 f_op 指针
<br>分配并填充要放入 flip-&gt;private_data 的任何数据结构
<br>然而，首要任务通常是识别正在打开的设备。请记住，open 方法的原型是：<br>int (*open)(struct inode *inode, struct file *filp);
<br>inode 参数包含我们需要的信息，形式为 i_cdev 字段，其中包含我们之前设置的 cdev 结构。唯一的问题是我们通常不想要 cdev 结构本身，而是包含该 cdev 结构的 scull_dev 结构。C 语言允许程序员进行各种技巧来实现这种转换；然而，编写这种技巧容易出错，并且会导致代码难以阅读和理解。幸运的是，在这种情况下，内核黑客已经为我们完成了这些技巧，形式为 container_of 宏，定义在 &lt;linux/kernel.h&gt; 中：<br>container_of(pointer, container_type, container_field);
<br>此宏接受一个指向 container_type 结构内的 container_field 字段的指针，并返回指向包含结构的指针。在 scull_open 中，此宏用于查找适当的设备结构：<br>struct scull_dev *dev; /* 设备信息 */

dev = container_of(inode-&gt;i_cdev, struct scull_dev, cdev);
filp-&gt;private_data = dev; /* 供其他方法使用 */
<br>一旦找到 scull_dev 结构，scull 将其指针存储在 file 结构的 private_data 字段中，以便将来更容易访问。<br>识别正在打开的设备的另一种方法是查看存储在 inode 结构中的次设备号。如果你使用 register_chrdev 注册设备，则必须使用此技术。确保使用 iminor 从 inode 结构中获取次设备号，并确保它对应于你的驱动实际准备处理的设备。<br>scull_open 的（稍微简化的）代码如下：<br>int scull_open(struct inode *inode, struct file *filp)
{
    struct scull_dev *dev; /* 设备信息 */
    dev = container_of(inode-&gt;i_cdev, struct scull_dev, cdev);
    filp-&gt;private_data = dev; /* 供其他方法使用 */
    /* 如果以只写方式打开，则将设备长度修剪为 0 */
    if ((filp-&gt;f_flags &amp; O_ACCMODE) == O_WRONLY) {
        scull_trim(dev); /* 忽略错误 */
    }
    return 0; /* 成功 */
}
<br>代码看起来相当简单，因为在调用 open 时它没有执行任何特定的设备处理。它不需要这样做，因为 scull 设备在设计上是全局且持久的。具体来说，没有诸如“在第一次打开时初始化设备”之类的操作，因为我们不为 scull 保留打开计数。<br>对设备执行的唯一真正操作是在以写方式打开设备时将其长度修剪为 0。执行此操作是因为，根据设计，用较短的文件覆盖 scull 设备会导致设备数据区域变短。这类似于以写方式打开常规文件会将其长度修剪为 0。如果设备以读方式打开，则此操作不执行任何操作。<br>我们稍后将在查看其他 scull 变体的代码时看到真正的初始化是如何工作的。<br><br>release 方法的作用与 open 相反。有时你会发现方法实现称为 device_close 而不是 device_release。无论哪种方式，设备方法应执行以下任务：<br>
<br>释放 open 在 flip-&gt;private_data 中分配的任何内容
<br>在最后一次关闭时关闭设备
<br>基本形式的 scull 没有硬件需要关闭，因此所需的代码非常少：<br>int scull_release(struct inode *inode, struct file *filp)
{
    return 0;
}
<br>你可能会好奇，当一个设备文件被关闭的次数多于它被打开的次数时会发生什么。毕竟，dup 和 fork 系统调用会创建打开文件的副本，而不会调用 open；这些副本在程序终止时都会被关闭。例如，大多数程序不会显式打开它们的 stdin 文件（或设备），但所有程序最终都会关闭它。那么，驱动程序如何知道一个打开的设备文件是否真的被关闭了呢？<br>答案很简单：并非每次 close 系统调用都会触发 release 方法的调用。只有那些真正释放设备数据结构时，才会调用 release 方法——这也是它名字的由来。内核会维护一个计数器，记录文件结构体被使用的次数。fork 和 dup 并不会创建新的文件结构体（只有 open 会这样做）；它们只是增加现有结构体的引用计数。只有当文件结构体的引用计数降为 0 时，close 系统调用才会执行 release 方法，而这通常发生在结构体被销毁时。release 方法与 close 系统调用之间的这种关系确保了驱动程序对每次 open 只会看到一次 release 调用。<br>需要注意的是，每次应用程序调用 close 时，flush 方法都会被调用。然而，很少有驱动程序实现 flush，因为在关闭时通常没有什么需要执行的操作，除非涉及到 release。<br>正如你所想象的，上述讨论同样适用于应用程序在没有显式关闭其打开文件的情况下终止的场景：内核会在进程退出时自动关闭所有打开的文件，内部通过 close 系统调用来实现这一点。]]></description><link>第3章-字符设备驱动/3.5-open-和-release.html</link><guid isPermaLink="false">第3章 字符设备驱动/3.5 open 和 release.md</guid><pubDate>Tue, 04 Mar 2025 16:01:35 GMT</pubDate></item><item><title><![CDATA[3.6 scull 的内存使用]]></title><description><![CDATA[ 
 <br>在介绍 read 和 write 操作之前，我们最好先看看 scull 如何以及为什么执行内存分配。“如何”需要彻底理解代码，“为什么”展示了驱动编写者需要做出的选择，尽管 scull 绝对不是一个典型的设备。<br>本节仅涉及 scull 中的内存分配策略，并不展示编写真实驱动所需的硬件管理技能。这些技能在第9章和第10章中介绍。因此，如果你对理解面向内存的 scull 驱动的内部工作原理不感兴趣，可以跳过本节。<br>scull 使用的内存区域（也称为设备）的长度是可变的。你写入的数据越多，它增长得越多；通过用较短的文件覆盖设备来执行修剪。<br>scull 驱动引入了两个用于管理 Linux 内核内存的核心函数。这些函数定义在 &lt;linux/slab.h&gt; 中：<br>void *kmalloc(size_t size, int flags);
void kfree(void *ptr);
<br>调用 kmalloc 尝试分配 size 字节的内存；返回值是指向该内存的指针，如果分配失败则为 NULL。flags 参数用于描述应如何分配内存；我们将在第8章中详细检查这些标志。目前，我们始终使用 GFP_KERNEL。分配的内存应使用 kfree 释放。你不应将任何未从 kmalloc 获得的内容传递给 kfree。然而，将 NULL 指针传递给 kfree 是合法的。<br>kmalloc 不是分配大块内存的最有效方式（参见第8章），因此为 scull 选择的实现并不是特别聪明。智能实现的源代码将更难阅读，而本节的目标是展示 read 和 write，而不是内存管理。这就是为什么代码只使用 kmalloc 和 kfree，而不使用整个页面的分配，尽管这种方法会更有效。<br>另一方面，我们不想限制“设备”区域的大小，这既是出于哲学原因，也是出于实际原因。从哲学上讲，对正在管理的数据项设置任意限制总是一个坏主意。实际上，scull 可以用于临时占用系统的内存以在低内存条件下运行测试。运行此类测试可能有助于你理解系统的内部结构。你可以使用命令 cp /dev/zero /dev/scull0 来使用 scull 占用所有实际 RAM，并且你可以使用 dd 实用程序选择将多少数据复制到 scull 设备。<br>在 scull 中，每个设备是一个指针链表，每个指针指向一个 scull_dev 结构。每个这样的结构默认最多可以引用4百万字节，通过一个中间指针数组。发布的源代码使用一个包含 1000 个指针的数组，每个指针指向 4000 字节的区域。我们将每个内存区域称为一个量子，将数组（或其长度）称为量子集。scull 设备及其内存区域如图 3-1 所示。<br>图 3-1. scull 设备的布局<br>
<img alt="the_layer_of_a_scull_device" src="第3章-字符设备驱动/images/the_layer_of_a_scull_device.png"><br>选择的数字使得在 scull 中写入单个字节会消耗 8000 或 12000 字节的内存：4000 用于量子，4000 或 8000 用于量子集（根据目标平台上指针是 32 位还是 64 位）。相反，如果你写入大量数据，链表的开销并不太糟糕。每四兆字节数据只有一个链表元素，设备的最大大小受计算机内存大小的限制。<br>选择适当的量子大小和量子集大小是一个策略问题，而不是机制问题，最佳大小取决于设备的使用方式。因此，scull 驱动不应强制使用任何特定的量子大小和量子集大小。在 scull 中，用户可以通过多种方式更改负责的值：通过在编译时更改 scull.h 中的宏 SCULL_QUANTUM 和 SCULL_QSET，通过在模块加载时设置整数值 scull_quantum 和 scull_qset，或通过在运行时使用 ioctl 更改当前值和默认值。<br>使用宏和整数值来允许编译时和加载时配置让人想起如何选择主设备号。我们使用此技术来处理驱动中与策略相关的任意值。<br>剩下的唯一问题是如何选择默认数字。在这种情况下，问题在于找到由于半满量子和量子集导致的内存浪费与如果量子和集很小而发生的分配、释放和指针链接开销之间的最佳平衡。此外，还应考虑 kmalloc 的内部设计。（我们现在不会深入探讨这一点；kmalloc 的内部结构在第8章中探讨。）默认数字的选择基于假设在测试 scull 时可能会向其写入大量数据，尽管设备的正常使用很可能只传输几千字节的数据。<br>我们已经看到了表示我们设备内部的 scull_dev 结构。该结构的 quantum 和 qset 字段分别保存设备的量子大小和量子集大小。然而，实际数据由不同的结构跟踪，我们称之为 struct scull_qset：<br>struct scull_qset {
    void **data;
    struct scull_qset *next;
};
<br>下一个代码片段展示了如何在实践中使用 struct scull_dev 和 struct scull_qset 来保存数据。函数 scull_trim 负责释放整个数据区域，并在文件以写方式打开时由 scull_open 调用。它只是遍历列表并释放它找到的任何量子和量子集。<br>int scull_trim(struct scull_dev *dev)
{
    struct scull_qset *next, *dptr;
    int qset = dev-&gt;qset; /* "dev" 不为空 */
    int i;

    for (dptr = dev-&gt;data; dptr; dptr = next) { /* 所有列表项 */
        if (dptr-&gt;data) {
            for (i = 0; i &lt; qset; i++)
                kfree(dptr-&gt;data[i]);
            kfree(dptr-&gt;data);
            dptr-&gt;data = NULL;
        }
        next = dptr-&gt;next;
        kfree(dptr);
    }
    dev-&gt;size = 0;
    dev-&gt;quantum = scull_quantum;
    dev-&gt;qset = scull_qset;
    dev-&gt;data = NULL;
    return 0;
}
<br>scull_trim 还用于在模块清理函数中将 scull 使用的内存返回给系统。]]></description><link>第3章-字符设备驱动/3.6-scull-的内存使用.html</link><guid isPermaLink="false">第3章 字符设备驱动/3.6 scull 的内存使用.md</guid><pubDate>Tue, 04 Mar 2025 16:01:43 GMT</pubDate><enclosure url="第3章-字符设备驱动/images/the_layer_of_a_scull_device.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="第3章-字符设备驱动/images/the_layer_of_a_scull_device.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3.7 read 和 write]]></title><description><![CDATA[ 
 <br>read 和 write 方法都执行类似的任务，即从应用程序代码复制数据或向应用程序代码复制数据。因此，它们的原型非常相似，值得同时介绍它们：<br>ssize_t read(struct file *filp, char __user *buff, size_t count, loff_t *offp);
ssize_t write(struct file *filp, const char __user *buff, size_t count, loff_t *offp);
<br>对于这两种方法，filp 是文件指针，count 是请求的数据传输大小。buff 参数指向用户缓冲区，该缓冲区保存要写入的数据或应放置新读取数据的空缓冲区。最后，offp 是指向“长偏移类型”对象的指针，该对象指示用户正在访问的文件位置。返回值是“有符号大小类型”；其用法稍后讨论。<br>让我们重复一遍，read 和 write 方法的 buff 参数是用户空间指针。因此，内核代码不能直接解引用它。此限制有几个原因：<br>
<br>根据你的驱动运行的架构以及内核的配置方式，用户空间指针在内核模式下可能完全无效。该地址可能没有映射，或者它可能指向一些其他随机数据。
<br>即使指针在内核空间中有相同的含义，用户空间内存是分页的，并且系统调用时相关内存可能不在 RAM 中。尝试直接引用用户空间内存可能会生成页面错误，这是内核代码不允许的。结果将是一个“oops”，这将导致发出系统调用的进程死亡。
<br>该指针由用户程序提供，该程序可能有错误或恶意。如果你的驱动盲目地解引用用户提供的指针，它将为用户空间程序打开一个访问或覆盖系统中任何内存的大门。如果你不希望对你用户系统的安全负责，你绝不能直接解引用用户空间指针。
<br>显然，你的驱动必须能够访问用户空间缓冲区才能完成其工作。然而这种访问必须始终通过内核提供的特殊函数来执行，以确保安全。我们在这里介绍一些这些函数（定义在 &lt;asm/uaccess.h&gt; 中），其余的将在第1章的“使用 ioctl 参数”部分中介绍；它们使用一些特殊的、依赖于架构的技巧来确保内核和用户空间之间的数据传输是安全和正确的。<br>scull 中的 read 和 write 代码需要将整个数据段复制到用户地址空间或从用户地址空间复制。以下内核函数提供了这种能力，它们复制任意字节数组，并且是大多数 read 和 write 实现的核心：<br>unsigned long copy_to_user(void __user *to, const void *from, unsigned long count);
unsigned long copy_from_user(void *to, const void __user *from, unsigned long count);
<br>尽管这些函数的行为类似于普通的内存函数，但在从内核代码访问用户空间时必须格外小心。所寻址的用户页面可能当前不在内存中，虚拟内存子系统可能会在页面被传输到适当位置时将进程置于睡眠状态。例如，当页面必须从交换空间检索时，就会发生这种情况。对于驱动编写者来说，最终结果是任何访问用户空间的函数都必须是可重入的，必须能够与其他驱动函数并发执行，并且特别是必须处于可以合法睡眠的位置。我们将在第5章中回到这个主题。<br>这两个函数的作用不仅限于将数据复制到用户空间和从用户空间复制数据：它们还检查用户空间指针是否有效。如果指针无效，则不执行复制；如果在复制过程中遇到无效地址，则只复制部分数据。在这两种情况下，返回值是仍需复制的内存量。scull 代码会检查此错误返回，如果不是 0，则向用户返回 -EFAULT。<br>用户空间访问和无效用户空间指针的主题有些高级，将在第6章中讨论。然而，值得注意的是，如果你不需要检查用户空间指针，你可以调用 __copy_to_user 和 __copy_from_user。例如，如果你知道你已经检查了参数，这很有用。但要小心；如果你确实没有检查你传递给这些函数的用户空间指针，那么你可能会创建内核崩溃和/或安全漏洞。<br>就实际的设备方法而言，read 方法的任务是将数据从设备复制到用户空间（使用 copy_to_user），而 write 方法必须将数据从用户空间复制到设备（使用 copy_from_user）。每个 read 或 write 系统调用请求传输特定数量的字节，但驱动可以自由传输较少的数据——确切的规则对于读取和写入略有不同，并在本章后面描述。<br>无论方法传输的数据量如何，它们通常应在成功完成系统调用后更新 *offp 处的文件位置以表示当前文件位置。然后，内核在适当时将文件位置更改传播回文件结构。然而，pread 和 pwrite 系统调用具有不同的语义；它们从给定的文件偏移量操作，并且不会更改其他系统调用看到的文件位置。这些调用传递一个指向用户提供的位置的指针，并丢弃你的驱动所做的更改。<br>图 3-2 表示典型的 read 实现如何使用其参数。<br>ssize_t dev_read(struct file *file, char *buf, size_t count, loff_t *ppos);
<br>图 3-2. read 的参数<br>
<img alt="the_arguments_to_read" src="第3章-字符设备驱动/images/the_arguments_to_read.png"><br>如果发生错误，read 和 write 方法都返回负值。返回值大于或等于 0 时，告诉调用程序成功传输了多少字节。如果某些数据正确传输，然后发生错误，则返回值必须是成功传输的字节数，并且错误直到下次调用函数时才会报告。实现此约定当然要求你的驱动记住错误已发生，以便将来返回错误状态。<br>尽管内核函数返回负数以表示错误，并且该数字的值指示发生的错误类型（如第2章中介绍），但在用户空间中运行的程序总是将 -1 视为错误返回值。它们需要访问 errno 变量以找出发生了什么。用户空间行为由 POSIX 标准规定，但该标准不对内核的内部操作提出要求。<br><br>read 的返回值由调用应用程序解释：<br>
<br>如果该值等于传递给 _read 系统调用的 count 参数，则已传输请求的字节数。这是最佳情况。
<br>如果该值为正但小于 count，则仅传输了部分数据。这可能是由于设备的原因，具体取决于设备。大多数情况下，应用程序会重试读取。例如，如果你使用 fread 函数读取，库函数会重新发出系统调用，直到完成请求的数据传输。
<br>如果该值为 0，则已达到文件末尾（并且未读取任何数据）。
<br>负值表示发生了错误。该值指定了错误类型，根据 &lt;linux/errno.h&gt;。典型的错误返回值包括 -EINTR（中断的系统调用）或 -EFAULT（错误的地址）。
<br>前面的列表中缺少的是“没有数据，但可能稍后到达”的情况。在这种情况下，read 系统调用应阻塞。我们将在第6章中处理阻塞输入。<br>scull 代码利用了这些规则。特别是，它利用了部分读取规则。每次调用 scull_read 只处理一个数据量子，而不实现循环来收集所有数据；这使得代码更短且更易于阅读。如果读取程序确实需要更多数据，它会重新调用。如果使用标准 I/O 库（即 fread）读取设备，应用程序甚至不会注意到数据传输的量子化。<br>如果当前读取位置大于设备大小，scull 的 _read 方法返回 0 以表示没有可用数据（换句话说，我们处于文件末尾）。如果进程 A 正在读取设备而进程 B 以写方式打开它，从而将设备长度截断为 0，则可能会发生这种情况。进程 A 突然发现自己超过了文件末尾，下一次读取调用返回 0。<br>以下是 read 的代码（暂时忽略对 down_interruptible 和 up 的调用；我们将在下一章中讨论它们）：<br>ssize_t scull_read(struct file *filp, char __user *buf, size_t count, loff_t *f_pos)
{
    struct scull_dev *dev = filp-&gt;private_data;
    struct scull_qset *dptr; /* 第一个列表项 */
    int quantum = dev-&gt;quantum, qset = dev-&gt;qset;
    int itemsize = quantum * qset; /* 列表项中有多少字节 */
    int item, s_pos, q_pos, rest;
    ssize_t retval = 0;

    if (down_interruptible(&amp;dev-&gt;sem))
        return -ERESTARTSYS;
    if (*f_pos &gt;= dev-&gt;size)
        goto out;
    if (*f_pos + count &gt; dev-&gt;size)
        count = dev-&gt;size - *f_pos;

    /* 找到列表项、量子集索引和量子中的偏移量 */
    item = (long)*f_pos / itemsize;
    rest = (long)*f_pos % itemsize;
    s_pos = rest / quantum; q_pos = rest % quantum;

    /* 跟随列表到正确的位置（在其他地方定义） */
    dptr = scull_follow(dev, item);

    if (dptr == NULL || !dptr-&gt;data || !dptr-&gt;data[s_pos])
        goto out; /* 不要填充空洞 */

    /* 只读取到此量子的末尾 */
    if (count &gt; quantum - q_pos)
        count = quantum - q_pos;

    if (copy_to_user(buf, dptr-&gt;data[s_pos] + q_pos, count)) {
        retval = -EFAULT;
        goto out;
    }
    *f_pos += count;
    retval = count;

out:
    up(&amp;dev-&gt;sem);
    return retval;
}
<br><br>write 与 read 类似，可以传输比请求少的数据，根据以下返回值规则：<br>
<br>如果该值等于 count，则已传输请求的字节数。
<br>如果该值为正但小于 count，则仅传输了部分数据。程序很可能会重试写入剩余的数据。
<br>如果该值为 0，则未写入任何内容。此结果不是错误，并且没有理由返回错误代码。再次，标准库会重试 write 调用。我们将在第6章中介绍阻塞 write 时检查此情况的确切含义。
<br>负值表示发生了错误；与 read 一样，有效的错误值是 &lt;linux/errno.h&gt; 中定义的那些。
<br>不幸的是，仍然有一些行为不当的程序在部分传输时发出错误消息并中止。这是因为一些程序员习惯于看到完全失败或完全成功的 write 调用，这实际上是大多数情况下发生的情况，并且应该由设备支持。scull 实现中的此限制可以修复，但我们不想使代码比必要的更复杂。<br>scull 的 write 代码与 read 方法一样，一次处理一个量子：<br>ssize_t scull_write(struct file *filp, const char __user *buf, size_t count, loff_t *f_pos)
{
    struct scull_dev *dev = filp-&gt;private_data;
    struct scull_qset *dptr;
    int quantum = dev-&gt;quantum, qset = dev-&gt;qset;
    int itemsize = quantum * qset;
    int item, s_pos, q_pos, rest;
    ssize_t retval = -ENOMEM; /* 用于 "goto out" 语句的值 */

    if (down_interruptible(&amp;dev-&gt;sem))
        return -ERESTARTSYS;

    /* 找到列表项、量子集索引和量子中的偏移量 */
    item = (long)*f_pos / itemsize;
    rest = (long)*f_pos % itemsize;
    s_pos = rest / quantum; q_pos = rest % quantum;

    /* 跟随列表到正确的位置 */
    dptr = scull_follow(dev, item);
    if (dptr == NULL)
        goto out;
    if (!dptr-&gt;data) {
        dptr-&gt;data = kmalloc(qset * sizeof(char *), GFP_KERNEL);
        if (!dptr-&gt;data)
            goto out;
        memset(dptr-&gt;data, 0, qset * sizeof(char *));
    }
    if (!dptr-&gt;data[s_pos]) {
        dptr-&gt;data[s_pos] = kmalloc(quantum, GFP_KERNEL);
        if (!dptr-&gt;data[s_pos])
            goto out;
    }
    /* 只写入到此量子的末尾 */
    if (count &gt; quantum - q_pos)
        count = quantum - q_pos;

    if (copy_from_user(dptr-&gt;data[s_pos] + q_pos, buf, count)) {
        retval = -EFAULT;
        goto out;
    }
    *f_pos += count;
    retval = count;

    /* 更新大小 */
    if (dev-&gt;size &lt; *f_pos)
        dev-&gt;size = *f_pos;

out:
    up(&amp;dev-&gt;sem);
    return retval;
}
<br><br>Unix 系统长期以来支持两个名为 readv 和 writev 的系统调用。这些“向量”版本的 read 和 write 采用一个结构数组，每个结构包含一个指向缓冲区的指针和一个长度值。readv 调用将依次读取每个缓冲区中指示的数量。writev 将收集每个缓冲区的内容并将它们作为单个写入操作输出。<br>如果你的驱动不提供处理向量操作的方法，readv 和 writev 将通过多次调用你的 read 和 write 方法来实现。然而，在许多情况下，通过直接实现 readv 和 writev 可以实现更高的效率。<br>向量操作的原型是：<br>ssize_t (*readv) (struct file *filp, const struct iovec *iov, unsigned long count, loff_t *ppos);
ssize_t (*writev) (struct file *filp, const struct iovec *iov, unsigned long count, loff_t *ppos);
<br>在这里，filp 和 ppos 参数与 read 和 write 相同。iovec 结构定义在 &lt;linux/uio.h&gt; 中，如下所示：<br>struct iovec {
    void __user *iov_base;
    __kernel_size_t iov_len;
};
<br>每个 iovec 描述要传输的一块数据；它从 iov_base（在用户空间中）开始，长度为 iov_len 字节。count 参数告诉方法有多少个 iovec 结构。这些结构由应用程序创建，但内核在调用驱动之前将它们复制到内核空间。<br>向量操作的最简单实现是一个简单的循环，将每个 iovec 的地址和长度传递给驱动的 read 或 write 函数。然而，通常高效且正确的行为要求驱动做更聪明的事情。例如，磁带驱动器上的 writev 应将所有 iovec 结构的内容作为磁带上的单个记录写入。<br>然而，许多驱动从实现这些方法本身中得不到任何好处。因此，scull 省略了它们。内核使用 read 和 write 模拟它们，最终结果是相同的。]]></description><link>第3章-字符设备驱动/3.7-read-和-write.html</link><guid isPermaLink="false">第3章 字符设备驱动/3.7 read 和 write.md</guid><pubDate>Tue, 04 Mar 2025 16:01:58 GMT</pubDate><enclosure url="第3章-字符设备驱动/images/the_arguments_to_read.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="第3章-字符设备驱动/images/the_arguments_to_read.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3.8 使用新设备]]></title><description><![CDATA[ 
 <br>一旦你配备了上述四种方法，驱动就可以编译和测试；它保留你写入的任何数据，直到你用新数据覆盖它。设备的行为类似于数据缓冲区，其长度仅受实际可用 RAM 的限制。你可以尝试使用 cp、dd 和输入/输出重定向来测试驱动。<br>free 命令可用于查看可用内存量如何根据写入 scull 的数据量缩小和扩展。<br>为了更自信地一次读取和写入一个量子，你可以在驱动中的适当位置添加一个 printk，并观察应用程序读取或写入大块数据时发生的情况。或者，使用 strace 实用程序监视程序发出的系统调用及其返回值。跟踪 cp 或 ls -l &gt; /dev/scull0 显示量子化的读取和写入。监视（和调试）技术在第4章中详细介绍。]]></description><link>第3章-字符设备驱动/3.8-使用新设备.html</link><guid isPermaLink="false">第3章 字符设备驱动/3.8 使用新设备.md</guid><pubDate>Tue, 04 Mar 2025 16:02:06 GMT</pubDate></item><item><title><![CDATA[3.9 快速参考]]></title><description><![CDATA[ 
 <br>本章介绍了以下符号和头文件。struct file_operations 和 struct file 的字段列表在此不再重复。<br>
<br>#include &lt;linux/types.h&gt;
<br>dev_t<br>
dev_t 是内核中用于表示设备号的类型。
<br>int MAJOR(dev_t dev)
<br>int MINOR(dev_t dev)<br>
从设备号中提取主设备号和次设备号的宏。
<br>dev_t MKDEV(unsigned int major, unsigned int minor)<br>
从主设备号和次设备号构建 dev_t 数据项的宏。
<br>#include &lt;linux/fs.h&gt;<br>
“文件系统”头文件是编写设备驱动所需的头文件。许多重要的函数和数据结构在此声明。
<br>int register_chrdev_region(dev_t first, unsigned int count, char *name)
<br>int alloc_chrdev_region(dev_t *dev, unsigned int firstminor, unsigned int count, char *name)
<br>void unregister_chrdev_region(dev_t first, unsigned int count)<br>
允许驱动分配和释放设备号范围的函数。register_chrdev_region 应在提前知道所需主设备号时使用；对于动态分配，请改用 alloc_chrdev_region。
<br>int register_chrdev(unsigned int major, const char *name, struct file_operations *fops)<br>
旧的（2.6 之前）字符设备注册例程。它在 2.6 内核中被模拟，但不应在新代码中使用。如果主设备号不为 0，则它被原样使用；否则，为此设备分配一个动态号码。
<br>int unregister_chrdev(unsigned int major, const char *name)<br>
撤销 register_chrdev 所做的注册的函数。major 和 name 字符串必须包含用于注册驱动的相同值。
<br>struct file_operations
<br>struct file
<br>struct inode<br>
大多数设备驱动使用的三个重要数据结构。file_operations 结构保存字符驱动的方法；struct file 表示一个打开的文件，struct inode 表示磁盘上的文件。
<br>#include &lt;linux/cdev.h&gt;
<br>struct cdev *cdev_alloc(void)
<br>void cdev_init(struct cdev *dev, struct file_operations *fops)
<br>int cdev_add(struct cdev *dev, dev_t num, unsigned int count)
<br>void cdev_del(struct cdev *dev)<br>
用于管理 cdev 结构的函数，cdev 结构表示内核中的字符设备。
<br>#include &lt;linux/kernel.h&gt;
<br>container_of(pointer, type, field)<br>
一个方便的宏，可用于从指向包含在其中的某个结构的指针获取指向该结构的指针。
<br>#include &lt;asm/uaccess.h&gt;<br>
此头文件声明了内核代码用于在用户空间和内核空间之间移动数据的函数。
<br>unsigned long copy_from_user (void *to, const void *from, unsigned long count)
<br>unsigned long copy_to_user (void *to, const void *from, unsigned long count)<br>
在用户空间和内核空间之间复制数据。
]]></description><link>第3章-字符设备驱动/3.9-快速参考.html</link><guid isPermaLink="false">第3章 字符设备驱动/3.9 快速参考.md</guid><pubDate>Tue, 04 Mar 2025 16:02:15 GMT</pubDate></item><item><title><![CDATA[4.0 调试技术]]></title><description><![CDATA[ 
 <br>内核编程带来了独特的调试挑战。内核代码不能像应用程序那样在调试器下轻松执行，也不能轻易地进行跟踪，因为它是一组与特定进程无关的功能。内核代码的错误可能非常难以重现，并且可能会导致整个系统崩溃，从而销毁许多可以用来追踪问题的证据。<br>本章将介绍一些在这些复杂情况下监控内核代码和追踪错误的技术。]]></description><link>第4章-调试技术/4.0-调试技术.html</link><guid isPermaLink="false">第4章 调试技术/4.0 调试技术.md</guid><pubDate>Tue, 04 Mar 2025 16:03:05 GMT</pubDate></item><item><title><![CDATA[4.1 内核中的调试支持]]></title><description><![CDATA[ 
 <br>在第2章中，我们建议你构建并安装自己的内核，而不是使用发行版提供的标准内核。运行自定义内核的一个最重要的原因是，内核开发者在内核中内置了多种调试功能。这些功能可能会产生额外的输出并降低性能，因此在发行版的生产内核中通常不会启用这些功能。然而，作为内核开发者，你的优先级不同，你会愿意接受这些额外的调试支持带来的（最小）开销。<br>这里，我们列出了开发内核时应启用的配置选项。除非另有说明，所有这些选项都可以在你喜欢的内核配置工具的“kernel hacking”菜单中找到。请注意，并非所有架构都支持这些选项。<br>
<br>
CONFIG_DEBUG_KERNEL<br>
这个选项只是使其他调试选项可用；它应该被启用，但本身并不启用任何功能。

<br>
CONFIG_DEBUG_SLAB<br>
这个关键选项在内核内存分配函数中启用了多种检查；启用这些检查后，可以检测到多种内存溢出和未初始化错误。分配的每个字节在交给调用者之前会被设置为0x85，释放时则设置为0x6b。如果你在驱动程序的输出中看到这些“毒药”模式重复出现（通常在oops列表中），你就知道要查找哪种错误了。启用调试后，内核还会在每个分配的内存对象前后放置特殊的保护值；如果这些值被更改，内核会知道有人越界访问了内存分配，并会大声抱怨。还会启用各种更隐蔽错误的检查。

<br>
CONFIG_DEBUG_PAGEALLOC<br>
释放时，完整的内存页会从内核地址空间中移除。这个选项可能会显著降低性能，但它也可以快速指出某些内存损坏错误。

<br>
CONFIG_DEBUG_SPINLOCK<br>
启用此选项后，内核会捕获对未初始化自旋锁的操作以及其他各种错误（例如多次解锁）。

<br>
CONFIG_DEBUG_SPINLOCK_SLEEP<br>
此选项启用了对持有自旋锁时尝试睡眠的检查。实际上，即使调用不会睡眠，它也会抱怨任何可能睡眠的函数。

<br>
CONFIG_INIT_DEBUG<br>
标记为init（或initdata）的项在系统初始化或模块加载后会被丢弃。此选项启用了对在初始化完成后尝试访问初始化内存的代码的检查。

<br>
CONFIG_DEBUG_INFO<br>
此选项使内核在构建时包含完整的调试信息。如果你想用gdb调试内核，就需要这些信息。如果你计划使用gdb，可能还需要启用CONFIG_FRAME_POINTER。

<br>
CONFIG_MAGIC_SYSRQ<br>
启用“魔法SysRq”键。我们将在本章后面的“系统挂起”部分讨论这个键。

<br>
CONFIG_DEBUG_STACKOVERFLOW<br>
CONFIG_DEBUG_STACK_USAGE<br>
这些选项可以帮助追踪内核栈溢出。栈溢出的一个明显迹象是oops列表中没有合理的回溯信息。第一个选项在内核中添加了显式的溢出检查；第二个选项使内核监控栈的使用情况，并通过魔法SysRq键提供一些统计信息。

<br>
CONFIG_KALLSYMS<br>
此选项（位于“General setup/Standard features”下）使内核符号信息被构建到内核中；默认情况下它是启用的。符号信息用于调试上下文；如果没有它，oops列表只能以十六进制形式给出内核回溯信息，这不太有用。

<br>
CONFIG_IKCONFIG<br>
CONFIG_IKCONFIG_PROC<br>
这些选项（位于“General setup”菜单中）使完整的内核配置状态被构建到内核中，并通过/proc提供。大多数内核开发者知道他们使用的配置，不需要这些选项（它们会使内核变大）。不过，如果你试图调试别人构建的内核中的问题，这些选项可能会有用。

<br>
CONFIG_ACPI_DEBUG<br>
位于“Power management/ACPI”下。此选项启用详细的ACPI（高级配置和电源接口）调试信息，如果你怀疑与ACPI相关的问题，这可能会很有用。

<br>
CONFIG_DEBUG_DRIVER<br>
位于“Device drivers”下。启用驱动程序核心中的调试信息，这有助于追踪底层支持代码中的问题。我们将在第14章讨论驱动程序核心。

<br>
CONFIG_SCSI_CONSTANTS<br>
此选项位于“Device drivers/SCSI device support”下，构建详细的SCSI错误消息信息。如果你正在开发SCSI驱动程序，你可能需要这个选项。

<br>
CONFIG_INPUT_EVBUG<br>
此选项（位于“Device drivers/Input device support”下）启用输入事件的详细日志记录。如果你正在开发输入设备的驱动程序，此选项可能会有所帮助。但请注意此选项的安全隐患：它会记录你输入的所有内容，包括密码。

<br>
CONFIG_PROFILING<br>
此选项位于“Profiling support”下。性能分析通常用于系统性能调优，但它也可以用于追踪某些内核挂起和相关问题。

<br>我们将在讨论各种追踪内核问题的方法时重新审视上述一些选项。但首先，我们将看看经典的调试技术：打印语句。]]></description><link>第4章-调试技术/4.1-内核中的调试支持.html</link><guid isPermaLink="false">第4章 调试技术/4.1 内核中的调试支持.md</guid><pubDate>Tue, 04 Mar 2025 16:04:01 GMT</pubDate></item><item><title><![CDATA[4.2 通过打印调试]]></title><description><![CDATA[ 
 <br>最常见的调试技术是监控，这在应用程序编程中是通过在适当的位置调用printf来实现的。在调试内核代码时，你可以通过printk实现相同的目标。<br><br>我们在前面的章节中使用printk函数时，假设它的工作方式与printf类似。现在是时候介绍一些不同之处了。其中一个区别是，printk允许你通过将不同的日志级别或优先级与消息关联来对消息进行分类。你通常使用宏来指示日志级别。例如，KERN_INFO是我们之前在一些打印语句中看到的日志级别之一。日志级别宏在编译时扩展为一个字符串，并与消息文本连接；这就是为什么在以下示例中优先级和格式字符串之间没有逗号的原因。以下是两个printk命令的示例，一个是调试消息，另一个是紧急消息：<br>printk(KERN_DEBUG "Here I am: %s:%i\n", __FILE__, __LINE__);
printk(KERN_CRIT "I'm trashed; giving up on %p\n", ptr);
<br>有八种可能的日志级别字符串，定义在头文件&lt;linux/kernel.h&gt;中；我们按严重程度递减的顺序列出它们：<br>
<br>KERN_EMERG<br>
用于紧急消息，通常是在崩溃之前。
<br>KERN_ALERT<br>
需要立即采取行动的情况。
<br>KERN_CRIT<br>
关键条件，通常与严重的硬件或软件故障有关。
<br>KERN_ERR<br>
用于报告错误条件；设备驱动程序通常使用KERN_ERR来报告硬件问题。
<br>KERN_WARNING<br>
关于问题情况的警告，这些问题本身不会对系统造成严重问题。
<br>KERN_NOTICE<br>
正常但仍值得注意的情况。许多与安全相关的条件在此级别报告。
<br>KERN_INFO<br>
信息性消息。许多驱动程序在启动时打印它们找到的硬件信息。
<br>KERN_DEBUG<br>
用于调试消息。
<br>每个字符串（在宏扩展中）代表一个尖括号中的整数。整数的范围从0到7，较小的值表示较高的优先级。<br>没有指定优先级的printk语句默认为DEFAULT_MESSAGE_LOGLEVEL，在kernel/printk.c中指定为一个整数。在2.6.10内核中，DEFAULT_MESSAGE_LOGLEVEL是KERN_WARNING，但过去它曾发生变化。<br>根据日志级别，内核可能会将消息打印到当前控制台，无论是文本模式终端、串行端口还是并行打印机。如果优先级小于整数变量console_loglevel，消息将逐行传递到控制台（除非提供尾随换行符，否则不会发送任何内容）。如果系统中同时运行klogd和syslogd，内核消息将附加到/var/log/messages（或根据syslogd配置处理），而不受console_loglevel的影响。如果klogd没有运行，除非你读取/proc/kmsg（通常使用dmesg命令最容易完成），否则消息不会到达用户空间。使用klogd时，你应该记住它不会保存连续的相同行；它只保存第一行，并在稍后保存它收到的重复次数。<br>变量console_loglevel初始化为DEFAULT_CONSOLE_LOGLEVEL，可以通过sys_syslog系统调用进行修改。一种修改方法是在调用klogd时指定-c开关，如klogd手册页中所述。请注意，要更改当前值，你必须先终止klogd，然后使用-c选项重新启动它。或者，你可以编写一个程序来更改控制台日志级别。你可以在O'Reilly的FTP站点提供的源代码文件中的misc-progs/setlevel.c中找到这样一个程序的版本。新级别指定为1到8之间的整数值。如果设置为1，只有级别为0（KERN_EMERG）的消息会到达控制台；如果设置为8，包括调试消息在内的所有消息都会显示。<br>你也可以使用文本文件/proc/sys/kernel/printk读取和修改控制台日志级别。该文件包含四个整数值：当前日志级别、默认消息级别、允许的最小日志级别和启动时默认日志级别。向该文件写入单个值会更改当前日志级别；例如，你可以通过以下命令使所有内核消息出现在控制台上：<br># echo 8 &gt; /proc/sys/kernel/printk
<br>现在应该清楚为什么hello.c示例中有KERN_ALERT标记；它们是为了确保消息出现在控制台上。<br><br>Linux允许通过将消息发送到特定的虚拟控制台（如果你的控制台位于文本屏幕上）来灵活地控制控制台日志策略。默认情况下，“控制台”是当前的虚拟终端。要选择不同的虚拟终端来接收消息，你可以在任何控制台设备上发出ioctl(TIOCLINUX)命令。以下程序setconsole可用于选择接收内核消息的控制台；它必须由超级用户运行，并在misc-progs目录中提供。<br>以下是完整的程序。你应该使用一个参数调用它，指定接收消息的控制台编号。<br>int main(int argc, char **argv)
{
    char bytes[2] = {11,0}; /* 11是TIOCLINUX命令号 */
    if (argc=2) bytes[1] = atoi(argv[1]); /* 选择的控制台 */
    else {
    fprintf(stderr, "%s: need a single argv",argv[0]); exit(1);
    }
    if (ioctl(STDIN_FILENO, TIOCLINUX, bytes)&lt;0) { /* 使用stdin */
    fprintf(stderr,"%s: ioctl(stdin, TIOCLINUX): %s\n",
    argv[0], strerror(errno));
    }
    exit(1);
}
<br>setconsole使用特殊的ioctl命令TIOCLINUX，它实现了Linux特定的功能。要使用TIOCLINUX，你需要传递一个指向字节数组的参数。数组的第一个字节是请求的子命令号，后面的字节是子命令特定的。在setconsole中，使用了子命令11，下一个字节（存储在bytes[1]中）标识了虚拟控制台。TIOCLINUX的完整描述可以在内核源代码的drivers/char/tty_io.c中找到。<br><br>printk函数将消息写入一个长度为__LOG_BUF_LEN字节的环形缓冲区：该值在配置内核时选择，范围从4 KB到1 MB。然后该函数唤醒任何等待消息的进程，即任何在syslog系统调用中睡眠或正在读取/proc/kmsg的进程。这两个接口几乎等效，但请注意，从/proc/kmsg读取会消耗日志缓冲区中的数据，而syslog系统调用可以选择返回日志数据的同时保留给其他进程。通常，读取/proc文件更容易，并且是klogd的默认行为。dmesg命令可用于查看缓冲区的内容而不刷新它；实际上，该命令将缓冲区的全部内容返回到stdout，无论它是否已被读取。<br>如果你在停止klogd后手动读取内核消息，你会发现/proc文件看起来像一个FIFO，因为读取器会阻塞，等待更多数据。显然，如果klogd或其他进程已经在读取相同的数据，你就不能以这种方式读取消息，因为你会争用数据。<br>如果环形缓冲区填满，printk会回绕并开始将新数据添加到缓冲区的开头，覆盖最旧的数据。因此，日志记录过程会丢失最旧的数据。与使用这种环形缓冲区的优势相比，这个问题可以忽略不计。例如，环形缓冲区允许系统在没有日志记录进程的情况下运行，同时通过覆盖旧数据来最小化内存浪费（如果没有人读取它）。Linux消息传递方法的另一个特点是，printk可以从任何地方调用，甚至从中断处理程序中调用，且没有限制可以打印多少数据。唯一的缺点是可能会丢失一些数据。<br>如果klogd进程正在运行，它会检索内核消息并将其分派给syslogd，syslogd然后检查/etc/syslog.conf以确定如何处理它们。syslogd根据设施和优先级区分消息；设施和优先级的允许值在&lt;sys/syslog.h&gt;中定义。内核消息由LOG_KERN设施记录，优先级对应于printk中使用的优先级（例如，LOG_ERR用于KERN_ERR消息）。如果klogd没有运行，数据将保留在环形缓冲区中，直到有人读取它或缓冲区溢出。<br>如果你想避免系统日志被驱动程序的监控消息淹没，你可以指定klogd的-f（文件）选项，指示它将消息保存到特定文件，或者自定义/etc/syslog.conf以满足你的需求。另一种可能性是采取蛮力方法：杀死klogd并在未使用的虚拟终端上详细打印消息，或者从未使用的xterm中发出cat /proc/kmsg命令。<br><br>在驱动程序开发的早期阶段，printk可以极大地帮助调试和测试新代码。另一方面，当你正式发布驱动程序时，你应该删除或至少禁用这些打印语句。不幸的是，你可能会发现，一旦你认为不再需要这些消息并删除它们，你在驱动程序中实现了一个新功能（或有人发现了一个错误），你希望至少重新启用其中一条消息。有几种方法可以解决这两个问题，既可以全局启用或禁用调试消息，也可以单独打开或关闭消息。<br>这里我们展示了一种编码printk调用的方法，以便你可以单独或全局地打开或关闭它们；该技术依赖于定义一个宏，该宏在你希望时解析为printk（或printf）调用：<br>
<br>每个打印语句可以通过删除或添加宏名称中的单个字母来启用或禁用。
<br>所有消息可以通过在编译前更改CFLAGS变量的值来一次性禁用。
<br>例如，使用setlevel 8; setconsole 10设置终端10以显示消息。
<br>以下代码片段实现了这些功能，并直接来自头文件scull.h：<br>#undef PDEBUG /* 取消定义它，以防万一 */
#ifdef SCULL_DEBUG
# ifdef KERNEL
/* 如果调试开启，并且在内核空间 */
# define PDEBUG(fmt, args...) printk( KERN_DEBUG "scull: " fmt, ## args)
# else
/* 在用户空间 */
# define PDEBUG(fmt, args...) fprintf(stderr, fmt, ## args)
# endif
#else
# define PDEBUG(fmt, args...) /* 不调试：什么都不做 */
#endif

#undef PDEBUGG
#define PDEBUGG(fmt, args...) /* 什么都不做：它是一个占位符 */
<br>符号PDEBUG根据是否定义了SCULL_DEBUG来定义或取消定义，并以适合代码运行环境的方式显示信息：在内核中使用内核调用printk，在用户空间中使用libc调用fprintf到标准错误。另一方面，PDEBUGG符号什么都不做；它可以用于轻松地“注释”打印语句，而无需完全删除它们。<br>为了进一步简化过程，请将以下行添加到你的Makefile中：<br># 注释/取消注释以下行以禁用/启用调试
DEBUG = y

# 将调试标志（或不）添加到CFLAGS
ifeq ($(DEBUG),y)
    DEBFLAGS = -O -g -DSCULL_DEBUG # "-O" 需要扩展内联
else
    DEBFLAGS = -O2
endif

CFLAGS += $(DEBFLAGS)
<br>本节中显示的宏依赖于gcc对ANSI C预处理器的扩展，该扩展支持具有可变数量参数的宏。这种gcc依赖不应该是一个问题，因为内核本身严重依赖于gcc特性。此外，Makefile依赖于GNU的make版本；内核已经依赖于GNU make，所以这种依赖也不是问题。<br>如果你熟悉C预处理器，你可以扩展给定的定义以实现“调试级别”的概念，定义不同的级别并为每个级别分配一个整数值（或位掩码）以确定其详细程度。<br>但每个驱动程序都有自己的特性和监控需求。优秀编程的艺术在于在灵活性和效率之间选择最佳权衡，我们无法告诉你什么对你最好。请记住，预处理器条件（以及代码中的常量表达式）在编译时执行，因此你必须重新编译以打开或关闭消息。一个可能的替代方法是使用C条件，它们在运行时执行，因此允许你在程序执行期间打开或关闭消息。这是一个很好的功能，但它会在每次执行代码时增加额外的处理，即使消息被禁用，这可能会影响性能。有时这种性能损失是不可接受的。<br>本节中显示的宏在许多情况下都证明是有用的，唯一的缺点是需要在更改消息后重新编译模块。<br><br>如果你不小心，你可能会发现自己用printk生成了数千条消息，淹没控制台，甚至可能溢出系统日志文件。当使用慢速控制台设备（例如串行端口）时，过高的消息速率也会减慢系统速度或使其无响应。当控制台不停地喷出数据时，很难掌握系统出了什么问题。因此，你应该非常小心地打印内容，特别是在驱动程序的发布版本中，尤其是在初始化完成后。一般来说，生产代码在正常操作期间不应打印任何内容；打印输出应该是需要关注的异常情况的指示。<br>另一方面，你可能希望在设备停止工作时发出日志消息。但你应该小心不要过度。一个在失败面前永远继续的愚蠢进程每秒可以生成数千次重试；如果你的驱动程序每次打印“我的设备坏了”消息，它可能会产生大量输出，并可能在控制台设备慢时占用CPU——即使控制台是串行端口或行式打印机，也不能使用中断来驱动控制台。<br>在许多情况下，最好的行为是设置一个标志，表示“我已经抱怨过这个问题了”，并且在标志设置后不再打印任何进一步的消息。在其他情况下，有理由偶尔发出“设备仍然坏了”的通知。内核提供了一个函数，在这种情况下可能会有所帮助：<br>int printk_ratelimit(void);
<br>在考虑打印可能经常重复的消息之前，应该调用此函数。如果函数返回非零值，则继续打印你的消息，否则跳过它。因此，典型的调用如下所示：<br>if (printk_ratelimit())
    printk(KERN_NOTICE "The printer is still on fire\n");
<br>printk_ratelimit 通过跟踪发送到控制台的消息数量来工作。当输出水平超过阈值时，printk_ratelimit 开始返回 0，并导致消息被丢弃。<br>printk_ratelimit 的行为可以通过修改 /proc/sys/kernel/printk_ratelimit（重新启用消息前等待的秒数）和 /proc/sys/kernel/printk_ratelimit_burst（在速率限制之前接受的消息数量）来自定义。<br><br>偶尔，当从驱动程序中打印消息时，你可能希望打印与硬件相关的设备号。打印主设备号和次设备号并不难，但为了保持一致性，内核提供了几个实用宏（定义在 &lt;linux/kdev_t.h&gt; 中）来完成这个任务：<br>int print_dev_t(char *buffer, dev_t dev);
char *format_dev_t(char *buffer, dev_t dev);
<br>这两个宏将设备号编码到给定的缓冲区中；唯一的区别是 print_dev_t 返回打印的字符数，而 format_dev_t 返回缓冲区指针；因此，它可以直接用作 printk 调用的参数，尽管必须记住 printk 在提供尾随换行符之前不会刷新。缓冲区应足够大以容纳设备号；考虑到未来内核版本中可能会出现 64 位设备号，缓冲区应至少为 20 字节长。]]></description><link>第4章-调试技术/4.2-通过打印调试.html</link><guid isPermaLink="false">第4章 调试技术/4.2 通过打印调试.md</guid><pubDate>Tue, 04 Mar 2025 16:12:37 GMT</pubDate></item><item><title><![CDATA[4.3 通过查询调试]]></title><description><![CDATA[ 
 <br>上一节描述了 printk 的工作原理及其使用方法。但它没有讨论它的缺点。<br>大量使用 printk 会显著减慢系统速度，即使你降低 console_loglevel 以避免加载控制台设备，因为 syslogd 会不断同步其输出文件；因此，打印的每一行都会导致磁盘操作。从 syslogd 的角度来看，这是正确的实现。它试图将所有内容写入磁盘，以防系统在打印消息后立即崩溃；然而，你不希望仅仅为了调试消息而减慢系统速度。这个问题可以通过在 /etc/syslog.conf 中的日志文件名前加上连字符来解决。修改配置文件的问题是，调试完成后，修改可能会保留在那里，尽管在正常系统操作期间你希望消息尽快刷新到磁盘。另一种替代方法是运行 klogd 以外的程序（例如之前建议的 cat /proc/kmsg），但这可能无法为正常系统操作提供合适的环境。<br>通常情况下，获取相关信息的最佳方法是在需要时查询系统，而不是不断生成数据。事实上，每个 Unix 系统都提供了许多工具来获取系统信息：ps、netstat、vmstat 等。<br>驱动程序开发者有几种技术可以查询系统：在 /proc 文件系统中创建文件、使用 ioctl 驱动程序方法以及通过 sysfs 导出属性。使用 sysfs 需要相当多的驱动程序模型背景。我们将在第 14 章讨论它。<br><br>/proc 文件系统是一个特殊的、由软件创建的文件系统，内核用它来向外界导出信息。/proc 下的每个文件都与一个内核函数相关联，该函数在文件被读取时动态生成文件的内容。我们已经看到了一些这样的文件在运行；例如，/proc/modules 总是返回当前加载的模块列表。<br>/proc 在 Linux 系统中被广泛使用。现代 Linux 发行版上的许多实用程序，如 ps、top 和 uptime，都从 /proc 获取信息。一些设备驱动程序也通过 /proc 导出信息，你的驱动程序也可以这样做。/proc 文件系统是动态的，因此你的模块可以随时添加或删除条目。<br>功能齐全的 /proc 条目可能非常复杂；除了其他功能外，它们还可以被写入和读取。大多数情况下，/proc 条目是只读文件。本节关注的是简单的只读情况。那些对实现更复杂功能感兴趣的人可以在这里找到基础知识；然后可以查阅内核源代码以获取完整的信息。<br>在继续之前，我们应该提到，不鼓励在 /proc 下添加文件。内核开发者认为 /proc 文件系统有点失控，已经远远超出了其原始目的（即提供系统中运行的进程的信息）。在新代码中提供信息的推荐方式是通过 sysfs。正如前面提到的，使用 sysfs 需要理解 Linux 设备模型，我们直到第 14 章才会讨论它。与此同时，/proc 下的文件稍微容易创建，并且完全适合调试目的，因此我们在这里介绍它们。<br><br>所有与 /proc 一起工作的模块都应包含 &lt;linux/proc_fs.h&gt; 以定义适当的函数。<br>要创建一个只读的 /proc 文件，你的驱动程序必须实现一个函数，在文件被读取时生成数据。当某个进程读取文件（使用 read 系统调用）时，请求通过此函数到达你的模块。我们将首先查看此函数，然后在本节后面讨论注册接口。<br>当进程从你的 /proc 文件读取时，内核会分配一页内存（即 PAGE_SIZE 字节），驱动程序可以将数据写入该内存以返回给用户空间。该缓冲区会传递给你的函数，该函数是一个名为 read_proc 的方法：<br>int (*read_proc)(char *page, char **start, off_t offset, int count, int *eof, void *data);
<br>page 指针是你将写入数据的缓冲区；start 由函数用于指示在 page 中写入了有趣数据的位置（稍后会详细介绍）；offset 和 count 的含义与 read 方法相同。eof 参数指向一个整数，驱动程序必须设置该整数以表示没有更多数据要返回，而 data 是一个驱动程序特定的数据指针，你可以用于内部簿记。<br>此函数应返回实际放置在 page 缓冲区中的数据字节数，就像其他文件的 read 方法一样。其他输出值是 eof 和 start。eof 是一个简单的标志，但 start 值的用途稍微复杂一些；其目的是帮助实现大于一页的 /proc 文件。<br>start 参数的使用有些非传统。其目的是指示在 page 中返回给用户的数据的位置。当你的 proc_read 方法被调用时，*start 将为 NULL。如果你将其保留为 NULL，内核会假定数据已按 offset 为 0 的方式放入 page 中；换句话说，它假定一个简单的 proc_read 版本，该版本将虚拟文件的全部内容放入 page 中，而不考虑 offset 参数。相反，如果你将 *start 设置为非 NULL 值，内核会假定 *start 指向的数据考虑了 offset，并准备直接返回给用户。通常，返回少量数据的简单 proc_read 方法会忽略 start。更复杂的方法将 *start 设置为 page，并仅将数据从请求的偏移量开始放置在那里。<br>长期以来，/proc 文件还存在另一个主要问题，start 也旨在解决这个问题。有时，内核数据结构的 ASCII 表示在连续的 read 调用之间会发生变化，因此读取进程可能会发现从一个调用到下一个调用的数据不一致。如果 *start 设置为一个小的整数值，调用者会使用它来独立于你返回的数据量递增 flip-&gt;f_pos，从而使 f_pos 成为你的 read_proc 过程的内部记录号。例如，如果你的 read_proc 函数从一个大的结构数组中返回信息，并且在第一次调用中返回了五个结构，*start 可以设置为 5。下一次调用会提供相同的值作为偏移量；驱动程序然后知道从数组中的第六个结构开始返回数据。这被其作者承认是一个“hack”，可以在 fs/proc/generic.c 中看到。<br>请注意，实现大型 /proc 文件有更好的方法；它被称为 seq_file，我们稍后会讨论它。首先，我们来看一个示例。以下是 scull 设备的一个简单（虽然有点丑陋）的 read_proc 实现：<br>int scull_read_procmem(char *buf, char **start, off_t offset,
    int count, int *eof, void *data)
{
    int i, j, len = 0;
    int limit = count - 80; /* 不要打印超过这个值 */

    for (i = 0; i &lt; scull_nr_devs &amp;&amp; len &lt;= limit; i++) {
        struct scull_dev *d = &amp;scull_devices[i];
        struct scull_qset *qs = d-&gt;data;
        if (down_interruptible(&amp;d-&gt;sem))
            return -ERESTARTSYS;
        len += sprintf(buf+len, "\nDevice %i: qset %i, q %i, sz %li\n",
            i, d-&gt;qset, d-&gt;quantum, d-&gt;size);
        for (j = 0; qs &amp;&amp; len &lt;= limit; qs = qs-&gt;next) { /* 扫描列表 */
            len += sprintf(buf + len, " item at %p, qset at %p\n",
                qs, qs-&gt;data);
            if (qs-&gt;data &amp;&amp; !qs-&gt;next) /* 仅转储最后一项 */
                for (j = 0; j &lt; d-&gt;qset; j++) {
                    if (qs-&gt;data[j])
                        len += sprintf(buf + len,
                            " % 4i: %8p\n",
                            j, qs-&gt;data[j]);
                }
        }
        up(&amp;scull_devices[i].sem);
    }
    *eof = 1;
    return len;
}
<br>这是一个相当典型的 read_proc 实现。它假定永远不会需要生成超过一页的数据，因此忽略了 start 和 offset 值。然而，它小心地不溢出其缓冲区，以防万一。<br><br>如果你阅读内核源代码，你可能会遇到使用旧接口实现 /proc 文件的代码：<br>int (*get_info)(char *page, char **start, off_t offset, int count);
<br>所有参数的含义与 read_proc 相同，但缺少 eof 和 data 参数。此接口仍然受支持，但未来可能会消失；新代码应改用 read_proc 接口。<br><br>一旦你定义了一个 read_proc 函数，你需要将其连接到 /proc 层次结构中的一个条目。这是通过调用 create_proc_read_entry 来完成的：<br>struct proc_dir_entry *create_proc_read_entry(const char *name,
    mode_t mode, struct proc_dir_entry *base,
    read_proc_t *read_proc, void *data);
<br>这里，name 是要创建的文件的名称，mode 是文件的保护掩码（可以传递 0 以使用系统范围的默认值），base 指示文件应创建的目录（如果 base 为 NULL，则文件在 /proc 根目录中创建），read_proc 是实现文件的 read_proc 函数，data 被内核忽略（但传递给 read_proc）。以下是 scull 用于使其 /proc 函数作为 /proc/scullmem 可用的调用：<br>create_proc_read_entry("scullmem", 0 /* 默认模式 */,
    NULL /* 父目录 */, scull_read_procmem,
    NULL /* 客户端数据 */);
<br>在这里，我们在 /proc 下直接创建了一个名为 scullmem 的文件，具有默认的、全局可读的保护。<br>目录条目指针可用于在 /proc 下创建整个目录层次结构。请注意，条目可以更容易地放置在 /proc 的子目录中，只需在条目名称中给出目录名称——只要目录本身已经存在。例如，一个（经常被忽略的）约定说，与设备驱动程序相关的 /proc 条目应放在 drivers/ 子目录中，scull 可以通过将其名称指定为 drivers/scullmem 将其条目放在那里。<br>当然，/proc 中的条目应在模块卸载时删除。remove_proc_entry 是撤销 create_proc_read_entry 所做操作的函数：<br>remove_proc_entry("scullmem", NULL /* 父目录 */);
<br>未能删除条目可能会导致在不希望的时间调用，或者如果你的模块已卸载，可能会导致内核崩溃。<br>使用 /proc 文件时，你必须记住实现中的一些麻烦——难怪现在不鼓励使用它。<br>最重要的问题是与删除 /proc 条目有关。这种删除很可能在文件正在使用时发生，因为 /proc 条目没有所有者，因此使用它们不会影响模块的引用计数。这个问题可以通过在删除模块之前运行 sleep 100 &lt; /proc/myfile 来简单地触发。<br>另一个问题与注册两个同名的条目有关。内核信任驱动程序，不会检查名称是否已注册，因此如果你不小心，可能会以相同的名称注册两个或多个条目。这是一个在课堂上已知会发生的问题，这些条目在访问时和调用 remove_proc_entry 时都是不可区分的。<br><br>正如我们上面提到的，在 /proc 下实现大文件有点尴尬。随着时间的推移，当输出量变大时，/proc 方法的实现以错误著称。为了清理 /proc 代码并使内核程序员的生活更轻松，添加了 seq_file 接口。该接口提供了一组简单的函数来实现大型内核虚拟文件。<br>seq_file 接口假定你正在创建一个虚拟文件，该文件逐步遍历必须返回给用户空间的项目序列。要使用 seq_file，你必须创建一个简单的“迭代器”对象，该对象可以在序列中建立位置、向前移动并输出序列中的一个项目。听起来可能很复杂，但实际上过程相当简单。我们将通过创建 scull 驱动程序中的 /proc 文件来展示它是如何完成的。<br>第一步，不可避免地是包含 &lt;linux/seq_file.h&gt;。然后你必须创建四个迭代器方法，称为 start、next、stop 和 show。<br>start 方法总是首先被调用。此函数的原型是：<br>void *start(struct seq_file *sfile, loff_t *pos);
<br>sfile 参数几乎总是可以忽略。pos 是一个整数位置，指示读取应从何处开始。位置的解释完全取决于实现；它不必是结果文件中的字节位置。由于 seq_file 实现通常逐步遍历一系列有趣的项目，因此位置通常被解释为指向序列中下一个项目的游标。scull 驱动程序将每个设备解释为序列中的一个项目，因此传入的 pos 只是 scull_devices 数组的索引。因此，scull 中使用的 start 方法是：<br>static void *scull_seq_start(struct seq_file *s, loff_t *pos)
{
    if (*pos &gt;= scull_nr_devs)
        return NULL; /* 没有更多内容可读 */
    return scull_devices + *pos;
}
<br>返回值（如果非 NULL）是一个私有值，迭代器实现可以使用它。<br>next 函数应将迭代器移动到下一个位置，如果没有剩余内容则返回 NULL。此方法的原型是：<br>void *next(struct seq_file *sfile, void *v, loff_t *pos);
<br>这里，v 是上一次调用 start 或 next 返回的迭代器，pos 是文件中的当前位置。next 应递增 pos 指向的值；根据你的迭代器的工作方式，你可能（尽管可能不会）希望将 pos 递增超过 1。以下是 scull 的做法：<br>static void *scull_seq_next(struct seq_file *s, void *v, loff_t *pos)
{
    (*pos)++;
    if (*pos &gt;= scull_nr_devs)
        return NULL;
    return scull_devices + *pos;
}
<br>当内核完成迭代器时，它会调用 stop 进行清理：<br>void stop(struct seq_file *sfile, void *v);
<br>scull 实现没有清理工作要做，因此其 stop 方法为空。<br>值得注意的是，seq_file 代码在设计上不会在 start 和 stop 调用之间睡眠或执行其他非原子任务。你还保证在调用 start 后不久会看到一个 stop 调用。因此，你的 start 方法获取信号量或自旋锁是安全的。只要你的其他 seq_file 方法是原子的，整个调用序列就是原子的。（如果这段文字对你没有意义，请在阅读下一章后再回来看看。）<br>在这些调用之间，内核调用 show 方法以实际向用户空间输出一些有趣的内容。此方法的原型是：<br>int show(struct seq_file *sfile, void *v);
<br>此方法应为迭代器 v 指示的序列中的项目创建输出。然而，它不应使用 printk；相反，有一组特殊的函数用于 seq_file 输出：<br>
<br>
int seq_printf(struct seq_file *sfile, const char *fmt, ...);<br>
这是 seq_file 实现的 printf 等效函数；它采用通常的格式字符串和额外的值参数。你还必须传递 show 函数给出的 seq_file 结构。如果 seq_printf 返回非零值，则表示缓冲区已满，输出被丢弃。大多数实现忽略返回值。

<br>
int seq_putc(struct seq_file *sfile, char c);  

<br>
int seq_puts(struct seq_file *sfile, const char *s);<br>
这些是用户空间 putc 和 puts 函数的等效函数。

<br>
int seq_escape(struct seq_file *m, const char *s, const char *esc);<br>
此函数等效于 seq_puts，但 s 中的任何字符如果在 esc 中也找到，则以八进制格式打印。esc 的常见值是 " \t\n\"，这可以防止嵌入的空白字符弄乱输出并可能混淆 shell 脚本。

<br>
int seq_path(struct seq_file *sfile, struct vfsmount *m, struct dentry *dentry, char *esc);<br>
此函数可用于输出与给定目录条目关联的文件名。它在设备驱动程序中不太可能有用；我们在这里包含它是为了完整性。

<br>回到我们的示例；scull 中使用的 show 方法是：<br>static int scull_seq_show(struct seq_file *s, void *v)
{
    struct scull_dev *dev = (struct scull_dev *) v;
    struct scull_qset *d;
    int i;

    if (down_interruptible(&amp;dev-&gt;sem))
        return -ERESTARTSYS;
    seq_printf(s, "\nDevice %i: qset %i, q %i, sz %li\n",
        (int) (dev - scull_devices), dev-&gt;qset,
        dev-&gt;quantum, dev-&gt;size);
    for (d = dev-&gt;data; d; d = d-&gt;next) { /* 扫描列表 */
        seq_printf(s, " item at %p, qset at %p\n", d, d-&gt;data);
        if (d-&gt;data &amp;&amp; !d-&gt;next) /* 仅转储最后一项 */
            for (i = 0; i &lt; dev-&gt;qset; i++) {
                if (d-&gt;data[i])
                    seq_printf(s, " % 4i: %8p\n",
                        i, d-&gt;data[i]);
            }
    }
    up(&amp;dev-&gt;sem);
    return 0;
}
<br>在这里，我们终于解释了我们的“迭代器”值，它只是一个指向 scull_dev 结构的指针。<br>现在 scull 有了完整的迭代器操作集，它必须将它们打包并连接到 /proc 中的一个文件。第一步是通过填充一个 seq_operations 结构来完成：<br>static struct seq_operations scull_seq_ops = {
    .start = scull_seq_start,
    .next = scull_seq_next,
    .stop = scull_seq_stop,
    .show = scull_seq_show
};
<br>有了这个结构，我们必须创建一个内核理解的文件实现。我们不使用前面描述的 read_proc 方法；当使用 seq_file 时，最好以稍微低一点的级别连接到 /proc。这意味着创建一个 file_operations 结构（是的，与字符驱动程序使用的结构相同），实现内核处理文件读取和查找所需的所有操作。幸运的是，这个任务很简单。第一步是创建一个 open 方法，将文件连接到 seq_file 操作：<br>static int scull_proc_open(struct inode *inode, struct file *file)
{
    return seq_open(file, &amp;scull_seq_ops);
}
<br>seq_open 的调用将文件结构与上面定义的序列操作连接起来。事实证明，open 是我们必须自己实现的唯一文件操作，因此我们现在可以设置我们的 file_operations 结构：<br>static struct file_operations scull_proc_ops = {
    .owner = THIS_MODULE,
    .open = scull_proc_open,
    .read = seq_read,
    .llseek = seq_lseek,
    .release = seq_release
};
<br>在这里，我们指定了我们自己的 open 方法，但使用现成的方法 seq_read、seq_lseek 和 seq_release 来处理其他所有事情。<br>最后一步是在 /proc 中创建实际的文件：<br>entry = create_proc_entry("scullseq", 0, NULL);
if (entry)
    entry-&gt;proc_fops = &amp;scull_proc_ops;
<br>我们没有使用 create_proc_read_entry，而是调用了更低级别的 create_proc_entry，其原型如下：<br>struct proc_dir_entry *create_proc_entry(const char *name,
    mode_t mode,
    struct proc_dir_entry *parent);
<br>参数与 create_proc_read_entry 中的等效参数相同：文件的名称、其保护模式和父目录。<br>通过上述代码，scull 有了一个新的 /proc 条目，看起来与之前的条目非常相似。然而，它更优越，因为无论输出变得多大，它都能正常工作，正确处理查找，并且通常更容易阅读和维护。我们建议使用 seq_file 来实现包含多行输出的文件。<br><br>ioctl 是一个系统调用，它作用于文件描述符；它接收一个标识要执行的命令的数字和（可选的）另一个参数，通常是一个指针。作为使用 /proc 文件系统的替代方法，你可以实现一些专门用于调试的 ioctl 命令。这些命令可以将相关的数据结构从驱动程序复制到用户空间，你可以在那里检查它们。<br>使用 ioctl 获取信息比使用 /proc 稍微困难一些，因为你需要另一个程序来发出 ioctl 并显示结果。这个程序必须编写、编译并与你正在测试的模块保持同步。另一方面，驱动程序端的代码可能比实现 /proc 文件所需的代码更容易。<br>有时 ioctl 是获取信息的最佳方式，因为它比读取 /proc 更快。如果必须在数据写入屏幕之前对其执行一些工作，以二进制形式检索数据比读取文本文件更有效。此外，ioctl 不需要将数据分割成小于一页的片段。<br>ioctl 方法的另一个有趣的优势是，即使调试被禁用，信息检索命令也可以留在驱动程序中。与 /proc 文件不同，/proc 文件对任何查看目录的人都是可见的（太多人可能会好奇“那个奇怪的文件是什么”），未记录的 ioctl 命令可能会被忽视。此外，如果驱动程序发生奇怪的事情，它们仍然存在。唯一的缺点是模块会稍微变大。]]></description><link>第4章-调试技术/4.3-通过查询调试.html</link><guid isPermaLink="false">第4章 调试技术/4.3 通过查询调试.md</guid><pubDate>Tue, 04 Mar 2025 16:14:35 GMT</pubDate></item><item><title><![CDATA[4.4 通过观察调试]]></title><description><![CDATA[ 
 <br>有时，通过观察用户空间应用程序的行为可以追踪到一些小问题。观察程序还可以帮助建立对驱动程序正常工作的信心。例如，我们在查看 scull 的 read 实现如何响应不同数据量的读取请求后，对其正常工作感到有信心。<br>有各种方法可以观察用户空间程序的工作。你可以在其上运行调试器以逐步执行其函数，添加打印语句，或在 strace 下运行程序。这里我们只讨论最后一种技术，当真正的目标是检查内核代码时，它最有趣。<br>strace 命令是一个强大的工具，它显示用户空间程序发出的所有系统调用。它不仅显示调用，还可以显示调用的参数及其返回值的符号形式。当系统调用失败时，会显示错误的符号值（例如 ENOMEM）和相应的字符串（内存不足）。strace 有许多命令行选项；最有用的选项是 -t 以显示每次调用执行的时间，-T 以显示调用中花费的时间，-e 以限制跟踪的调用类型，以及 -o 以将输出重定向到文件。默认情况下，strace 将跟踪信息打印到 stderr。<br>strace 从内核本身接收信息。这意味着无论程序是否使用调试支持编译（gcc 的 -g 选项），都可以对其进行跟踪。你还可以将跟踪附加到正在运行的进程，类似于调试器可以连接到正在运行的进程并控制它的方式。<br>跟踪信息通常用于支持发送给应用程序开发者的错误报告，但它对内核程序员也非常有用。我们已经看到驱动程序代码通过响应系统调用来执行；strace 允许我们检查每个调用的输入和输出数据的一致性。<br>例如，以下屏幕转储显示了运行命令 strace ls /dev &gt; /dev/scull0 的最后几行：<br>open("/dev", O_RDONLY|O_NONBLOCK|O_LARGEFILE|O_DIRECTORY) = 3
fstat64(3, {st_mode=S_IFDIR|0755, st_size=24576, ...}) = 0
fcntl64(3, F_SETFD, FD_CLOEXEC) = 0
getdents64(3, /* 141 entries */, 4096) = 4088
[...]
getdents64(3, /* 0 entries */, 4096) = 0
close(3) = 0
[...]
fstat64(1, {st_mode=S_IFCHR|0664, st_rdev=makedev(254, 0), ...}) = 0
write(1, "MAKEDEV\nadmmidi0\nadmmidi1\nadmmid"..., 4096) = 4000
write(1, "b\nptywc\nptywd\nptywe\nptywf\nptyx0\n"..., 96) = 96
write(1, "b\nptyxc\nptyxd\nptyxe\nptyxf\nptyy0\n"..., 4096) = 3904
write(1, "s17\nvcs18\nvcs19\nvcs2\nvcs20\nvcs21"..., 192) = 192
write(1, "\nvcs47\nvcs48\nvcs49\nvcs5\nvcs50\nvc"..., 673) = 673
close(1) = 0
exit_group(0) = ?
<br>从第一个 write 调用中可以看出，ls 在查看目标目录后，尝试写入 4 KB。奇怪的是（对于 ls），只写入了 4000 字节，并且操作被重试。然而，我们知道 scull 中的 write 实现一次写入一个量子，因此我们可以预期部分写入。经过几个步骤后，一切顺利通过，程序成功退出。<br>作为另一个示例，让我们读取 scull 设备（使用 wc 命令）：<br>[...]
open("/dev/scull0", O_RDONLY|O_LARGEFILE) = 3
fstat64(3, {st_mode=S_IFCHR|0664, st_rdev=makedev(254, 0), ...}) = 0
read(3, "MAKEDEV\nadmmidi0\nadmmidi1\nadmmid"..., 16384) = 4000
read(3, "b\nptywc\nptywd\nptywe\nptywf\nptyx0\n"..., 16384) = 4000
read(3, "s17\nvcs18\nvcs19\nvcs2\nvcs20\nvcs21"..., 16384) = 865
read(3, "", 16384) = 0
fstat64(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 1), ...}) = 0
write(1, "8865 /dev/scull0\n", 17) = 17
close(3) = 0
exit_group(0) = ?
<br>正如预期的那样，read 一次只能检索 4000 字节，但数据总量与上一个示例中写入的数据相同。有趣的是，与上一个跟踪相比，此示例中的重试是如何组织的。wc 针对快速读取进行了优化，因此它绕过了标准库，尝试通过单个系统调用读取更多数据。你可以从跟踪中的 read 行中看到我们尝试一次读取 16 KB。<br>Linux 专家可以从 strace 的输出中找到许多有用的信息。如果你对所有这些符号感到困惑，你可以限制自己观察文件方法（open、read 等）如何使用 -e 标志工作。<br>个人认为，strace 最有用的地方是精确定位系统调用中的运行时错误。通常，应用程序或演示程序中的 perror 调用不够详细，无法用于调试，能够准确告诉哪个系统调用的哪个参数触发了错误可能会非常有帮助。]]></description><link>第4章-调试技术/4.4-通过观察调试.html</link><guid isPermaLink="false">第4章 调试技术/4.4 通过观察调试.md</guid><pubDate>Tue, 04 Mar 2025 16:15:07 GMT</pubDate></item><item><title><![CDATA[4.5 调试系统故障]]></title><description><![CDATA[ 
 <br>即使你使用了所有的监控和调试技术，有时驱动程序中仍然存在错误，系统在执行驱动程序时会崩溃。当这种情况发生时，重要的是能够收集尽可能多的信息来解决问题。<br>请注意，“故障”并不意味着“恐慌”。Linux 代码足够健壮，能够优雅地响应大多数错误：故障通常会导致当前进程被销毁，而系统继续运行。系统可能会恐慌，如果故障发生在进程上下文之外，或者系统的某些关键部分受到损害，它可能会恐慌。但当问题是由于驱动程序错误引起的时，通常只会导致使用驱动程序的进程突然死亡。当进程被销毁时，唯一不可恢复的损害是分配给进程上下文的一些内存丢失；例如，驱动程序通过 kmalloc 分配的动态列表可能会丢失。然而，由于内核在进程死亡时为任何打开的设备调用 close 操作，你的驱动程序可以释放 open 方法分配的内容。<br>即使 oops 通常不会导致整个系统崩溃，你可能会发现自己在 oops 后需要重新启动。一个有问题的驱动程序可能会使硬件处于不可用状态，使内核资源处于不一致状态，或者在最坏的情况下，随机损坏内核内存。通常，你可以简单地卸载有问题的驱动程序，并在 oops 后重试。然而，如果你看到任何表明整个系统不正常的迹象，通常最好立即重新启动。<br>我们已经说过，当内核代码行为不当时，控制台上会打印一条信息丰富的消息。下一节将解释如何解码和使用这些消息。即使对新手来说，它们看起来相当晦涩，处理器转储充满了有趣的信息，通常足以在不进行额外测试的情况下精确定位程序错误。<br><br>大多数错误表现为 NULL 指针解引用或使用其他不正确的指针值。此类错误的通常结果是 oops 消息。<br>处理器使用的几乎所有地址都是虚拟地址，并通过复杂的页表结构映射到物理地址（例外情况是与内存管理子系统本身一起使用的物理地址）。当解引用无效指针时，分页机制无法将指针映射到物理地址，处理器向操作系统发出页面错误信号。如果地址无效，内核无法“调入”缺失的地址；如果这种情况发生在处理器处于超级用户模式时，它（通常）会生成一个 oops。<br>oops 显示故障时的处理器状态，包括 CPU 寄存器的内容和其他看似难以理解的信息。该消息由故障处理程序（arch/*/kernel/traps.c）中的 printk 语句生成，并按照前面“printk”部分中描述的方式分派。<br>让我们看一个这样的消息。以下是在运行 2.6 版本内核的 PC 上解引用 NULL 指针的结果。这里最相关的信息是指令指针（EIP），即错误指令的地址。<br>Unable to handle kernel NULL pointer dereference at virtual address 00000000
printing eip:
d083a064
Oops: 0002 [#1]
SMP
CPU: 0
EIP: 0060:[&lt;d083a064&gt;] Not tainted
EFLAGS: 00010246 (2.6.6)
EIP is at faulty_write+0x4/0x10 [faulty]
eax: 00000000 ebx: 00000000 ecx: 00000000 edx: 00000000
esi: cf802460 edi: cf802480 ebp: 00000005 esp: c31c5f74
ds: 007b es: 007b ss: 0088
Process bash (pid: 2086, threadinfo=c31c4000 task=cfaa6c0)
Stack: c0150558 cf802460 080e9408 00000005 cf802480 00000000 cf802460 cf802460 ffffff7 080e9408 c31c4000 c0150682 cf802460 080e9408 00000005 cf802480 00000000 00000001 00000005 c0103ff6f 00000001 080e9408 00000005 00000005
Call Trace:
[c0150558] vfs_write+0x18/0x130
[c0150682] sys_write+0x42/0x70
[c0103ff6f] syscall_call+0x7/0xb
Code: 89 15 00 00 00 00 c3 90 84 74 26 00 83 ec 0c b8 00 a6 83 d0
<br>此消息是由写入 faulty 模块拥有的设备生成的，该模块是专门为演示故障而构建的。faulty.c 的 write 方法的实现非常简单：<br>ssize_t faulty_write (struct file *filp, const char __user *buf, size_t count, loff_t *pos)
{
    /* 通过解引用 NULL 指针制造一个简单的故障 */
    *(int *)0 = 0;
    return 0;
}
<br>正如你所看到的，我们在这里所做的就是解引用一个 NULL 指针。由于 0 从来不是有效的指针值，因此会发生故障，内核将其转换为前面显示的 oops 消息。然后调用进程被杀死。<br>faulty 模块在其 read 实现中有一个不同的故障条件：<br>ssize_t faulty_read(struct file *filp, char __user *buf,
    size_t count, loff_t *pos)
{
    int ret;
    char stack_buf[4];

    /* 让我们尝试一个缓冲区溢出 */
    memset(stack_buf, 0xff, 20);
    if (count &gt; 4)
        count = 4; /* 复制 4 个字节给用户 */
    ret = copy_to_user(buf, stack_buf, count);
    if (!ret)
        return count;
    return ret;
}
<br>此方法将一个字符串复制到局部变量中；不幸的是，字符串比目标数组长。当函数返回时，生成的缓冲区溢出会导致 oops。由于返回指令将指令指针带到无处之地，这种故障更难追踪，你可能会得到如下内容：<br>EIP: 0010:[&lt;00000000&gt;]
Unable to handle kernel paging request at virtual address ffffffff
printing eip:
ffffffff
Oops: 0000 [#5]
SMP
CPU: 0
EIP: 0060:[&lt;ffffffff&gt;] Not tainted
EFLAGS: 00010296 (2.6.6)
EIP is at 0xffffffff
eax: 0000000 cbx: ffffffff ecx: 0000000 edx: bfffdafc
esi: cf434f00 edi: ffffffff ebp: 00002000 esp: cz7ffff78
ds: 0070 es: 0070 ss: 0068
Process head (pid: 3331, threadinfo=c27fe000 task=e32d51c0)
Stack: ffffffff bfffdaf0 00002000 cf434f20 00000001 00000286 cf434f00 ffffffff7
    bfffdaf0 cz7fe000 cd50612 cf434f00 bfffdaf0 00002000 cf434f20 00000000
    00000003 00002000 cd103f8f 00000003 bfffdaf0 00002000 00002000 bfffdaf0
Call Trace:
[ccd150612&gt;] sys_read40442/0x70
[
**

### `Oops` 消息（续）

```bash
[ccd103f8f&gt;] syscall_call+0x7/0xb
Code: Bad EIP value.
<br>在这种情况下，我们只看到部分调用栈（vfs_read 和 faulty_read 缺失），内核抱怨“错误的 EIP 值”。这个抱怨以及开头列出的错误地址（ffffffff）都是内核栈已损坏的提示。<br>通常，当你面对 oops 时，首先要看的是问题发生的位置，这通常与调用栈分开列出。在上面显示的第一个 oops 中，相关的行是：<br>EIP is at faulty_write+0x4/0x10 [faulty]
<br>这里我们看到我们在 faulty_write 函数中，该函数位于 faulty 模块中（方括号中列出）。十六进制数字表示指令指针位于函数中的第 4 个字节，该函数似乎是 10（十六进制）字节长。通常，这足以找出问题所在。<br>如果你需要更多信息，调用栈会显示你是如何到达问题发生的地方的。栈本身以十六进制形式打印；通过一些工作，你通常可以从栈列表中确定局部变量和函数参数的值。有经验的内核开发者可以从这里的模式识别中受益；例如，如果我们查看 faulty_read 的 oops 中的栈列表：<br>Stack:
ffffffff bfffda70 00002000 cfa347a0 00000001 00000286 cfa347a0 ffffffff7
bfffda70 c27fe000 c0150612 cfa347a0 bfffda70 00002000 cfa347a0 00000000
00000003 00002000 c010378f 00000003 bfffda70 00002000 00002000 bfffda70
<br>栈顶的 ffffffff 是我们破坏的字符串的一部分。在 x86 架构上，默认情况下，用户空间栈从 0xc0000000 以下开始；因此，重复的值 0xbfffda70 可能是用户空间栈地址；实际上，它是传递给 read 系统调用的缓冲区的地址，每次传递到内核调用链时都会复制它。在 x86 上（再次，默认情况下），内核空间从 0xc0000000 开始，因此高于该值的值几乎肯定是内核空间地址，依此类推。<br>最后，在查看 oops 列表时，始终要注意本章开头讨论的“slab poisoning”值。因此，例如，如果你得到一个内核 oops，其中错误地址是 0xa5a5a5a5，你几乎肯定是在某个地方忘记初始化动态内存。<br>请注意，只有在启用 CONFIG_KALLSYMS 选项构建内核时，你才会看到符号调用栈（如上所示）。否则，你会看到一个裸的十六进制列表，这在解码之前不太有用。<br><br>尽管内核代码中的大多数错误最终都会导致 oops 消息，但有时它们可能会完全挂起系统。如果系统挂起，则不会打印任何消息。例如，如果代码进入无限循环，内核会停止调度，系统不会响应任何操作，包括 Ctrl-Alt-Del 组合键。你有两种选择来处理系统挂起——要么事先预防，要么事后调试。<br>你可以通过在关键点插入 schedule 调用来防止无限循环。schedule 调用（正如你可能猜到的）调用调度程序，因此允许其他进程从当前进程窃取 CPU 时间。如果一个进程由于你的驱动程序中的错误而在内核空间中循环，schedule 调用使你能够在跟踪正在发生的事情后杀死该进程。<br>你应该意识到，当然，任何对 schedule 的调用都可能创建对你的驱动程序的额外重入调用，因为它允许其他进程运行。这种重入通常不应该是一个问题，假设你在驱动程序中使用了适当的锁定。但是，请确保不要在驱动程序持有自旋锁的任何时候调用 schedule。<br>如果你的驱动程序真的挂起了系统，并且你不知道在哪里插入 schedule 调用，最好的方法可能是添加一些打印消息并将它们写入控制台（如果需要，可以通过更改 console_loglevel 值）。<br>有时系统可能看起来挂起，但实际上并没有。例如，如果键盘以某种奇怪的方式锁定，可能会发生这种情况。这些假挂起可以通过查看你为此目的保持运行的程序的输出来检测。显示器上的时钟或系统负载表是一个很好的状态监视器；只要它继续更新，调度程序就在工作。<br>许多锁定的一个不可或缺的工具是“魔法 SysRq 键”，它在大多数架构上都可用。魔法 SysRq 是通过 PC 键盘上的 Alt 和 SysRq 键的组合调用的，或者在其他平台上使用其他特殊键（详见 Documentation/sysrq.txt），并且在串行控制台上也可用。第三个键与这两个键一起按下，执行以下有用的操作之一：<br>
<br>
r<br>
关闭键盘原始模式；在崩溃的应用程序（如 X 服务器）可能使键盘处于奇怪状态的情况下很有用。

<br>
k<br>
调用“安全注意键”（SAK）功能。SAK 杀死当前控制台上运行的所有进程，给你一个干净的终端。

<br>
s<br>
执行所有磁盘的紧急同步。

<br>
u<br>
卸载。尝试以只读模式重新挂载所有磁盘。此操作通常在 s 之后立即调用，可以在系统严重故障时节省大量文件系统检查时间。

<br>
b<br>
启动。立即重新启动系统。确保先同步并重新挂载磁盘。

<br>
p<br>
打印处理器寄存器信息。

<br>
t<br>
打印当前任务列表。

<br>
m<br>
打印内存信息。

<br>其他魔法 SysRq 功能也存在；有关完整列表，请参阅内核源代码的 Documentation 目录中的 sysrq.txt。请注意，魔法 SysRq 必须在内核配置中显式启用，大多数发行版出于明显的安全原因不会启用它。然而，对于用于开发驱动程序的系统，启用魔法 SysRq 是值得的。魔法 SysRq 可以在运行时通过以下命令禁用：<br>echo 0 &gt; /proc/sys/kernel/sysrq
<br>如果非特权用户可以访问你的系统键盘，你应该考虑禁用它，以防止意外或故意的损坏。一些以前的内核版本默认禁用 sysrq，因此你需要在运行时通过向同一个 /proc/sys 文件写入 1 来启用它。<br>sysrq 操作非常有用，因此它们已提供给无法访问控制台的系统管理员。文件 /proc/sysrq-trigger 是一个只写入口点，你可以通过写入相关的命令字符来触发特定的 sysrq 操作；然后你可以从内核日志中收集任何输出数据。这个 sysrq 的入口点始终有效，即使 sysrq 在控制台上被禁用。<br>如果你遇到“活动挂起”，即你的驱动程序卡在循环中但整个系统仍在运行，有几个值得了解的技术。通常，SysRq p 功能会直接指向有问题的例程。如果失败，你还可以使用内核分析功能。构建一个启用了分析功能的内核，并使用 profile=2 启动它。使用 readprofile 实用程序重置分析计数器，然后让你的驱动程序进入循环。稍后，再次使用 readprofile 查看内核在哪里花费时间。另一个更高级的替代方法是 oprofile，你也可以考虑使用它。文件 Documentation/basic_profiling.txt 告诉你开始使用分析器所需的一切。<br>在追踪系统挂起时，一个值得使用的预防措施是以只读方式挂载所有磁盘（或卸载它们）。如果磁盘是只读的或卸载的，就没有损坏文件系统或使其处于不一致状态的风险。另一种可能性是使用通过 NFS（网络文件系统）挂载所有文件系统的计算机。内核中必须启用“NFS-Root”功能，并且在启动时必须传递特殊参数。在这种情况下，你将避免文件系统损坏，甚至无需使用 SysRq，因为文件系统一致性由 NFS 服务器管理，它不会被你的设备驱动程序关闭。]]></description><link>第4章-调试技术/4.5-调试系统故障.html</link><guid isPermaLink="false">第4章 调试技术/4.5 调试系统故障.md</guid><pubDate>Tue, 04 Mar 2025 16:18:00 GMT</pubDate></item><item><title><![CDATA[4.6  调试器及相关工具]]></title><description><![CDATA[ 
 <br>调试模块的最后手段是使用调试器逐步执行代码，观察变量和机器寄存器的值。这种方法耗时，应尽可能避免。然而，通过调试器实现的代码细粒度视角有时是无价的。<br>在内核上使用交互式调试器是一个挑战。内核在自己的地址空间中运行，代表系统中的所有进程。因此，用户空间调试器提供的许多常见功能（如断点和单步执行）在内核中更难实现。在本节中，我们将介绍几种调试内核的方法；每种方法都有其优缺点。<br><br>gdb 对于查看系统内部非常有用。在这个级别熟练使用调试器需要对 gdb 命令有一定的信心，对目标平台的汇编代码有一定的理解，以及能够匹配源代码和优化的汇编代码。<br>调试器必须像内核是一个应用程序一样调用。除了指定 ELF 内核映像的文件名外，你还需要在命令行上提供一个核心文件的名称。对于正在运行的内核，该核心文件是内核核心映像 /proc/kcore。典型的 gdb 调用如下所示：<br>gdb /usr/src/linux/vmlinux /proc/kcore
<br>第一个参数是未压缩的 ELF 内核可执行文件的名称，而不是 zImage 或 bzImage 或任何专门为引导环境构建的内容。<br>gdb 命令行上的第二个参数是核心文件的名称。像 /proc/ 中的任何文件一样，/proc/kcore 是在读取时生成的。当 read 系统调用在 /proc 文件系统中执行时，它映射到数据生成函数而不是数据检索函数；我们已经在本章前面的“使用 /proc 文件系统”部分中利用了此功能。kcore 用于表示内核“可执行文件”的核心文件格式；它是一个巨大的文件，因为它表示整个内核地址空间，对应于所有物理内存。在 gdb 中，你可以通过发出标准的 gdb 命令来查看内核变量。例如，p jiffies 打印从系统启动到当前时间的时钟滴答数。<br>当你在 gdb 中打印数据时，内核仍在运行，各种数据项在不同时间具有不同的值；然而，gdb 通过缓存已读取的数据来优化对核心文件的访问。如果你再次查看 jiffies 变量，你将得到与之前相同的答案。缓存值以避免额外的磁盘访问是传统核心文件的正确行为，但在使用“动态”核心映像时很不方便。解决方案是在每次想要刷新 gdb 缓存时发出命令 core-file /proc/kcore；调试器准备好使用新的核心文件并丢弃任何旧信息。然而，你并不总是需要在读取新数据时发出 core-file；gdb 以几千字节的块读取核心文件，并且只缓存它已经引用的块。<br>通常由 gdb 提供的许多功能在内核上不可用。例如，gdb 无法修改内核数据；它期望在控制下运行要调试的程序，然后再处理其内存映像。也无法设置断点或观察点，或单步执行内核函数。<br>请注意，为了在 gdb 中提供符号信息，你必须在编译内核时启用 CONFIG_DEBUG_INFO 选项。结果是在磁盘上生成一个更大的内核映像，但没有这些信息，挖掘内核变量几乎是不可能的。<br>有了调试信息，你可以了解内核内部发生的许多事情。gdb 可以愉快地打印结构、跟踪指针等。然而，更难的是检查模块。由于模块不是传递给 gdb 的 vmlinux 映像的一部分，调试器对它们一无所知。幸运的是，从内核 2.6.7 开始，可以教 gdb 它需要了解的内容以检查可加载模块。<br>Linux 可加载模块是 ELF 格式的可执行映像；因此，它们被划分为许多部分。一个典型的模块可能包含十几个或更多部分，但在调试会话中通常只有三个相关部分：<br>
<br>
.text<br>
此部分包含模块的可执行代码。调试器必须知道此部分的位置才能提供回溯或设置断点。（当在 /proc/kcore 上运行调试器时，这些操作都不相关，但在使用 kgdb 时可能有用，稍后描述）。

<br>
.bss  

<br>
.data<br>
这两个部分保存模块的变量。任何在编译时未初始化的变量最终都会进入 .bss，而初始化的变量则进入 .data。

<br>让 gdb 与可加载模块一起工作需要告知调试器给定模块的各个部分加载到哪里。该信息在 sysfs 中可用，位于 /sys/module 下。例如，加载 scull 模块后，目录 /sys/module/scull/sections 包含名为 .text 的文件；每个文件的内容是该部分的基地址。<br>我们现在可以发出一个 gdb 命令，告诉它我们的模块。我们需要的命令是 add-symbol-file；该命令将模块对象文件的名称、.text 基地址和一系列可选参数作为参数，描述其他感兴趣的部分的位置。在挖掘 sysfs 中的模块部分数据后，我们可以构建如下命令：<br>(gdb) add-symbol-file .../scull.ko 0xd0832000 \
    -s .bss 0xd0837100 \
    -s .data 0xd0836be0
<br>我们在示例源代码中包含了一个小脚本（gdbline），它可以为给定模块创建此命令。<br>我们现在可以使用 gdb 检查可加载模块中的变量。以下是来自 scull 调试会话的快速示例：<br>(gdb) add-symbol-file scull.ko 0xd0832000 \
    -s .bss 0xd0837100 \
    -s .data 0xd0836be0
add symbol table from file "scull.ko" at
    .text_addr = 0xd0832000
    .bss_addr = 0xd0837100
    .data_addr = 0xd0836be0
(y or n) y
Reading symbols from scull.ko...done.
(gdb) p scull_devices[0]
$1 = {data = 0xc7666c50,
    quantum = 4000,
    qset = 1000,
    size = 20881,
    access_key = 0,
    ...}
<br>在这里，我们看到第一个 scull 设备当前持有 20,881 字节。如果我们愿意，我们可以跟随数据链，或查看模块中任何其他感兴趣的内容。<br>另一个值得了解的技巧是：<br>(gdb) print *(address)
<br>在这里，为 address 填入一个十六进制地址；输出是对应于该地址的代码的文件和行号。此技术可能有用，例如，找出函数指针真正指向的位置。<br>我们仍然无法执行典型的调试任务，如设置断点或修改数据；要执行这些操作，我们需要使用像 kdb（接下来描述）或 kgdb（我们稍后会讨论）这样的工具。<br><br>许多读者可能想知道为什么内核没有内置更高级的调试功能。答案很简单，Linus 不相信交互式调试器。他担心它们会导致糟糕的修复，那些修补症状而不是解决问题的根本原因。因此，没有内置调试器。<br>然而，其他内核开发者认为交互式调试工具有时有用。其中一个工具是 kdb 内置内核调试器，可从 oss.sgi.com 作为非官方补丁获得。要使用 kdb，你必须获取补丁（确保获取与内核版本匹配的版本），应用它，然后重新构建和重新安装内核。请注意，截至本文撰写时，kdb 仅在 IA-32（x86）系统上工作（尽管 IA-64 的版本曾一度存在于主线内核源代码中，后来被移除）。<br>一旦你运行了启用 kdb 的内核，有几种方法可以进入调试器。按下控制台上的 Pause（或 Break）键会启动调试器。当内核发生 oops 或命中断点时，kdb 也会启动。无论如何，你会看到如下消息：<br>Entering kdb (0xc0347b80) on processor 0 due to keyboard Entry
[0]kdb&gt;
<br>请注意，当 kdb 运行时，内核几乎停止了一切。在调用 kdb 的系统上，不应运行其他任何东西；特别是，你不应启用网络——当然，除非你正在调试网络驱动程序。通常，如果你要使用 kdb，最好以单用户模式启动系统。<br>作为一个示例，考虑一个快速的 scull 调试会话。假设驱动程序已经加载，我们可以告诉 kdb 在 scull_read 中设置一个断点，如下所示：<br>[0]kdb&gt; bp scull_read
Instruction(i) BP #0 at 0xc0087c5dc (scull_read)
is enabled globally adjust 1
[0]kdb&gt; go
<br>bp 命令告诉 kdb 在下一次内核进入 scull_read 时停止。然后你输入 go 继续执行。在将某些内容放入其中一个 scull 设备后，我们可以尝试通过在另一个终端上的 shell 下运行 cat 来读取它，结果如下：<br>Instruction(i) breakpoint #0 at 0xd087c5dc (adjusted)
0xd087c5dc scull_read: int3

Entering kdb (current=0xcf09f890, pid 1575) on processor 0 due to
Breakpoint @ 0xd087c5dc
[0]kdb&gt;
<br>我们现在位于 scull_read 的开头。要查看我们是如何到达那里的，我们可以获取一个栈回溯：<br>[0]kdb&gt; bt
ESP EIP Function (args)
0xcdbddf74 0xd087c5dc [scull][scull_read]
0xcdbddf78 0xc0150718 vfs_read+0xb8
0xcdbddf4a 0xc01509c2 sys_read+0x42
0xcdbddfca 0xc0103fcf syscall_call+0x7
[0]kdb&gt;
<br>kdb 试图打印调用栈中每个函数的参数。然而，它会被编译器使用的优化技巧搞糊涂。因此，它无法打印 scull_read 的参数。<br>是时候查看一些数据了。mds 命令操作数据；我们可以使用如下命令查询 scull_devices 指针的值：<br>[0]kdb&gt; mds scull_devices 1
0xd0880de8 cf36ac00 ...
<br>在这里，我们要求从 scull_devices 的位置开始的一个（4 字节）字的数据；答案告诉我们，我们的设备数组位于地址 0xd0880de8；第一个设备结构本身位于 0xcf36ac00。要查看该设备结构，我们需要使用该地址：<br>[0]kdb&gt; mds cf36ac00
0xcf36ac00 ce137dbc ...
0xcf36ac04 00000fa0 ...
0xcf36ac08 000003e8 ...
0xcf36ac0c 0000009b ...
0xcf36ac10 00000000 ...
0xcf36ac14 00000001 ...
0xcf36ac18 00000000 ...
0xcf36ac1c 00000001 ...
<br>这里的八行对应于 scull_dev 结构的开头部分。因此，我们看到第一个设备的内存分配在 0xce137dbc，量子大小为 4000（十六进制 fa0），量子集大小为 1000（十六进制 3e8），当前设备中存储了 155（十六进制 9b）字节。<br>kdb 也可以更改数据。假设我们想从设备中删除一些数据：<br>[0]kdb&gt; mm cf36ac0c 0x50
0xcf36ac0c = 0x50
<br>随后在设备上运行 cat 将返回比之前更少的数据。<br>kdb 还有许多其他功能，包括单步执行（按指令，而不是 C 源代码行）、在数据访问时设置断点、反汇编代码、遍历链表、访问寄存器数据等。应用 kdb 补丁后，你可以在内核源代码树的 Documentation/kdb 目录中找到完整的手册页。<br><br>我们到目前为止看到的两种交互式调试方法（在 /proc/kcore 上使用 gdb 和 kdb）都达不到用户空间应用程序开发者所习惯的环境。如果有一个真正的内核调试器支持像修改变量、断点等功能，那不是很好吗？<br>事实证明，确实存在这样的解决方案。截至本文撰写时，有两个独立的补丁在流通，它们允许 gdb 以完整功能运行以调试内核。令人困惑的是，这两个补丁都称为 kgdb。它们通过将运行测试内核的系统与运行调试器的系统分开来工作；两者通常通过串行电缆连接。因此，开发者可以在其稳定的桌面系统上运行 gdb，同时操作在测试机器上运行的内核。在这种模式下设置 gdb 需要一些初始时间，但当出现难以解决的错误时，这种投资可以迅速得到回报。<br>这些补丁处于快速变化的状态，甚至可能在某个时候合并，因此我们避免对它们进行过多描述，只介绍它们的位置和基本功能。感兴趣的读者可以查看当前的情况。<br>第一个 kgdb 补丁目前位于 -mm 内核树中——这是补丁进入 2.6 主线的暂存区。此版本的补丁支持 x86、SuperH、ia64、x86_64、SPARC 和 32 位 PPC 架构。除了通常通过串行端口操作的模式外，此版本的 kgdb 还可以通过局域网进行通信。只需启用以太网模式并使用 kgdboe 参数启动，指示调试命令可以源自的 IP 地址。Documentation/i386/kgdb 下的文档描述了如何设置。[*]<br>作为替代方案，你可以使用 http://kgdb.sf.net/ 上的 kgdb 补丁。此版本的调试器不支持网络通信模式（尽管据说正在开发中），但它确实有一些内置支持来处理可加载模块。它支持 x86、x86_64、PowerPC 和 S/390 架构。<br><br>用户模式 Linux（UML）是一个有趣的概念。它被结构化为 Linux 内核的一个独立端口，拥有自己的 arch/um 子目录。然而，它并不运行在新的硬件类型上；相反，它运行在 Linux 系统调用接口上实现的虚拟机上。因此，UML 允许 Linux 内核作为 Linux 系统上的一个独立的用户模式进程运行。<br>将内核作为用户模式进程运行带来了许多优势。由于它在受约束的虚拟处理器上运行，有问题的内核不会损坏“真实”系统。可以轻松地在同一台机器上尝试不同的硬件和软件配置。对于内核开发者来说，最重要的是用户模式内核可以轻松地用 gdb 或其他调试器进行操作。<br>然而，UML 对驱动程序开发者有一个很大的缺点：用户模式内核无法访问主机系统的硬件。因此，虽然它可以用于调试本书中的大多数示例驱动程序，但 UML 目前还不能用于调试必须处理真实硬件的驱动程序。<br>有关 UML 的更多信息，请参见 <a rel="noopener nofollow" class="external-link" href="http://user-mode-linux.sf.net/" target="_blank">http://user-mode-linux.sf.net/</a>。<br><br>Linux 跟踪工具包（LTT）是一个内核补丁和一组相关实用程序，允许跟踪内核中的事件。跟踪包括时间信息，可以创建给定时间段内发生的事件的相当完整的图片。因此，它不仅可以用于调试，还可以用于追踪性能问题。<br>LTT 及其详细文档可以在 <a rel="noopener nofollow" class="external-link" href="http://www.opersys.com/LTT" target="_blank">http://www.opersys.com/LTT</a> 找到。<br><br>动态探针（DProbes）是 IBM 为 Linux 在 IA-32 架构上发布的调试工具（根据 GPL 发布）。它允许在系统中的几乎任何位置（用户空间和内核空间）放置“探针”。探针由一些代码（用一种专门的、基于堆栈的语言编写）组成，当控制到达给定点时执行。此代码可以向用户空间报告信息、更改寄存器或执行许多其他操作。DProbes 的有用特性是，一旦该功能被构建到内核中，探针可以在运行系统中插入任何位置，而无需内核构建或重新启动。DProbes 还可以与 LTT 一起工作，以在任意位置插入新的跟踪事件。<br>DProbes 工具可以从 IBM 的开源站点下载：<a rel="noopener nofollow" class="external-link" href="http://oss.software.ibm.com" target="_blank">http://oss.software.ibm.com</a>。<br><br><br>本章介绍了多种调试内核代码的技术，从简单的打印语句到复杂的调试器和跟踪工具。每种方法都有其优缺点，开发者应根据具体情况选择最合适的工具。通过熟练掌握这些调试技术，你可以更有效地解决内核开发中的问题，并提高代码的稳定性和性能。]]></description><link>第4章-调试技术/4.6-调试器及相关工具.html</link><guid isPermaLink="false">第4章 调试技术/4.6  调试器及相关工具.md</guid><pubDate>Tue, 04 Mar 2025 16:20:34 GMT</pubDate></item><item><title><![CDATA[5.0 并发与竞态条件]]></title><description><![CDATA[ 
 <br>到目前为止，我们很少关注并发问题——即系统同时执行多个任务时会发生什么。然而，并发管理是操作系统编程中的核心问题之一。与并发相关的错误是最容易引入的，也是最难发现的。即使是经验丰富的Linux内核程序员，偶尔也会引入与并发相关的错误。<br>在早期的Linux内核中，并发的来源相对较少。内核不支持对称多处理（SMP）系统，唯一的并发执行原因是硬件中断的处理。这种方式虽然简单，但在现代硬件和应用的需求下已经不再适用。现代系统要求在多处理器上实现高性能，并且要求系统能够快速响应事件。为了满足这些需求，Linux内核已经发展到可以同时处理更多任务的程度。这种演变带来了更高的性能和可扩展性，但也显著增加了内核编程的复杂性。设备驱动程序开发人员现在必须从一开始就将并发纳入设计，并且必须深刻理解内核提供的并发管理机制。<br>本章的目的是帮助读者建立这种理解。为此，我们介绍了一些可以立即应用于第3章中scull驱动的机制。其他机制虽然暂时不会用到，但也会在本章中介绍。首先，我们来看看scull驱动中可能出现的问题以及如何避免这些潜在问题。]]></description><link>第5章-并发与竞态条件/5.0-并发与竞态条件.html</link><guid isPermaLink="false">第5章 并发与竞态条件/5.0 并发与竞态条件.md</guid><pubDate>Tue, 04 Mar 2025 16:22:31 GMT</pubDate></item><item><title><![CDATA[5.1 scull中的陷阱]]></title><description><![CDATA[ 
 <br>让我们快速看一下scull内存管理代码的一个片段。在scull的写操作逻辑中，scull必须决定所需的内存是否已经分配。处理这一任务的代码如下：<br>if (!dptr-&gt;data[s_pos]) {
    dptr-&gt;data[s_pos] = kmalloc(quantum, GFP_KERNEL);
    if (!dptr-&gt;data[s_pos])
        goto out;
}
<br>假设有两个进程（我们称之为“A”和“B”）同时尝试向同一个scull设备的相同偏移量写入数据。每个进程都会同时到达上述代码片段的第一行if测试。如果指针为NULL，每个进程都会决定分配内存，并将结果指针赋值给dptr-&gt;data[s_pos]。由于两个进程都在向同一个位置赋值，显然只有一个赋值会生效。<br>最终的结果是，第二个完成赋值的进程会“获胜”。如果进程A先赋值，它的赋值会被进程B覆盖。此时，scull会完全忘记A分配的内存，它只保留了指向B分配的内存的指针。因此，A分配的内存将被丢弃，永远不会返回给系统。<br>这一系列事件展示了竞态条件。竞态条件是由于对共享数据的无控制访问导致的。当错误的访问模式发生时，会产生意外的结果。在这个例子中，结果是内存泄漏。这已经足够糟糕了，但竞态条件还可能导致系统崩溃、数据损坏或安全问题。程序员可能会认为竞态条件是极低概率事件，但在计算世界中，百万分之一的事件可能每几秒就会发生一次，后果可能非常严重。<br>我们很快就会从scull中消除竞态条件，但首先我们需要更全面地了解并发及其管理。]]></description><link>第5章-并发与竞态条件/5.1-scull中的陷阱.html</link><guid isPermaLink="false">第5章 并发与竞态条件/5.1 scull中的陷阱.md</guid><pubDate>Tue, 04 Mar 2025 16:24:56 GMT</pubDate></item><item><title><![CDATA[并发及其管理]]></title><description><![CDATA[ 
 <br><br>在现代Linux系统中，并发的来源很多，因此竞态条件也很多。多个用户空间进程在运行，它们可能以意想不到的方式访问你的代码。SMP系统可以在不同的处理器上同时执行你的代码。内核代码是可抢占的；你的驱动代码可能在任何时候失去处理器，而替代它的进程也可能在你的驱动中运行。设备中断是异步事件，可能导致你的代码并发执行。内核还提供了各种延迟代码执行的机制，如工作队列、任务队列和定时器，这些机制可能导致你的代码在任何时候运行，与当前进程的操作无关。在现代热插拔的世界中，你的设备可能在你正在操作时突然消失。<br>避免竞态条件可能是一项艰巨的任务。在一个任何事情都可能随时发生的世界中，驱动程序开发人员如何避免绝对的混乱？事实证明，大多数竞态条件可以通过一些思考、内核的并发控制原语以及一些基本原则来避免。我们将首先介绍这些原则，然后讨论如何应用它们。<br>竞态条件是由于对共享资源的访问而产生的。当两个执行线程需要操作相同的数据结构（或硬件资源）时，混乱的可能性总是存在的。因此，设计驱动程序时的第一条经验法则是尽可能避免共享资源。如果没有并发访问，就不会有竞态条件。因此，精心编写的内核代码应尽量减少共享。最明显的应用是避免使用全局变量。如果你将资源放在多个执行线程可以访问的地方，必须有充分的理由。<br>然而，事实是这种共享通常是必要的。硬件资源本质上是共享的，软件资源也经常需要被多个线程访问。请记住，全局变量并不是共享数据的唯一方式；任何时候你的代码将指针传递给内核的其他部分，都可能创建一个新的共享情况。共享是不可避免的。<br>资源共享的硬性规则是：任何时候硬件或软件资源被多个执行线程共享，并且有可能一个线程遇到该资源的不一致视图时，你必须显式地管理对该资源的访问。在上面的scull示例中，进程B的视图是不一致的；它不知道进程A已经为（共享的）设备分配了内存，因此它执行了自己的分配并覆盖了A的工作。在这种情况下，我们必须控制对scull数据结构的访问。我们需要安排代码，使其要么看到已经分配的内存，要么知道没有其他人已经或将要分配内存。通常的访问管理技术称为锁定或互斥——确保在任何时候只有一个执行线程可以操作共享资源。本章的大部分内容将致力于讨论锁定。]]></description><link>第5章-并发与竞态条件/5.2-并发及其管理.html</link><guid isPermaLink="false">第5章 并发与竞态条件/5.2 并发及其管理.md</guid><pubDate>Tue, 04 Mar 2025 16:23:17 GMT</pubDate></item><item><title><![CDATA[信号量和互斥锁]]></title><description><![CDATA[ 
 <br><br>让我们看看如何为scull添加锁定。我们的目标是使对scull数据结构的操作具有原子性，即从其他执行线程的角度来看，整个操作是一次性完成的。对于我们的内存泄漏示例，我们需要确保如果一个线程发现必须分配某个内存块，它有机会在执行分配之前，其他线程不能进行相同的测试。为此，我们必须设置临界区：在任何时候只能由一个线程执行的代码。<br>并非所有的临界区都是相同的，因此内核为不同的需求提供了不同的原语。在这种情况下，对scull数据结构的所有访问都是在进程上下文中进行的，作为用户直接请求的结果；没有来自中断处理程序或其他异步上下文的访问。没有特定的延迟（响应时间）要求；应用程序开发人员理解I/O请求通常不会立即得到满足。此外，scull在访问其数据结构时不会持有任何其他关键系统资源。所有这些意味着，如果scull驱动程序在等待访问数据结构时进入睡眠状态，没有人会介意。<br>“进入睡眠”在这个上下文中是一个明确的术语。当一个Linux进程到达无法继续执行的点时，它会进入睡眠状态（或“阻塞”），将处理器让给其他进程，直到未来的某个时间它可以继续工作。进程通常在等待I/O完成时进入睡眠状态。随着我们深入内核，我们会遇到许多不能进入睡眠状态的情况。然而，scull中的写方法不属于这些情况。因此，我们可以使用可能导致进程在等待访问临界区时进入睡眠的锁定机制。<br>同样重要的是，我们将执行一个可能进入睡眠的操作（使用kmalloc分配内存）——因此，睡眠在任何情况下都是可能的。如果我们的临界区要正常工作，我们必须使用一个在线程持有锁时仍然有效的锁定原语。并非所有的锁定机制都可以在可能进入睡眠的情况下使用（我们稍后会看到一些不能使用的机制）。对于我们目前的需求，最适合的机制是信号量。<br>信号量是计算机科学中一个广为人知的概念。信号量的核心是一个整数值，结合两个通常称为P和V的函数。希望进入临界区的进程将调用相关信号量的P函数；如果信号量的值大于零，该值将减一，进程继续执行。如果信号量的值为0（或更小），进程必须等待，直到其他进程释放信号量。释放信号量通过调用V函数完成；该函数增加信号量的值，并在必要时唤醒等待的进程。<br>当信号量用于互斥——防止多个进程同时进入临界区时，它们的初始值通常设置为1。这种信号量在任何时候只能由一个进程或线程持有。以这种方式使用的信号量有时称为互斥锁，即“互斥”的缩写。Linux内核中几乎所有信号量都用于互斥。<br><br>Linux内核提供了一个符合上述语义的信号量实现，尽管术语略有不同。要使用信号量，内核代码必须包含&lt;asm/semaphore.h&gt;。相关类型是struct semaphore；实际信号量可以通过几种方式声明和初始化。一种是直接创建信号量，然后使用sema_init进行初始化：<br>void sema_init(struct semaphore *sem, int val);
<br>其中val是信号量的初始值。<br>然而，信号量通常以互斥模式使用。为了使这种常见情况更容易，内核提供了一组辅助函数和宏。因此，可以使用以下方式声明和初始化互斥锁：<br>DECLARE_MUTEX(name);
DECLARE_MUTEX_LOCKED(name);
<br>这里，结果是名为name的信号量变量，初始化为1（使用DECLARE_MUTEX）或0（使用DECLARE_MUTEX_LOCKED）。在后一种情况下，互斥锁一开始处于锁定状态；必须显式解锁，才能允许任何线程访问。<br>如果必须在运行时初始化互斥锁（例如，如果它是动态分配的），可以使用以下函数之一：<br>void init_MUTEX(struct semaphore *sem);
void init_MUTEX_LOCKED(struct semaphore *sem);
<br>在Linux世界中，P函数称为down——或其某种变体。这里的“down”指的是该函数减少信号量的值，并可能在将调用者置于睡眠状态一段时间以等待信号量可用后，授予对受保护资源的访问权限。down有三个版本：<br>void down(struct semaphore *sem);
int down_interruptible(struct semaphore *sem);
int down_trylock(struct semaphore *sem);
<br>down减少信号量的值，并在必要时等待。down_interruptible做同样的事情，但操作是可中断的。可中断版本几乎总是你想要的；它允许等待信号量的用户空间进程被用户中断。除非确实没有其他选择，否则通常不希望使用不可中断的操作。不可中断的操作是创建不可杀死的进程（在ps中看到的可怕的“D状态”）并惹恼用户的好方法。使用down_interruptible需要一些额外的注意，因为如果操作被中断，函数返回非零值，并且调用者不持有信号量。正确使用down_interruptible需要始终检查返回值并做出相应的响应。<br>最后一个版本down_trylock从不睡眠；如果信号量在调用时不可用，down_trylock立即返回非零值。<br>一旦线程成功调用了down的某个版本，它就被称为“持有”信号量（或“获取”信号量）。该线程现在有权访问受信号量保护的临界区。当需要互斥的操作完成后，必须释放信号量。Linux中与V等效的函数是up：<br>void up(struct semaphore *sem);
<br>一旦调用了up，调用者就不再持有信号量。<br>正如你所期望的，任何获取信号量的线程都必须通过一次（且仅一次）调用up来释放它。在错误路径中通常需要特别注意；如果在持有信号量时遇到错误，必须在将错误状态返回给调用者之前释放信号量。未能释放信号量是一个容易犯的错误；结果（进程在看似无关的地方挂起）可能很难重现和追踪。<br><br>信号量机制为scull提供了一个工具，可以用于在访问scull_dev数据结构时避免竞态条件。但我们需要正确使用这个工具。正确使用锁定原语的关键是明确指定哪些资源需要保护，并确保每次访问这些资源时都使用适当的锁定。在我们的示例驱动程序中，所有感兴趣的内容都包含在scull_dev结构中，因此这是我们锁定机制的逻辑范围。<br>让我们再次看一下这个结构：<br>struct scull_dev {
    struct scull_qset *data; /* 指向第一个量子集的指针 */
    int quantum; /* 当前量子大小 */
    int qset; /* 当前数组大小 */
    unsigned long size; /* 存储在此的数据量 */
    unsigned int access_key; /* 由sculluid和scullpriv使用 */
    struct semaphore sem; /* 互斥信号量 */
    struct cdev cdev; /* 字符设备结构 */
};
<br>在结构的底部是一个名为sem的成员，当然，这就是我们的信号量。我们选择为每个虚拟scull设备使用一个单独的信号量。使用一个全局信号量也是同样正确的。然而，各种scull设备之间没有共享资源，因此没有理由让一个进程在另一个进程操作不同的scull设备时等待。为每个设备使用单独的信号量允许对不同设备的操作并行进行，从而提高性能。<br>信号量在使用前必须初始化。scull在加载时执行此初始化，代码如下：<br>for (i = 0; i &lt; scull_nr_devs; i++) {
    scull_devices[i].quantum = scull_quantum;
    scull_devices[i].qset = scull_qset;
    init_MUTEX(&amp;scull_devices[i].sem);
    scull_setup_cdev(&amp;scull_devices[i], i);
}
<br>请注意，信号量必须在scull设备对系统的其余部分可用之前初始化。因此，init_MUTEX在scull_setup_cdev之前调用。以相反的顺序执行这些操作将创建一个竞态条件，即在信号量准备好之前就可能被访问。<br>接下来，我们必须检查代码，确保在访问scull_dev数据结构时始终持有信号量。例如，scull_write从以下代码开始：<br>if (down_interruptible(&amp;dev-&gt;sem))
    return -ERESTARTSYS;
<br>请注意对down_interruptible返回值的检查；如果它返回非零值，操作被中断。在这种情况下，通常的做法是返回-ERESTARTSYS。看到此返回代码后，内核的较高层将从头开始重新启动调用，或将错误返回给用户。如果你返回-ERESTARTSYS，你必须首先撤消任何可能已经对用户可见的更改，以便在系统调用重试时发生正确的事情。如果你无法以这种方式撤消更改，则应返回-EINTR。<br>无论scull_write是否能够成功执行其他任务，它都必须释放信号量。如果一切顺利，执行将进入函数的最后几行：<br>out:
up(&amp;dev-&gt;sem);
return retval;
<br>这段代码释放信号量并返回所需的状态。在scull_write中有几个地方可能会出错；这些包括内存分配失败或尝试从用户空间复制数据时出错。在这些情况下，代码执行goto out，确保执行适当的清理。<br><br>信号量为所有调用者执行互斥，无论每个线程可能想要做什么。然而，许多任务可以分为两种不同的工作类型：只需要读取受保护数据结构的任务和必须进行更改的任务。只要没有人试图进行任何更改，通常可以允许多个并发读者。这样做可以显著优化性能；只读任务可以并行完成其工作，而不必等待其他读者退出临界区。<br>Linux内核提供了一种特殊类型的信号量，称为rw_semaphore（或“读者/写者信号量”）来处理这种情况。驱动程序中使用rw_semaphore的情况相对较少，但它们偶尔会很有用。<br>使用rw_semaphore的代码必须包含&lt;linux/rwsem.h&gt;。读者/写者信号量的相关数据类型是struct rw_semaphore；rw_semaphore必须在运行时显式初始化：<br>void init_rwsem(struct rw_semaphore *sem);
<br>新初始化的rw_semaphore对下一个到来的任务（读者或写者）可用。需要只读访问的代码的接口如下：<br>void down_read(struct rw_semaphore *sem);
int down_read_trylock(struct rw_semaphore *sem);
void up_read(struct rw_semaphore *sem);
<br>调用down_read提供对受保护资源的只读访问，可能与其他读者并发。请注意，down_read可能会使调用进程进入不可中断的睡眠状态。down_read_trylock在无法获得读访问时不会等待；如果获得访问权限，它返回非零值，否则返回0。请注意，down_read_trylock的约定与大多数内核函数不同，成功由返回值为0表示。使用down_read获取的rw_semaphore最终必须通过up_read释放。<br>写者的接口类似：<br>void down_write(struct rw_semaphore *sem);
int down_write_trylock(struct rw_semaphore *sem);
void up_write(struct rw_semaphore *sem);
void downgrade_write(struct rw_semaphore *sem);
<br>down_write、down_write_trylock和up_write的行为与它们的读者对应物类似，当然，它们提供写访问。如果你有一个需要快速更改写锁，然后进行较长时间的只读访问的情况，你可以使用downgrade_write在完成更改后允许其他读者进入。<br>rw_semaphore允许一个写者或无限数量的读者持有信号量。写者优先；一旦写者尝试进入临界区，在所有写者完成工作之前，不允许任何读者进入。如果你有大量写者争用信号量，这种实现可能导致读者饥饿——读者长时间被拒绝访问。因此，rw_semaphore最好在写访问很少且写访问时间较短的情况下使用。]]></description><link>第5章-并发与竞态条件/5.3-信号量和互斥锁.html</link><guid isPermaLink="false">第5章 并发与竞态条件/5.3 信号量和互斥锁.md</guid><pubDate>Tue, 04 Mar 2025 16:24:41 GMT</pubDate></item><item><title><![CDATA[完成机制]]></title><description><![CDATA[ 
 <br><br>内核编程中的一个常见模式是启动当前线程之外的某些活动，然后等待该活动完成。这种活动可以是创建新的内核线程或用户空间进程、向现有进程发出请求或某种基于硬件的操作。在这种情况下，可能会诱人地使用信号量来同步这两个任务，代码如下：<br>struct semaphore sem;

init_MUTEX_LOCKED(&amp;sem);
start_external_task(&amp;sem);
down(&amp;sem);
<br>外部任务可以在其工作完成后调用up(&amp;sem)。<br>事实证明，信号量并不是这种情况下的最佳工具。在正常使用中，尝试锁定信号量的代码几乎总是发现信号量可用；如果信号量争用严重，性能会受到影响，锁定方案需要重新审视。因此，信号量已经针对“可用”情况进行了大量优化。然而，当以上述方式用于通信任务完成时，调用down的线程几乎总是必须等待；性能会相应受到影响。如果信号量声明为自动变量，它们在这种使用方式下也可能受到（难以处理的）竞态条件的影响。在某些情况下，信号量可能在调用up的进程完成之前消失。<br>这些担忧促使在2.4.7内核中添加了“完成”接口。完成机制是一种轻量级机制，只有一个任务：允许一个线程告诉另一个线程工作已完成。要使用完成机制，你的代码必须包含&lt;linux/completion.h&gt;。可以使用以下方式创建完成：<br>DECLARE_COMPLETION(my_completion);
<br>或者，如果必须在运行时动态创建和初始化完成：<br>struct completion my_completion;
/* ... */
init_completion(&amp;my_completion);
<br>等待完成只需调用：<br>void wait_for_completion(struct completion *c);
<br>请注意，此函数执行不可中断的等待。如果你的代码调用wait_for_completion而没有人完成任务，结果将是一个不可杀死的进程。<br>在另一侧，实际完成事件可以通过调用以下函数之一来发出信号：<br>void complete(struct completion *c);
void complete_all(struct completion *c);
<br>如果有多个线程在等待同一个完成事件，这两个函数的行为会有所不同。complete 只会唤醒一个等待的线程，而 complete_all 则会唤醒所有等待的线程。在大多数情况下，只有一个等待者，因此这两个函数的效果是相同的。<br>完成机制通常是一次性的设备；它使用一次后就会被丢弃。然而，如果采取适当的措施，完成结构也可以被重复使用。如果没有使用 complete_all，只要没有关于所发出事件的歧义，完成结构可以在不重新初始化的情况下重复使用。如果你使用了 complete_all，则必须在重复使用之前重新初始化完成结构。可以使用以下宏快速执行此重新初始化：<br>INIT_COMPLETION(struct completion c);
<br>作为一个使用完成机制的示例，考虑 complete 模块，它包含在示例源代码中。该模块定义了一个具有简单语义的设备：任何尝试从该设备读取的进程都将等待（使用 wait_for_completion），直到其他进程写入该设备。实现此行为的代码如下：<br>DECLARE_COMPLETION(comp);

ssize_t complete_read(struct file *filp, char __user *buf, size_t count, loff_t *pos)
{
    printk(KERN_DEBUG "process %i (%s) going to sleep\n",
           current-&gt;pid, current-&gt;comm);
    wait_for_completion(&amp;comp);
    printk(KERN_DEBUG "awoken %i (%s)\n", current-&gt;pid, current-&gt;comm);
    return 0; /* EOF */
}

ssize_t complete_write(struct file *filp, const char __user *buf, size_t count, loff_t *pos)
{
    printk(KERN_DEBUG "process %i (%s) awakening the readers...\n",
           current-&gt;pid, current-&gt;comm);
    complete(&amp;comp);
    return count; /* succeed, to avoid retrial */
}
<br>可以同时有多个进程从该设备“读取”。每次写入设备都会导致一个读取操作完成，但无法确定是哪一个读取操作。<br>完成机制的典型用途是在模块退出时处理内核线程的终止。在典型情况下，驱动程序的某些内部工作由一个内核线程在 while (1) 循环中执行。当模块准备清理时，退出函数会告诉线程退出，然后等待完成。为此，内核包含一个特定函数供线程使用：<br>void complete_and_exit(struct completion *c, long retval);
]]></description><link>第5章-并发与竞态条件/5.4-完成机制.html</link><guid isPermaLink="false">第5章 并发与竞态条件/5.4 完成机制.md</guid><pubDate>Tue, 04 Mar 2025 16:27:36 GMT</pubDate></item><item><title><![CDATA[自旋锁]]></title><description><![CDATA[ 
 <br><br>信号量是用于互斥的有用工具，但它们并不是内核提供的唯一工具。实际上，大多数锁定是通过一种称为自旋锁的机制实现的。与信号量不同，自旋锁可以用于不能睡眠的代码中，例如中断处理程序。如果使用得当，自旋锁通常比信号量具有更高的性能。然而，它们也带来了一些不同的使用限制。<br>自旋锁的概念很简单。自旋锁是一种互斥设备，只能有两个值：“锁定”和“未锁定”。它通常实现为一个整数值中的单个位。希望获取特定锁的代码会测试相关位。如果锁可用，则设置“锁定”位，代码继续进入临界区。如果锁已被其他线程持有，代码将进入一个紧密的循环，反复检查锁，直到它变为可用。这个循环就是自旋锁的“自旋”部分。<br>当然，自旋锁的实际实现比上述描述要复杂一些。“测试并设置”操作必须以原子方式完成，以便即使有多个线程同时自旋，也只有一个线程可以获取锁。还必须小心避免在超线程处理器上发生死锁——这些处理器实现了多个虚拟CPU共享单个处理器核心和缓存。因此，自旋锁的实际实现在Linux支持的每个架构上都有所不同。然而，在所有系统上，核心概念是相同的：当有争用自旋锁时，等待的处理器会执行一个紧密的循环，不会完成任何有用的工作。<br>自旋锁本质上是为多处理器系统设计的，尽管运行抢占式内核的单处理器工作站在并发性方面表现得像SMP系统。如果非抢占式单处理器系统在锁上自旋，它将永远自旋；没有其他线程能够获得CPU来释放锁。因此，在没有启用抢占的单处理器系统上，自旋锁操作被优化为不执行任何操作，除了那些改变IRQ屏蔽状态的操作。由于抢占的存在，即使你从未期望你的代码在SMP系统上运行，你仍然需要实现适当的锁定。<br><br>自旋锁原语所需的头文件是 &lt;linux/spinlock.h&gt;。实际的锁类型为 spinlock_t。像任何其他数据结构一样，自旋锁必须初始化。可以在编译时初始化如下：<br>spinlock_t my_lock = SPIN_LOCK_UNLOCKED;
<br>或者在运行时使用：<br>void spin_lock_init(spinlock_t *lock);
<br>在进入临界区之前，你的代码必须使用以下函数获取所需的锁：<br>void spin_lock(spinlock_t *lock);
<br>请注意，所有自旋锁等待本质上都是不可中断的。一旦你调用 spin_lock，你将自旋直到锁变为可用。<br>要释放你获取的锁，请使用：<br>void spin_unlock(spinlock_t *lock);
<br>还有许多其他自旋锁函数，我们稍后会一一介绍。但它们都遵循上述函数展示的核心思想。除了锁定和释放锁之外，你几乎无法对锁进行其他操作。然而，使用自旋锁时有一些规则需要注意。在深入了解完整的自旋锁接口之前，我们先来看看这些规则。<br><br>想象一下，你的驱动程序获取了一个自旋锁，并在其临界区内执行操作。在某个时刻，你的驱动程序失去了处理器。也许它调用了一个函数（例如 copy_from_user），导致进程进入睡眠状态。或者，内核抢占启动，一个更高优先级的进程将你的代码推到一边。你的代码现在持有一个锁，并且在可预见的未来不会释放它。如果其他线程尝试获取相同的锁，它将在最好的情况下等待（在处理器上自旋）很长时间。在最坏的情况下，系统可能会完全死锁。<br>大多数读者会同意，这种情况最好避免。因此，适用于自旋锁的核心规则是，任何代码在持有自旋锁时必须是原子的。它不能睡眠；事实上，它不能出于任何原因放弃处理器，除了服务中断（有时甚至不能这样做）。<br>内核抢占的情况由自旋锁代码本身处理。任何时候内核代码持有自旋锁时，相关处理器上的抢占都会被禁用。即使是单处理器系统也必须以这种方式禁用抢占，以避免竞态条件。这就是为什么即使你从未期望你的代码在多处理器机器上运行，仍然需要适当的锁定。<br>避免在持有锁时睡眠可能更加困难；许多内核函数可能会睡眠，而且这种行为并不总是有很好的文档记录。从用户空间复制数据是一个明显的例子：所需的用户空间页面可能需要从磁盘交换进来，然后才能继续复制操作，而这个操作显然需要睡眠。几乎任何需要分配内存的操作都可能睡眠；除非明确告知不要这样做，否则 kmalloc 可能会决定放弃处理器并等待更多内存可用。睡眠可能发生在令人惊讶的地方；编写在自旋锁下执行的代码需要仔细检查你调用的每个函数。<br>另一个场景是：你的驱动程序正在执行，并且刚刚获取了一个控制其设备访问的锁。在持有锁的同时，设备发出中断，导致你的中断处理程序运行。中断处理程序在访问设备之前也必须获取锁。在中断处理程序中获取自旋锁是合法的；这是自旋锁操作不睡眠的原因之一。但如果中断例程在与最初获取锁的代码相同的处理器上执行会发生什么？当中断处理程序自旋时，非中断代码将无法运行以释放锁。该处理器将永远自旋。<br>为了避免这种陷阱，必须在持有自旋锁时禁用中断（仅在本地CPU上）。有一些自旋锁函数的变体可以为你禁用中断（我们将在下一节中看到它们）。然而，关于中断的完整讨论必须等到第10章。<br>最后一个重要的自旋锁使用规则是，自旋锁必须始终尽可能短时间地持有。你持有锁的时间越长，另一个处理器可能不得不自旋等待你释放锁的时间就越长，而且它不得不自旋的可能性也越大。长时间持有锁还会阻止当前处理器调度，这意味着更高优先级的进程——它确实应该能够获得CPU——可能不得不等待。内核开发人员在2.5开发系列中投入了大量精力来减少内核延迟（进程可能必须等待调度的时间）。一个编写不当的驱动程序可能会仅仅因为持有锁的时间过长而抹杀所有这些进展。为了避免这种问题，请务必保持锁的持有时间尽可能短。<br><br>我们已经看到了两个操作自旋锁的函数：spin_lock 和 spin_unlock。然而，还有其他几个函数，名称和用途类似。我们现在将介绍完整的集合。这个讨论将带我们进入一些我们暂时无法完全覆盖的领域；对自旋锁API的完整理解需要理解中断处理和相关概念。<br>实际上有四个函数可以锁定自旋锁：<br>void spin_lock(spinlock_t *lock);
void spin_lock_irqsave(spinlock_t *lock, unsigned long flags);
void spin_lock_irq(spinlock_t *lock);
void spin_lock_bh(spinlock_t *lock);
<br>我们已经了解了 spin_lock 的工作原理。spin_lock_irqsave 在获取自旋锁之前禁用中断（仅在本地处理器上）；之前的中断状态存储在 flags 中。如果你确定没有其他代码可能已经禁用了你处理器上的中断（换句话说，你确定在释放自旋锁时应启用中断），你可以使用 spin_lock_irq 而不必跟踪 flags。最后，spin_lock_bh 在获取锁之前禁用软件中断，但保持硬件中断启用。<br>如果你的自旋锁可能被在（硬件或软件）中断上下文中运行的代码获取，你必须使用禁用中断的自旋锁形式。否则，系统迟早会死锁。如果你不在硬件中断处理程序中访问你的锁，但通过软件中断访问（例如，在任务队列中运行的代码，这是第7章的主题），你可以使用 spin_lock_bh 来安全地避免死锁，同时仍然允许硬件中断被服务。<br>还有四种释放自旋锁的方式；你使用的释放函数必须与你用来获取锁的函数相对应：<br>void spin_unlock(spinlock_t *lock);
void spin_unlock_irqrestore(spinlock_t *lock, unsigned long flags);
void spin_unlock_irq(spinlock_t *lock);
void spin_unlock_bh(spinlock_t *lock);
<br>每个 spin_unlock 变体都会撤销相应的 spin_lock 函数所做的工作。传递给 spin_unlock_irqrestore 的 flags 参数必须与传递给 spin_lock_irqsave 的变量相同。你还必须在同一个函数中调用 spin_lock_irqsave 和 spin_unlock_irqrestore；否则，你的代码在某些架构上可能会出错。<br>还有一组非阻塞的自旋锁操作：<br>int spin_trylock(spinlock_t *lock);
int spin_trylock_bh(spinlock_t *lock);
<br>这些函数在成功时返回非零值（获取了锁），否则返回0。没有禁用中断的“try”版本。<br><br>内核提供了一种读者/写者形式的自旋锁，与我们之前看到的读者/写者信号量直接类似。这些锁允许多个读者同时进入临界区，但写者必须独占访问。读者/写者锁的类型为 rwlock_t，定义在 &lt;linux/spinlock.h&gt; 中。它们可以通过两种方式声明和初始化：<br>rwlock_t my_rwlock = RW_LOCK_UNLOCKED; /* 静态方式 */

rwlock_t my_rwlock;
rwlock_init(&amp;my_rwlock); /* 动态方式 */
<br>可用的函数列表现在看起来应该相当熟悉。对于读者，以下函数可用：<br>void read_lock(rwlock_t *lock);
void read_lock_irqsave(rwlock_t *lock, unsigned long flags);
void read_lock_irq(rwlock_t *lock);
void read_lock_bh(rwlock_t *lock);

void read_unlock(rwlock_t *lock);
void read_unlock_irqrestore(rwlock_t *lock, unsigned long flags);
void read_unlock_irq(rwlock_t *lock);
void read_unlock_bh(rwlock_t *lock);
<br>有趣的是，没有 read_trylock。<br>写者访问的函数类似：<br>void write_lock(rwlock_t *lock);
void write_lock_irqsave(rwlock_t *lock, unsigned long flags);
void write_lock_irq(rwlock_t *lock);
void write_lock_bh(rwlock_t *lock);
int write_trylock(rwlock_t *lock);

void write_unlock(rwlock_t *lock);
void write_unlock_irqrestore(rwlock_t *lock, unsigned long flags);
void write_unlock_irq(rwlock_t *lock);
void write_unlock_bh(rwlock_t *lock);
<br>读者/写者锁可能会像 rw_semaphore 一样导致读者饥饿。这种行为很少成为问题；然而，如果有足够的锁争用导致饥饿，性能已经很差了。]]></description><link>第5章-并发与竞态条件/5.5-自旋锁.html</link><guid isPermaLink="false">第5章 并发与竞态条件/5.5 自旋锁.md</guid><pubDate>Tue, 04 Mar 2025 16:26:40 GMT</pubDate></item><item><title><![CDATA[锁定陷阱]]></title><description><![CDATA[ 
 <br><br>多年使用锁的经验——早于Linux——表明锁定可能非常难以正确实现。管理并发性本质上是一项棘手的任务，有许多出错的方式。在本节中，我们快速看一下可能出错的地方。<br><br>如前所述，适当的锁定方案需要清晰明确的规则。当你创建一个可以并发访问的资源时，你应该定义哪个锁将控制该访问。锁定应该在开始时就规划好；事后添加锁定可能非常困难。在开始时花费的时间通常会在调试时得到丰厚的回报。<br>当你编写代码时，你无疑会遇到几个都需要访问由特定锁保护的结构体的函数。此时，你必须小心：如果一个函数获取了锁，然后调用另一个也尝试获取锁的函数，你的代码将死锁。信号量和自旋锁都不允许锁持有者再次获取锁；如果你尝试这样做，事情就会挂起。<br>为了使你的锁定正常工作，你必须编写一些函数，假设它们的调用者已经获取了相关的锁。通常，只有你的内部静态函数可以以这种方式编写；从外部调用的函数必须显式处理锁定。当你编写假设锁定的内部函数时，请为你自己（以及任何与你代码一起工作的人）做好事，明确记录这些假设。几个月后回来弄清楚是否需要持有锁来调用特定函数可能会非常困难。<br>在 scull 的情况下，设计决策是要求所有直接从系统调用调用的函数获取适用于设备结构的信号量。所有内部函数，仅从其他 scull 函数调用，则可以假设信号量已被正确获取。<br><br>在具有大量锁的系统中（内核正在成为这样的系统），代码通常需要同时持有多个锁。如果必须使用两个不同的资源执行某种计算，每个资源都有自己的锁，通常没有其他选择，只能获取两个锁。<br>然而，获取多个锁可能是危险的。如果你有两个锁，称为 Lock1 和 Lock2，并且代码需要同时获取它们，你可能会遇到死锁。想象一下，一个线程锁定 Lock1，而另一个线程同时锁定 Lock2。然后每个线程尝试获取它没有的锁。两个线程都将死锁。<br>解决这个问题的方法通常很简单：当必须获取多个锁时，它们应始终以相同的顺序获取。只要遵循这个约定，就可以避免上述简单的死锁。然而，遵循锁定顺序规则可能说起来容易做起来难。这种规则很少被写下来。通常，你只能看看其他代码是怎么做的。<br>有几个经验法则可以帮助你。如果你必须获取一个本地锁（例如设备锁）和一个属于内核更核心部分的锁，请先获取你的锁。如果你有信号量和自旋锁的组合，你当然必须先获取信号量；在持有自旋锁时调用 down（可能会睡眠）是一个严重的错误。但最重要的是，尽量避免需要多个锁的情况。<br><br>第一个支持多处理器系统的Linux内核是2.0；它只包含一个自旋锁。大内核锁将整个内核变成了一个大临界区；任何时候只有一个CPU可以执行内核代码。这个锁很好地解决了并发性问题，使内核开发人员能够解决支持SMP的所有其他问题。但它扩展性不好。即使是双处理器系统也可能花费大量时间等待大内核锁。四处理器系统的性能甚至无法接近四台独立机器的性能。<br>因此，后续的内核版本包含了更细粒度的锁定。在2.2中，一个自旋锁控制对块I/O子系统的访问；另一个用于网络，依此类推。现代内核可能包含数千个锁，每个锁保护一个小资源。这种细粒度锁定有利于扩展性；它允许每个处理器在不争用其他处理器使用的锁的情况下完成其特定任务。很少有人怀念大内核锁。<br>然而，细粒度锁定是有代价的。在一个有数千个锁的内核中，很难知道你需要哪些锁——以及你应该以什么顺序获取它们——来执行特定操作。请记住，锁定错误可能非常难以发现；更多的锁提供了更多机会让真正棘手的锁定错误潜入内核。细粒度锁定可能带来一种复杂性，从长远来看，可能对内核的可维护性产生很大的不利影响。<br>设备驱动程序中的锁定通常相对简单；你可以有一个覆盖所有操作的单一锁，或者为你管理的每个设备创建一个锁。作为一般规则，除非你有真正的理由相信争用可能成为问题，否则应该从相对粗粒度的锁定开始。抵制过早优化的冲动；真正的性能瓶颈通常出现在意想不到的地方。<br>如果你确实怀疑锁争用正在影响性能，你可能会发现 lock_meter 工具很有用。这个补丁（可在 http://oss.sgi.com/projects/lockmeter/ 获得）对内核进行检测，以测量在锁中等待的时间。通过查看报告，你可以快速确定锁争用是否真的是问题。]]></description><link>第5章-并发与竞态条件/5.6-锁定陷阱.html</link><guid isPermaLink="false">第5章 并发与竞态条件/5.6 锁定陷阱.md</guid><pubDate>Tue, 04 Mar 2025 16:27:22 GMT</pubDate></item><item><title><![CDATA[锁定的替代方案]]></title><description><![CDATA[ 
 <br><br>Linux内核提供了许多强大的锁定原语，可以用来防止内核自己绊倒自己。但正如我们所看到的，锁定方案的设计和实现并非没有陷阱。通常没有替代信号量和自旋锁的方案；它们可能是唯一正确完成任务的方式。然而，在某些情况下，可以设置原子访问而不需要完全锁定。本节将探讨其他方法。<br><br>有时，你可以重新设计算法，完全避免锁定的需要。许多读者/写者情况——如果只有一个写者——通常可以以这种方式工作。如果写者确保读者看到的数据结构视图始终一致，那么可以创建一个无锁的数据结构。<br>一种通常对无锁生产者/消费者任务有用的数据结构是环形缓冲区。该算法涉及生产者将数据放入数组的一端，而消费者从另一端移除数据。当到达数组的末尾时，生产者绕回开头。因此，环形缓冲区需要一个数组和两个索引值来跟踪下一个新值应该放在哪里以及应该从缓冲区中移除哪个值。<br>当仔细实现时，环形缓冲区在不存在多个生产者或消费者的情况下不需要锁定。生产者是唯一允许修改写索引及其指向的数组位置的线程。只要写者在更新写索引之前将新值存储到缓冲区中，读者将始终看到一致的视图。读者是唯一可以访问读索引及其指向的值的线程。通过小心确保两个指针不会相互超越，生产者和消费者可以并发访问缓冲区而不会出现竞态条件。<br>图5-1展示了环形缓冲区的几种填充状态。这个缓冲区的定义是，当读指针和写指针相等时表示缓冲区为空，而当写指针紧跟在读指针后面时表示缓冲区已满（注意处理回绕的情况！）。如果编程得当，这个缓冲区可以在没有锁的情况下使用。<br>写指针 -&gt; |   |   |   |   |   |
读指针 -&gt; |   |   |   |   |   |

写指针 -&gt; | A |   |   |   |   |
读指针 -&gt; | A |   |   |   |   |

写指针 -&gt; | A | B |   |   |   |
读指针 -&gt; | A | B |   |   |   |

写指针 -&gt; | A | B | C |   |   |
读指针 -&gt; | A | B | C |   |   |

写指针 -&gt; | A | B | C | D |   |
读指针 -&gt; | A | B | C | D |   |

写指针 -&gt; | A | B | C | D | E |
读指针 -&gt; | A | B | C | D | E |
<br>图5-1：环形缓冲区<br>环形缓冲区在设备驱动程序中相当常见。特别是网络适配器，通常使用环形缓冲区与处理器交换数据（数据包）。请注意，从2.6.10开始，内核中提供了一个通用的环形缓冲区实现；有关如何使用它的信息，请参阅 &lt;linux/kfifo.h&gt;。<br><br>有时，共享资源是一个简单的整数值。假设你的驱动程序维护一个共享变量 n_op，用于记录当前有多少设备操作正在进行。通常，即使是像这样的简单操作：<br>n_op++;
<br>也需要锁定。某些处理器可能会以原子方式执行这种递增操作，但你不能依赖它。然而，对于一个简单的整数值来说，完整的锁定机制似乎有些过度。对于这种情况，内核提供了一个称为 atomic_t 的原子整数类型，定义在 &lt;asm/atomic.h&gt; 中。<br>在所有支持的架构上，atomic_t 都持有一个 int 值。然而，由于某些处理器的工作方式，可能无法使用完整的整数范围；因此，你不应指望 atomic_t 能持有超过24位的值。以下操作为该类型定义，并且保证在SMP计算机的所有处理器上都是原子的。这些操作非常快，因为它们尽可能编译为单个机器指令。<br>void atomic_set(atomic_t *v, int i);
atomic_t v = ATOMIC_INIT(0);
<br>将原子变量 v 设置为整数值 i。你也可以使用 ATOMIC_INIT 宏在编译时初始化原子值。<br>int atomic_read(atomic_t *v);
<br>返回 v 的当前值。<br>void atomic_add(int i, atomic_t *v);
<br>将 i 加到原子变量 v 上。返回值为 void，因为返回新值会有额外的开销，而且大多数情况下不需要知道它。<br>void atomic_sub(int i, atomic_t *v);
<br>从 *v 中减去 i。<br>void atomic_inc(atomic_t *v);
void atomic_dec(atomic_t *v);
<br>递增或递减原子变量。<br>int atomic_inc_and_test(atomic_t *v);
int atomic_dec_and_test(atomic_t *v);
int atomic_sub_and_test(int i, atomic_t *v);
<br>执行指定的操作并测试结果；如果在操作后原子值为0，则返回值为 true，否则为 false。注意，没有 atomic_add_and_test。<br>int atomic_add_negative(int i, atomic_t *v);
<br>将整数值 i 加到 v 上。如果结果为负数，则返回 true，否则返回 false。<br>int atomic_add_return(int i, atomic_t *v);
int atomic_sub_return(int i, atomic_t *v);
int atomic_inc_return(atomic_t *v);
int atomic_dec_return(atomic_t *v);
<br>行为类似于 atomic_add 及其相关函数，但它们会将原子变量的新值返回给调用者。<br>如前所述，atomic_t 数据项只能通过这些函数访问。如果你将一个原子项传递给一个期望整数参数的函数，你会得到一个编译器错误。<br>你还应记住，atomic_t 值仅在所涉及的量真正是原子时才有效。需要多个 atomic_t 变量的操作仍然需要某种其他形式的锁定。考虑以下代码：<br>atomic_sub(amount, &amp;first_atomic);
atomic_add(amount, &amp;second_atomic);
<br>在这两个操作之间有一段时间，amount 已经从第一个原子值中减去，但尚未加到第二个原子值中。如果这种状态可能会在两者之间运行的代码中引发问题，则必须使用某种形式的锁定。<br><br>atomic_t 类型适用于执行整数算术。然而，当你需要以原子方式操作单个位时，它并不那么有效。为此，内核提供了一组函数，可以原子地修改或测试单个位。由于整个操作在一步中完成，没有中断（或其他处理器）可以干扰。<br>原子位操作非常快，因为它们尽可能使用单个机器指令执行操作，而不禁用中断。这些函数是架构相关的，声明在 &lt;asm/bitops.h&gt; 中。它们保证在SMP计算机上也是原子的，并且对于保持处理器之间的一致性非常有用。<br>不幸的是，这些函数中的数据类型也是架构相关的。nr 参数（描述要操作的位）通常定义为 int，但在某些架构上为 unsigned long。要修改的地址通常是指向 unsigned long 的指针，但某些架构使用 void *。<br>可用的位操作包括：<br>void set_bit(nr, void *addr);
<br>设置 addr 指向的数据项中的第 nr 位。<br>void clear_bit(nr, void *addr);
<br>清除 addr 处的 unsigned long 数据中的指定位。其语义与 set_bit 相同。<br>void change_bit(nr, void *addr);
<br>切换位。<br>test_bit(nr, void *addr);
<br>这个函数是唯一不需要原子操作的位操作；它只是返回位的当前值。<br>int test_and_set_bit(nr, void *addr);
int test_and_clear_bit(nr, void *addr);
int test_and_change_bit(nr, void *addr);
<br>这些函数的行为与前面列出的函数类似，但它们还返回位的前一个值。<br>当这些函数用于访问和修改共享标志时，你不需要做任何事情，只需调用它们；它们以原子方式执行操作。然而，使用位操作来管理控制共享变量访问的锁变量则稍微复杂一些，值得一个例子。大多数现代代码不会以这种方式使用位操作，但类似以下的代码仍然存在于内核中。<br>需要访问共享数据项的代码段尝试使用 test_and_set_bit 或 test_and_clear_bit 原子地获取锁。通常的实现如下所示；它假设锁位于地址 addr 的第 nr 位。它还假设当锁空闲时该位为0，当锁忙时为非零。<br>/* 尝试设置锁 */
while (test_and_set_bit(nr, addr) != 0)
    wait_for_a_while();

/* 执行你的工作 */

/* 释放锁，并检查... */
if (test_and_clear_bit(nr, addr) == 0)
    something_went_wrong(); /* 已经释放：错误 */
<br>如果你阅读内核源代码，你会发现类似这样的代码。然而，在新代码中使用自旋锁要好得多；自旋锁经过充分调试，它们处理中断和内核抢占等问题，其他阅读你代码的人也不必费力理解你在做什么。<br><br>2.6内核包含了一些新机制，旨在提供对共享资源的快速、无锁访问。顺序锁适用于受保护的资源小、简单且频繁访问，而写访问很少但必须快速的情况。本质上，它们通过允许读者自由访问资源，但要求读者检查是否与写者发生冲突，并在发生冲突时重试访问。顺序锁通常不能用于保护涉及指针的数据结构，因为读者可能在写者更改数据结构时跟随无效指针。<br>顺序锁定义在 &lt;linux/seqlock.h&gt; 中。通常有两种初始化顺序锁（类型为 seqlock_t）的方法：<br>seqlock_t lock1 = SEQLOCK_UNLOCKED;

seqlock_t lock2;
seqlock_init(&amp;lock2);
<br>读访问通过在进入临界区时获取一个（无符号）整数序列值来工作。在退出时，将该序列值与当前值进行比较；如果不匹配，则必须重试读访问。因此，读者代码的形式如下：<br>unsigned int seq;

do {
    seq = read_seqbegin(&amp;the_lock);
    /* 执行你需要做的操作 */
} while (read_seqretry(&amp;the_lock, seq));
<br>这种锁通常用于保护某些需要多个一致值的简单计算。如果在计算结束时的测试显示发生了并发写操作，则可以简单地丢弃结果并重新计算。<br>如果你的顺序锁可能从中断处理程序中访问，你应该使用IRQ安全版本：<br>unsigned int read_seqbegin_irqsave(seqlock_t *lock, unsigned long flags);
int read_seqretry_irqrestore(seqlock_t *lock, unsigned int seq, unsigned long flags);
<br>写者必须获取独占锁才能进入受顺序锁保护的临界区。为此，调用：<br>void write_seqlock(seqlock_t *lock);
<br>写锁使用自旋锁实现，因此所有通常的约束都适用。调用以下函数释放锁：<br>void write_sequnlock(seqlock_t *lock);
<br>由于自旋锁用于控制写访问，所有常见的变体都可用：<br>void write_seqlock_irqsave(seqlock_t *lock, unsigned long flags);
void write_seqlock_irq(seqlock_t *lock);
void write_seqlock_bh(seqlock_t *lock);

void write_sequnlock_irqrestore(seqlock_t *lock, unsigned long flags);
void write_sequnlock_irq(seqlock_t *lock);
void write_sequnlock_bh(seqlock_t *lock);
<br>还有一个 write_tryseqlock，如果成功获取锁，则返回非零值。<br><br>读-复制-更新（RCU）是一种高级的互斥方案，在适当条件下可以提供高性能。它在驱动程序中的使用很少见，但并非未知，因此值得快速概述。对其完整细节感兴趣的读者可以在其创建者发布的白皮书中找到（<a data-tooltip-position="top" aria-label="http://www.rdrop.com/users/paulmck/rcu/intro/rcu_intro.html%EF%BC%89%E3%80%82" rel="noopener nofollow" class="external-link" href="http://www.rdrop.com/users/paulmck/rcu/intro/rcu_intro.html%EF%BC%89%E3%80%82" target="_blank">http://www.rdrop.com/users/paulmck/rcu/intro/rcu_intro.html）。</a><br>RCU对它可以保护的数据结构类型施加了一些限制。它针对读操作常见而写操作罕见的情况进行了优化。受保护的资源应通过指针访问，并且对这些资源的所有引用必须仅由原子代码持有。当需要更改数据结构时，写线程会创建一个副本，更改副本，然后将相关指针指向新版本——因此得名。当内核确定没有对旧版本的引用时，可以释放它。<br>作为RCU在现实世界中的使用示例，考虑网络路由表。每个出站数据包都需要检查路由表以确定应使用哪个接口。检查是快速的，一旦内核找到目标接口，它就不再需要路由表条目。RCU允许在不锁定的情况下执行路由查找，从而显著提高性能。内核中的Starmode无线电IP驱动程序也使用RCU来跟踪其设备列表。<br>使用RCU的代码应包含 &lt;linux/rcupdate.h&gt;。<br>在读端，使用RCU保护的数据结构的代码应将其引用括在 rcu_read_lock 和 rcu_read_unlock 调用之间。因此，RCU代码通常如下所示：<br>struct my_stuff *stuff;

rcu_read_lock();
stuff = find_the_stuff(args...);
do_something_with(stuff);
rcu_read_unlock();
<br>rcu_read_lock 调用很快；它禁用内核抢占，但不等待任何东西。在读“锁”持有的期间执行的代码必须是原子的。在调用 rcu_read_unlock 后，不能使用对受保护资源的引用。<br>需要更改受保护结构的代码必须执行几个步骤。第一部分很简单；它分配一个新结构，如果需要，从旧结构中复制数据，然后替换读代码看到的指针。此时，对于读端来说，更改已经完成；任何进入临界区的代码都会看到数据的新版本。<br>剩下的就是释放旧版本。问题当然是，运行在其他处理器上的代码可能仍然持有对旧数据的引用，因此不能立即释放。相反，写代码必须等待，直到它知道不再存在这样的引用。由于所有持有对此数据结构引用的代码必须（根据规则）是原子的，我们知道一旦系统中的每个处理器至少被调度一次，所有引用都必须消失。这就是RCU所做的；它设置一个回调，等待所有处理器都被调度；然后运行该回调以执行清理工作。<br>更改RCU保护的数据结构的代码必须通过分配一个 struct rcu_head 来获取其清理回调，尽管它不需要以任何方式初始化该结构。通常，该结构只是嵌入在受RCU保护的较大资源中。在对该资源的更改完成后，应调用：<br>void call_rcu(struct rcu_head *head, void (*func)(void *arg), void *arg);
<br>当可以安全释放资源时，调用给定的 func；它传递给 call_rcu 的 arg 相同。通常，func 只需要调用 kfree。<br>完整的RCU接口比我们在这里看到的更复杂；例如，它包括用于处理受保护的链表的实用函数。有关完整信息，请参阅相关的头文件。]]></description><link>第5章-并发与竞态条件/5.7-锁定的替代方案.html</link><guid isPermaLink="false">第5章 并发与竞态条件/5.7 锁定的替代方案.md</guid><pubDate>Tue, 04 Mar 2025 16:29:07 GMT</pubDate></item><item><title><![CDATA[快速参考]]></title><description><![CDATA[ 
 <br><br>本章介绍了大量用于管理并发的符号。其中最重要的总结如下：<br>#include &lt;asm/semaphore.h&gt;
<br>定义信号量及其操作的头文件。<br>DECLARE_MUTEX(name);
DECLARE_MUTEX_LOCKED(name);
<br>用于声明和初始化互斥信号量的两个宏。<br>void init_MUTEX(struct semaphore *sem);
void init_MUTEX_LOCKED(struct semaphore *sem);
<br>这两个函数可用于在运行时初始化信号量。<br>void down(struct semaphore *sem);
int down_interruptible(struct semaphore *sem);
int down_trylock(struct semaphore *sem);
void up(struct semaphore *sem);
<br>锁定和解锁信号量。down 在必要时将调用进程置于不可中断的睡眠状态；down_interruptible 可以被信号中断。down_trylock 不睡眠；如果信号量不可用，它立即返回。锁定信号量的代码最终必须使用 up 解锁它。<br>struct rw_semaphore;
init_rwsem(struct rw_semaphore *sem);
<br>读者/写者信号量及其初始化函数。<br>void down_read(struct rw_semaphore *sem);
int down_read_trylock(struct rw_semaphore *sem);
void up_read(struct rw_semaphore *sem);
<br>获取和释放读者/写者信号量的读访问权限的函数。<br>void down_write(struct rw_semaphore *sem);
int down_write_trylock(struct rw_semaphore *sem);
void up_write(struct rw_semaphore *sem);
void downgrade_write(struct rw_semaphore *sem);
<br>管理读者/写者信号量的写访问权限的函数。<br>#include &lt;linux/completion.h&gt;
DECLARE_COMPLETION(name);
init_completion(struct completion *c);
INIT_COMPLETION(struct completion c);
<br>描述Linux完成机制的头文件，以及初始化完成的常规方法。INIT_COMPLETION 应仅用于重新初始化先前使用过的完成。<br>void wait_for_completion(struct completion *c);
<br>等待完成事件被发出信号。<br>void complete(struct completion *c);
void complete_all(struct completion *c);
<br>发出完成事件的信号。complete 最多唤醒一个等待的线程，而 complete_all 唤醒所有等待者。<br>void complete_and_exit(struct completion *c, long retval);
<br>通过调用 complete 发出完成事件的信号，并为当前线程调用 exit。<br>#include &lt;linux/spinlock.h&gt;
spinlock_t lock = SPIN_LOCK_UNLOCKED;
spin_lock_init(spinlock_t *lock);
<br>定义自旋锁接口的头文件，以及初始化锁的两种方式。<br>void spin_lock(spinlock_t *lock);
void spin_lock_irqsave(spinlock_t *lock, unsigned long flags);
void spin_lock_irq(spinlock_t *lock);
void spin_lock_bh(spinlock_t *lock);
<br>锁定自旋锁并可能禁用中断的各种方式。<br>int spin_trylock(spinlock_t *lock);
int spin_trylock_bh(spinlock_t *lock);
<br>上述函数的非自旋版本；如果无法获取锁，则返回0，否则返回非零值。<br>void spin_unlock(spinlock_t *lock);
void spin_unlock_irqrestore(spinlock_t *lock, unsigned long flags);
void spin_unlock_irq(spinlock_t *lock);
void spin_unlock_bh(spinlock_t *lock);
<br>释放自旋锁的相应方式。<br>rwlock_t lock = RW_LOCK_UNLOCKED;
rwlock_init(rwlock_t *lock);
<br>初始化读者/写者锁的两种方式。<br>void read_lock(rwlock_t *lock);
void read_lock_irqsave(rwlock_t *lock, unsigned long flags);
void read_lock_irq(rwlock_t *lock);
void read_lock_bh(rwlock_t *lock);
<br>获取读者/写者锁的读访问权限的函数。<br>void read_unlock(rwlock_t *lock);
void read_unlock_irqrestore(rwlock_t *lock, unsigned long flags);
void read_unlock_irq(rwlock_t *lock);
void read_unlock_bh(rwlock_t *lock);
<br>释放读者/写者锁的读访问权限的函数。<br>void write_lock(rwlock_t *lock);
void write_lock_irqsave(rwlock_t *lock, unsigned long flags);
void write_lock_irq(rwlock_t *lock);
void write_lock_bh(rwlock_t *lock);
<br>获取读者/写者锁的写访问权限的函数。<br>void write_unlock(rwlock_t *lock);
void write_unlock_irqrestore(rwlock_t *lock, unsigned long flags);
void write_unlock_irq(rwlock_t *lock);
void write_unlock_bh(rwlock_t *lock);
<br>释放读者/写者锁的写访问权限的函数。<br>#include &lt;asm/atomic.h&gt;
atomic_t v = ATOMIC_INIT(value);
void atomic_set(atomic_t *v, int i);
int atomic_read
]]></description><link>第5章-并发与竞态条件/5.8-快速参考.html</link><guid isPermaLink="false">第5章 并发与竞态条件/5.8 快速参考.md</guid><pubDate>Tue, 04 Mar 2025 16:29:21 GMT</pubDate></item></channel></rss>